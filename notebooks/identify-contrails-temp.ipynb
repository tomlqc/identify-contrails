{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Contrails with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinstall tensorflow-io\n",
    "# to avoid the UserWarning: unable to load libtensorflow_io_plugins.so\n",
    "\n",
    "#!pip install tensorflow-io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "\n",
    "LOAD_CHECKPOINT = False  # <DEVEL>\n",
    "TRAIN = True  # <DEVEL>\n",
    "\n",
    "if os.path.exists('/kaggle'):\n",
    "    PLATFORM = 'kaggle'\n",
    "else:\n",
    "    PLATFORM = 'gcp'\n",
    "\n",
    "# ==============================\n",
    "\n",
    "print(f'PLATFORM = {PLATFORM}')\n",
    "print()\n",
    "print(f'LOAD_CHECKPOINT = {LOAD_CHECKPOINT}')\n",
    "print(f'TRAIN = {TRAIN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLATFORM == 'kaggle':\n",
    "\n",
    "    WORK_DIR = '/kaggle/working'  # preserved if notebook is saved\n",
    "    TEMP_DIR = '/kaggle/temp'  # just during current session\n",
    "\n",
    "    DATA_DIR = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n",
    "    \n",
    "    WEIGHTS_DIR = WORK_DIR\n",
    "    \n",
    "    resnet50_imagenet_weights =\\\n",
    "        '/kaggle/input/d/alexisbcook/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "    # You can write up to 20GB to the current directory (/kaggle/working/)\n",
    "    # that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "    # You can also write temporary files to /kaggle/temp/,\n",
    "    # but they won't be saved outside of the current session\n",
    "\n",
    "elif PLATFORM == 'gcp':\n",
    "\n",
    "    WORK_DIR = '/home/jupyter/kaggle/working'  # preserved if notebook is saved\n",
    "    TEMP_DIR = '/home/jupyter/kaggle/temp'  # just during current session\n",
    "\n",
    "    DATA_DIR = '/home/jupyter/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n",
    "    \n",
    "    WEIGHTS_DIR = '/home/jupyter/identify-contrails-models'\n",
    "    \n",
    "    resnet50_imagenet_weights = 'imagenet'\n",
    "    \n",
    "    %cd $WORK_DIR\n",
    "    \n",
    "else:\n",
    "    raise NotImplementedError(f'unknown platform \"{PLATFORM}\"')\n",
    "\n",
    "print('PWD =', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPDATE_DATA = False\n",
    "\n",
    "if UPDATE_DATA:\n",
    "    %cp -v /kaggle/input/identify-contrails/contrails_2023*.h5 .\n",
    "    %ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_CHECKPOINT:\n",
    "    prev_checkpoint_path = os.path.join(WEIGHTS_DIR, 'contrails_2023-07-22_16-22-01.h5')  # <DEVEL>\n",
    "    print(f'prev_checkpoint_path = {prev_checkpoint_path}')\n",
    "    if not os.path.exists(prev_checkpoint_path):\n",
    "        raise IOError(f'file does not exist {prev_checkpoint_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch submission.csv\n",
    "%ll -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import datetime\n",
    "import itertools\n",
    "import math\n",
    "import multiprocessing\n",
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from pprint import pprint\n",
    "from pytz import timezone\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRINT_TIME_FORMAT = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
    "FILE_TIME_FORMAT = \"%Y-%m-%d_%H-%M-%S\"\n",
    "\n",
    "start_time = datetime.datetime.now(timezone('CET'))\n",
    "\n",
    "file_time_str = start_time.strftime(FILE_TIME_FORMAT)\n",
    "\n",
    "print('Started', start_time.strftime(PRINT_TIME_FORMAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as backend\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print('cpu_count: ', multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paths:\n",
    "    train = os.path.join(DATA_DIR, 'train')\n",
    "    valid = os.path.join(DATA_DIR, 'validation')\n",
    "    test = os.path.join(DATA_DIR, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = sorted(os.listdir(Paths.train))\n",
    "valid_ids = sorted(os.listdir(Paths.valid))\n",
    "test_ids = sorted(os.listdir(Paths.test))\n",
    "print('n_samples (train, validation, test) =', len(train_ids), len(valid_ids), len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABI:\n",
    "    bands = {name: idx for idx, name in enumerate([\n",
    "        '08', '09', '10', '11', '12', '13', '14', '15', '16'])}\n",
    "    colors = {name: idx for idx, name in enumerate([\n",
    "        'red', 'blue', 'green', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'black'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TIMES_BEFORE = 4\n",
    "N_TIMES_AFTER = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_range(data, bounds):\n",
    "    \"\"\"Maps data to the range [0, 1].\"\"\"\n",
    "    return (data - bounds[0]) / (bounds[1] - bounds[0])\n",
    "\n",
    "_T11_BOUNDS = (243, 303)\n",
    "_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n",
    "_TDIFF_BOUNDS = (-4, 2)\n",
    "\n",
    "def get_ash_colors(sample_id, split_dir):\n",
    "    \"\"\"\n",
    "    Based on bands: 11, 14, 15\n",
    "    \n",
    "    Args:\n",
    "        sample_id(str): The id of the example i.e. '1000216489776414077'\n",
    "        split_dir(str): The split directoryu i.e. 'test', 'train', 'val'\n",
    "    \"\"\"\n",
    "    band15 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_15.npy\")\n",
    "    band14 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_14.npy\")\n",
    "    band11 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_11.npy\")\n",
    "\n",
    "    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)\n",
    "    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n",
    "    b = normalize_range(band14, _T11_BOUNDS)\n",
    "    ash_colors = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n",
    "    \n",
    "    return ash_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_mask(sample_id, split_dir):\n",
    "    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_individual_masks.npy\"\n",
    "    pixel_mask = np.load(masks_path)\n",
    "    return pixel_mask\n",
    "\n",
    "def get_pixel_mask(sample_id, split_dir):\n",
    "    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_pixel_masks.npy\"\n",
    "    pixel_mask = np.load(masks_path)\n",
    "    return pixel_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = 7829917977180135058  # train_ids[3]\n",
    "\n",
    "print(f'Check `ash_colors` on one of the samples: {sample_id}')\n",
    "\n",
    "ash_colors = get_ash_colors(sample_id, 'train')[..., N_TIMES_BEFORE]\n",
    "\n",
    "print(ash_colors.shape)\n",
    "for color in range(3):\n",
    "    array = ash_colors[..., color]\n",
    "    print(array.min(), array.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_mask = get_pixel_mask(sample_id, 'train')\n",
    "\n",
    "print(pixel_mask.shape)\n",
    "print(pixel_mask.min(), pixel_mask.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T19:30:33.222846Z",
     "iopub.status.busy": "2023-07-10T19:30:33.222338Z",
     "iopub.status.idle": "2023-07-10T19:30:33.228013Z",
     "shell.execute_reply": "2023-07-10T19:30:33.227016Z",
     "shell.execute_reply.started": "2023-07-10T19:30:33.222811Z"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:  # <CONFIG>\n",
    "    \n",
    "    seed = SEED\n",
    "\n",
    "    img_size = (256, 256)\n",
    "    \n",
    "    model = 'deeplabv3plus'  # unet | deeplabv3plus\n",
    "    preprocess = None\n",
    "    backbone_trainable = True\n",
    "    \n",
    "    num_epochs = 10  # <DEVEL> else 10\n",
    "    num_classes = 1\n",
    "    batch_size = 16  # <DEVEL> else 16 or 32\n",
    "    \n",
    "    threshold = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/examples/keras_recipes/reproducibility_recipes/\n",
    "\n",
    "# Set the seed using keras.utils.set_random_seed. This will set:\n",
    "# 1) `numpy` seed\n",
    "# 2) `tensorflow` random seed\n",
    "# 3) `python` random seed\n",
    "keras.utils.set_random_seed(Config.seed)\n",
    "\n",
    "# See also:\n",
    "# tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed Precision\n",
    "# https://www.tensorflow.org/guide/mixed_precision#supported_hardware\n",
    "\n",
    "if PLATFORM == 'kaggle':\n",
    "    MIXED_PRECISION = True\n",
    "elif PLATFORM == 'gcp':\n",
    "    # No mixed precision on QCP:\n",
    "    # \"Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0.\n",
    "    # Your GPU: Tesla P100-PCIE-16GB, compute capability 6.0\"\n",
    "    MIXED_PRECISION = False\n",
    "else:\n",
    "    raise NotImplementedError(f'unknown platform \"{PLATFORM}\"')\n",
    "\n",
    "if MIXED_PRECISION:\n",
    "    print('setting mixed_precision')\n",
    "\n",
    "    NP_FLOAT = 'float16'\n",
    "    TF_FLOAT = tf.float16\n",
    "    \n",
    "    keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    final_dtype = 'float32'\n",
    "    \n",
    "else:\n",
    "    print('no mixed_precision')\n",
    "\n",
    "    NP_FLOAT = 'float32'\n",
    "    TF_FLOAT = tf.float32\n",
    "\n",
    "    final_dtype = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet:\n",
    "    '''U-Net model.\n",
    "    \n",
    "    Inspired by and adapted from:\n",
    "    - https://keras.io/examples/vision/oxford_pets_image_segmentation\n",
    "    - https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580\n",
    "    - https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow/home/week/3\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, preprocess=None, weights=None):\n",
    "        self.preprocess = preprocess\n",
    "        self.weights = weights\n",
    "        \n",
    "    def conv2d_block(self, input_tensor, n_filters, kernel_size=3):\n",
    "        x = input_tensor\n",
    "        for i in range(2):\n",
    "            x = tf.keras.layers.SeparableConv2D(\n",
    "                filters = n_filters, kernel_size=(kernel_size, kernel_size), padding='same')(x)\n",
    "            #? kernel_initializer = 'he_normal'\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    def encoder_block(self, inputs, n_filters, pool_size, dropout):\n",
    "        f = self.conv2d_block(inputs, n_filters=n_filters)\n",
    "        p = tf.keras.layers.MaxPooling2D(pool_size)(f)\n",
    "        p = tf.keras.layers.Dropout(dropout)(p)\n",
    "        return f, p\n",
    "\n",
    "    def encoder(self, inputs, dropout=0.1):\n",
    "        f1, p1 = self.encoder_block(inputs, n_filters=64, pool_size=(2,2), dropout=dropout)\n",
    "        f2, p2 = self.encoder_block(p1, n_filters=128, pool_size=(2,2), dropout=dropout)\n",
    "        f3, p3 = self.encoder_block(p2, n_filters=256, pool_size=(2,2), dropout=dropout)\n",
    "        f4, p4 = self.encoder_block(p3, n_filters=512, pool_size=(2,2), dropout=dropout)\n",
    "        return p4, (f1, f2, f3, f4)\n",
    "\n",
    "    def bottleneck(self, inputs):\n",
    "        bottle_neck = self.conv2d_block(inputs, n_filters=1024)\n",
    "        return bottle_neck\n",
    "\n",
    "    def decoder_block(self, inputs, conv_output, n_filters, kernel_size, strides, dropout):\n",
    "        u = tf.keras.layers.Conv2DTranspose(\n",
    "            n_filters, kernel_size, strides=strides, padding = 'same')(inputs)\n",
    "        u = tf.keras.layers.BatchNormalization()(u)\n",
    "        c = tf.keras.layers.concatenate([u, conv_output])\n",
    "        c = tf.keras.layers.Dropout(dropout)(c)\n",
    "        c = self.conv2d_block(c, n_filters, kernel_size=3)\n",
    "        return c\n",
    "\n",
    "    def decoder(self, inputs, convs, num_classes, dropout=0.1):\n",
    "        f1, f2, f3, f4 = convs\n",
    "        c6 = self.decoder_block(inputs, f4, n_filters=512, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n",
    "        c7 = self.decoder_block(c6, f3, n_filters=256, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n",
    "        c8 = self.decoder_block(c7, f2, n_filters=128, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n",
    "        c9 = self.decoder_block(c8, f1, n_filters=64, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n",
    "        if num_classes == 1:\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            activation = \"softmax\"\n",
    "        outputs = layers.Conv2D(\n",
    "            num_classes, kernel_size=3, activation=activation, padding=\"same\", dtype=final_dtype)(c9)\n",
    "        return outputs\n",
    "\n",
    "    def model(self, image_size, num_classes):\n",
    "        inputs = tf.keras.layers.Input(shape=(image_size,image_size,3))\n",
    "        encoder_output, convs = self.encoder(inputs)\n",
    "        #model = tf.keras.Model(inputs=inputs, outputs=encoder_output)  # debug\n",
    "        bottle_neck = self.bottleneck(encoder_output)\n",
    "        outputs = self.decoder(bottle_neck, convs, num_classes)\n",
    "        model = tf.keras.Model(name=self.__class__.__name__, inputs=inputs, outputs=outputs)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabV3Plus:\n",
    "    '''DeepLabV3+ model.\n",
    "    \n",
    "    Adapted from:\n",
    "    - https://keras.io/examples/vision/deeplabv3_plus/#inference-using-colormap-overlay\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, preprocess='resnet50', weights='imagenet', resnet50_trainable=True):\n",
    "        self.preprocess = preprocess\n",
    "        self.weights = weights\n",
    "        self.resnet50_trainable = resnet50_trainable\n",
    "    \n",
    "    def convolution_block(\n",
    "        self,\n",
    "        block_input,\n",
    "        num_filters=256,\n",
    "        kernel_size=3,\n",
    "        dilation_rate=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "    ):\n",
    "        x = layers.Conv2D(\n",
    "            num_filters,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation_rate=dilation_rate,\n",
    "            padding=\"same\",\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=keras.initializers.HeNormal(),\n",
    "        )(block_input)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "    def DilatedSpatialPyramidPooling(self, dspp_input, dropout):\n",
    "        dims = dspp_input.shape\n",
    "        x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        x = self.convolution_block(x, kernel_size=1, use_bias=True)\n",
    "        out_pool = layers.UpSampling2D(\n",
    "            size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
    "        )(x)\n",
    "\n",
    "        out_1 = self.convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "        out_6 = self.convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "        out_12 = self.convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "        out_18 = self.convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "        x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "        output = self.convolution_block(x, kernel_size=1)\n",
    "        return output\n",
    "    \n",
    "    def model(self, image_size, num_classes):\n",
    "        \n",
    "        model_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "        \n",
    "        resnet50 = keras.applications.ResNet50(\n",
    "            weights=self.weights, include_top=False, input_tensor=model_input,\n",
    "        )\n",
    "        resnet50.trainable = self.resnet50_trainable\n",
    "        print('resnet50.trainable =', resnet50.trainable)\n",
    "        \n",
    "        x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "        x = self.DilatedSpatialPyramidPooling(x, dropout=0.1)\n",
    "\n",
    "        input_a = layers.UpSampling2D(\n",
    "            size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "            interpolation=\"bilinear\",\n",
    "        )(x)\n",
    "        input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "        input_b = self.convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "        x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "        x = self.convolution_block(x)\n",
    "        x = self.convolution_block(x)\n",
    "        x = layers.UpSampling2D(\n",
    "            size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "            interpolation=\"bilinear\",\n",
    "        )(x)\n",
    "        \n",
    "        if num_classes == 1:\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            activation = \"softmax\"\n",
    "        model_output = layers.Conv2D(\n",
    "            num_classes, kernel_size=(1, 1), activation=activation, padding=\"same\", dtype=final_dtype)(x)\n",
    "        \n",
    "        return keras.Model(name=self.__class__.__name__, inputs=model_input, outputs=model_output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Build model\n",
    "if Config.model == 'unet':\n",
    "    builder = UNet()\n",
    "\n",
    "elif Config.model == 'deeplabv3plus':\n",
    "    builder = DeepLabV3Plus(\n",
    "        preprocess=Config.preprocess,\n",
    "        weights=resnet50_imagenet_weights,\n",
    "        resnet50_trainable=Config.backbone_trainable,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    raise NotImplementedError(f'model \"{Config.model}\"')\n",
    "    \n",
    "model = builder.model(image_size=Config.img_size[0], num_classes=Config.num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T19:30:33.222846Z",
     "iopub.status.busy": "2023-07-10T19:30:33.222338Z",
     "iopub.status.idle": "2023-07-10T19:30:33.228013Z",
     "shell.execute_reply": "2023-07-10T19:30:33.227016Z",
     "shell.execute_reply.started": "2023-07-10T19:30:33.222811Z"
    },
    "tags": []
   },
   "source": [
    "# Configure datasets (keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = None  # 512 <DEVEL> else None\n",
    "N_VALID = None  # 128 <DEVEL> else None (1856)\n",
    "N_PARTIAL = 128  # 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('preprocess =', builder.preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AshColorSingleFrames(keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, img_size, sample_ids, split_dir, preprocess=None, n_samples=None):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.split_dir = split_dir\n",
    "        self.sample_ids = sample_ids[:n_samples]\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.sample_ids) / self.batch_size)\n",
    "    \n",
    "    def get_sample_ids(self, idx):\n",
    "        '''Get sample ids of batch idx.'''\n",
    "        i = idx * self.batch_size\n",
    "        return self.sample_ids[i : i + self.batch_size]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        \n",
    "        batch_sample_ids = self.get_sample_ids(idx)\n",
    "        \n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=NP_FLOAT)\n",
    "        for j, sample_id in enumerate(batch_sample_ids):\n",
    "            \n",
    "            img = get_ash_colors(sample_id, self.split_dir)[..., N_TIMES_BEFORE]\n",
    "            \n",
    "            if self.preprocess == 'resnet50':\n",
    "                img = keras.applications.resnet50.preprocess_input(img)\n",
    "            elif self.preprocess is not None:\n",
    "                raise NotImplementedError(f'preprocess \"{preprocess}\"')\n",
    "            \n",
    "            x[j] = img\n",
    "\n",
    "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "        if self.split_dir != 'test':\n",
    "            for j, sample_id in enumerate(batch_sample_ids):\n",
    "                img = get_pixel_mask(sample_id, self.split_dir)\n",
    "                y[j] = img\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = AshColorSingleFrames(\n",
    "    Config.batch_size, Config.img_size, train_ids, 'train',\n",
    "    preprocess=builder.preprocess, n_samples=N_TRAIN)\n",
    "print('number of batches:', len(train_set), 'train')\n",
    "\n",
    "valid_set = AshColorSingleFrames(\n",
    "    Config.batch_size, Config.img_size, valid_ids, 'validation',\n",
    "    preprocess=builder.preprocess, n_samples=N_VALID)\n",
    "print('number of batches:', len(valid_set), 'valid')\n",
    "\n",
    "partial_set = AshColorSingleFrames(\n",
    "    Config.batch_size, Config.img_size, valid_ids, 'validation',\n",
    "    preprocess=builder.preprocess, n_samples=N_PARTIAL)\n",
    "print('number of batches:', len(partial_set), 'partial')\n",
    "\n",
    "test_set = AshColorSingleFrames(\n",
    "    Config.batch_size, Config.img_size, test_ids, 'test',\n",
    "    preprocess=builder.preprocess)\n",
    "print('number of batches:', len(test_set), 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Check dimensions (x, y) of first batch:')\n",
    "\n",
    "train_set[0][0].shape, train_set[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFDataSetCreator:\n",
    "    '''Write TFRecords files and generate a TFRecordDataset from a keras.Sequence.\n",
    "    \n",
    "    Inspired by:\n",
    "    - https://www.tensorflow.org/tutorials/load_data/tfrecord\n",
    "    - https://keras.io/examples/keras_recipes/creating_tfrecords\n",
    "    - https://keras.io/examples/keras_recipes/tfrecord\n",
    "    - https://stackoverflow.com/questions/47861084/how-to-store-numpy-arrays-as-tfrecord\n",
    "    \n",
    "    References:\n",
    "    - https://www.tensorflow.org/guide/data - Build TensorFlow input pipelines\n",
    "    - https://www.tensorflow.org/guide/data_performance - Better performance with the tf.data API\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, keras_sequence):\n",
    "        self.keras_sequence = keras_sequence\n",
    "        self.split_dir = keras_sequence.split_dir\n",
    "        self.batch_size = keras_sequence.batch_size\n",
    "        \n",
    "        self.keep_existing = True\n",
    "        self.records_dir = os.path.join(TEMP_DIR, f'records-{self.batch_size}-{self.split_dir}')\n",
    "        self.record_paths = []\n",
    "        \n",
    "        self.progress_bar = True  # <DEVEL>\n",
    "    \n",
    "    def write_tfrec(self, batch_idx):\n",
    "        #pid = multiprocessing.current_process().pid\n",
    "        \n",
    "        record_path = os.path.join(self.records_dir, f'batch_{batch_idx:04d}.tfrec')\n",
    "        \n",
    "        if self.keep_existing and os.path.exists(record_path):\n",
    "            return record_path\n",
    "        \n",
    "        if self.progress_bar:\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('o', end='')\n",
    "            else:\n",
    "                print('.', end='')\n",
    "\n",
    "        x_b, y_b = self.keras_sequence[batch_idx]\n",
    "        with tf.io.TFRecordWriter(record_path) as writer:\n",
    "            for x, y in zip(x_b, y_b):\n",
    "                feature = {\n",
    "                    \"x\": tf.train.Feature(\n",
    "                        bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(x).numpy()])),\n",
    "                    \"y\": tf.train.Feature(\n",
    "                        bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(y).numpy()])),\n",
    "                }\n",
    "                example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "                writer.write(example.SerializeToString())\n",
    "        \n",
    "        return record_path\n",
    "    \n",
    "    def generate_tfrec(self, keep_existing=True):\n",
    "        \n",
    "        self.keep_existing = keep_existing\n",
    "        \n",
    "        records_dir = self.records_dir\n",
    "        os.makedirs(records_dir, exist_ok=True)\n",
    "        \n",
    "        n_records = len(self.keras_sequence)\n",
    "        n_procs = multiprocessing.cpu_count() * 2\n",
    "        print(f'generating {n_records} records with {n_procs} processes in: {records_dir}')\n",
    "        %ll -hd $records_dir\n",
    "\n",
    "        pool = multiprocessing.Pool(processes=n_procs)\n",
    "        batch_indexes = range(n_records)\n",
    "        record_paths = sorted(pool.map(self.write_tfrec, batch_indexes))\n",
    "        if self.progress_bar:\n",
    "            print()\n",
    "        \n",
    "        !du -sh $records_dir\n",
    "        self.record_paths = record_paths\n",
    "        return self\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_tfrecord_sample(element):\n",
    "        parse_dic = {\n",
    "            'x': tf.io.FixedLenFeature([], tf.string),  # Note that it is tf.string, not tf.float32\n",
    "            'y': tf.io.FixedLenFeature([], tf.string),  # Note that it is tf.string, not tf.float32\n",
    "        }\n",
    "        feature = tf.io.parse_single_example(element, parse_dic)\n",
    "        feature['x'] = tf.io.parse_tensor(feature['x'], out_type=TF_FLOAT)\n",
    "        feature['y'] = tf.io.parse_tensor(feature['y'], out_type=tf.uint8)\n",
    "        return feature\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_sample(features):\n",
    "        return features['x'], features['y']\n",
    "\n",
    "    def dataset(self):\n",
    "        dataset = (\n",
    "            tf.data.TFRecordDataset(self.record_paths, num_parallel_reads=AUTOTUNE)\n",
    "            .map(self.parse_tfrecord_sample, num_parallel_calls=AUTOTUNE)\n",
    "            .map(self.prepare_sample, num_parallel_calls=AUTOTUNE)\n",
    "            .shuffle(self.batch_size * 10)\n",
    "            .batch(self.batch_size)\n",
    "            .prefetch(AUTOTUNE)\n",
    "        )\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_EXISTING = True  # <DEVEL>\n",
    "\n",
    "timeit_start = datetime.datetime.now()\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Place tensors on the CPU\n",
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    tf_train_set = (\n",
    "        TFDataSetCreator(train_set)\n",
    "        .generate_tfrec(KEEP_EXISTING)\n",
    "        .dataset()\n",
    "    )\n",
    "\n",
    "    tf_valid_set = (\n",
    "        TFDataSetCreator(valid_set)\n",
    "        .generate_tfrec(KEEP_EXISTING)\n",
    "        .dataset()\n",
    "    )\n",
    "\n",
    "    tf_test_set = (\n",
    "        TFDataSetCreator(test_set)\n",
    "        .generate_tfrec(KEEP_EXISTING)\n",
    "        .dataset()\n",
    "    )\n",
    "\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "timeit_end = datetime.datetime.now()\n",
    "print('datasets generated in:', timeit_end - timeit_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=0.001, threshold=None):\n",
    "    '''Dice coefficient.\n",
    "    \n",
    "    Adapted from:\n",
    "    - https://stackoverflow.com/questions/72195156/correct-implementation-of-dice-loss-in-tensorflow-keras\n",
    "    - https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580\n",
    "    '''\n",
    "    \n",
    "    y_true_f = backend.flatten(tf.cast(y_true, TF_FLOAT))\n",
    "    y_pred_f = backend.flatten(tf.cast(y_pred, TF_FLOAT))\n",
    "    # ValueError: No gradients provided for any variable\n",
    "    if threshold is not None:\n",
    "        y_pred_f = backend.flatten(\n",
    "            tf.cast(tf.math.greater(tf.cast(y_pred, TF_FLOAT), threshold), TF_FLOAT))\n",
    "    intersection = backend.sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection + smooth) / (backend.sum(y_true_f) + backend.sum(y_pred_f) + smooth)\n",
    "    return dice\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def threshold_dice_coef(y_true, y_pred, smooth=0.001):\n",
    "#    '''Dice coefficient with threshold set to Config.threshold.'''\n",
    "#    return dice_coef(y_true, y_pred, smooth=smooth, threshold=Config.threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = 7829917977180135058  # train_ids[3]\n",
    "\n",
    "print(f'Check dice_coef() on one of the samples: {sample_id}')\n",
    "\n",
    "merged_mask = get_pixel_mask(sample_id, 'train')\n",
    "indiv_masks = get_individual_mask(sample_id, 'train')\n",
    "\n",
    "print(dice_coef(tf.convert_to_tensor(merged_mask),\n",
    "                tf.convert_to_tensor(merged_mask)))\n",
    "for idv in range(6):\n",
    "    print(dice_coef(tf.convert_to_tensor(merged_mask),\n",
    "                    tf.convert_to_tensor(indiv_masks[..., idv])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = f\"contrails_{file_time_str}.h5\"\n",
    "\n",
    "print(f'checkpoint file: {checkpoint_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler:\n",
    "# - https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules\n",
    "# - https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecay\n",
    "# Note: CosineDecay got warmup from v2.13.1 on\n",
    "\n",
    "initial_learning_rate = 0.01\n",
    "decay_steps = len(train_set)\n",
    "decay_rate = 0.7\n",
    "\n",
    "cos_scheduler = keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate, decay_steps)\n",
    "\n",
    "exp_scheduler = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps, decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure the model for training.\n",
    "\n",
    "# We use the \"sparse\" version of categorical_crossentropy\n",
    "# because our target data is integers.\n",
    "# See also:\n",
    "# loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=[dice_coef])\n",
    "\n",
    "callbacks = [\n",
    "    #keras.callbacks.LearningRateScheduler(exp_scheduler),\n",
    "    keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AND NOW, LET'S TRAIN!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_CHECKPOINT:\n",
    "    # Loads the weights\n",
    "    model.load_weights(prev_checkpoint_path)\n",
    "    print(f'model loaded weights from {prev_checkpoint_path}')\n",
    "\n",
    "if TRAIN:\n",
    "    # Train the model, doing validation at the end of each epoch.\n",
    "    history = model.fit(\n",
    "        tf_train_set, epochs=Config.num_epochs, validation_data=tf_valid_set, callbacks=callbacks,\n",
    "        workers=4, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    print('History', history.history.keys())\n",
    "\n",
    "    for var, yrange in [('loss', [0.0, 0.02]),\n",
    "                        ('dice_coef', [0.0, 0.8])]:\n",
    "        plt.figure(figsize=(10, 3))\n",
    "        plt.plot(history.history[var])\n",
    "        plt.plot(history.history[f'val_{var}'])\n",
    "        plt.ylim(yrange[0], yrange[1])\n",
    "        plt.title(f'model {var}')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel(var)\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(pred, threshold):\n",
    "    return (pred > threshold).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATE = True\n",
    "ALL_BATCHES = True\n",
    "BATCH_IDX = 0\n",
    "SAMPLE_IDX = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVALUATE:    \n",
    "    # Evaluate the model\n",
    "\n",
    "    if ALL_BATCHES:\n",
    "        loss, acc = model.evaluate(partial_set, verbose=2)\n",
    "    else:\n",
    "        eval_images, eval_masks = partial_set[BATCH_IDX]\n",
    "        loss, acc = model.evaluate(eval_images, eval_masks, verbose=2)\n",
    "\n",
    "    print(\"Model accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dice_coef(sample_set, pred_set, batch_size, threshold):\n",
    "    dice_coef_per_batch = np.full(len(sample_set), np.nan)\n",
    "    for idx in range(len(sample_set)):\n",
    "        x, y = sample_set[idx]\n",
    "        pred = pred_set[idx*batch_size:(idx + 1)*batch_size]\n",
    "        _coef = dice_coef(y, pred, threshold=threshold)\n",
    "        dice_coef_per_batch[idx] = _coef\n",
    "    return dice_coef_per_batch\n",
    "\n",
    "if EVALUATE:\n",
    "    \n",
    "    predictions = model.predict(partial_set)\n",
    "    \n",
    "    _coefs = eval_dice_coef(\n",
    "        partial_set, predictions, batch_size=partial_set.batch_size, threshold=None)\n",
    "    print(f'w/o threshold: {_coefs.mean():.2%}')\n",
    "    \n",
    "    if Config.threshold == 'auto':\n",
    "        best_coef = 0.\n",
    "        for threshold in np.arange(0.1, 0.8, 0.1):\n",
    "            _coefs = eval_dice_coef(\n",
    "                partial_set, predictions, batch_size=partial_set.batch_size, threshold=threshold)\n",
    "            mean_coef = _coefs.mean()\n",
    "            if mean_coef > best_coef:\n",
    "                best_coef = mean_coef\n",
    "                best_thresh = threshold\n",
    "            print(f'{threshold:.02} threshold: {mean_coef:.2%}')\n",
    "        print(f'best_threshold = {best_thresh:.02}')\n",
    "        Config.threshold = best_thresh\n",
    "        print('Config.threshold updated')\n",
    "    else:\n",
    "        threshold = Config.threshold\n",
    "        _coefs = eval_dice_coef(\n",
    "            partial_set, predictions, batch_size=partial_set.batch_size, threshold=threshold)\n",
    "        mean_coef = _coefs.mean()\n",
    "        print(f'{threshold:.02} threshold: {mean_coef:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(img, truth, pred):\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(16, 8))\n",
    "\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].set_title(\"Ash Color Image\")\n",
    "\n",
    "    axs[1].imshow(truth)\n",
    "    axs[1].set_title(\"Ground Truth\")\n",
    "\n",
    "    axs[2].imshow(pred)\n",
    "    axs[2].set_title(\"Prediction\")\n",
    "\n",
    "    axs[3].imshow(img)\n",
    "    axs[3].imshow(truth, cmap='Reds', alpha=.3, interpolation='none')\n",
    "    axs[3].set_title('Contrail mask on ash color image')\n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "if EVALUATE:\n",
    "    eval_images, eval_masks = partial_set[BATCH_IDX]\n",
    "    idx = SAMPLE_IDX\n",
    "    threshold = Config.threshold\n",
    "    plot_prediction(\n",
    "        eval_images[idx], eval_masks[idx], apply_threshold(predictions[idx], threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(x, fg_val=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x:  numpy array of shape (height, width), 1 - mask, 0 - background\n",
    "    Returns: run length encoding as list\n",
    "    \"\"\"\n",
    "\n",
    "    dots = np.where(\n",
    "        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if b > prev + 1:\n",
    "            run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "\n",
    "def list_to_string(x):\n",
    "    \"\"\"\n",
    "    Converts list to a string representation\n",
    "    Empty list returns '-'\n",
    "    \"\"\"\n",
    "    if x: # non-empty list\n",
    "        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n",
    "    else:\n",
    "        s = '-'\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recs = os.listdir(os.path.join(DATA_DIR, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'), index_col='record_id')[0:0]\n",
    "\n",
    "for test_id, pred in zip(test_ids, predictions):\n",
    "    \n",
    "    mask = apply_threshold(pred, Config.threshold)\n",
    "    \n",
    "    # notice the we're converting rec to an `int` here:\n",
    "    submission.loc[int(test_id), 'encoded_pixels'] = list_to_string(rle_encode(mask))\n",
    "    \n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strf_timedelta(timedelta):\n",
    "    total_seconds = timedelta.total_seconds()\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return '{:02}:{:02}:{:02}'.format(int(hours), int(minutes), int(seconds))\n",
    "\n",
    "end_time = datetime.datetime.now(timezone('CET'))\n",
    "\n",
    "print('Terminated', end_time.strftime(PRINT_TIME_FORMAT),\n",
    "      'in', strf_timedelta(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS THE END!"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
