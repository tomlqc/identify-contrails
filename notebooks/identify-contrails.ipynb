{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Identify Contrails with Keras","metadata":{}},{"cell_type":"code","source":"# reinstall tensorflow-io\n# to avoid the UserWarning: unable to load libtensorflow_io_plugins.so\n\n#!pip install tensorflow-io","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"import os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ==============================\n\nTRAIN = True\n\nif os.path.exists('/kaggle'):\n    PLATFORM = 'kaggle'\nelse:\n    PLATFORM = 'gcp'\n\n# ==============================\n\nprint(f'PLATFORM = {PLATFORM}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if PLATFORM == 'kaggle':\n\n    WORK_DIR = '/kaggle/working'  # preserved if notebook is saved\n    TEMP_DIR = '/kaggle/temp'  # just during current session\n\n    DATA_DIR = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n\n    # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n    # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nelif PLATFORM == 'gcp':\n\n    WORK_DIR = '/home/jupyter/kaggle/working'  # preserved if notebook is saved\n    TEMP_DIR = '/home/jupyter/kaggle/temp'  # just during current session\n\n    DATA_DIR = '/home/jupyter/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n    \n    %cd $WORK_DIR\n\nprint('PWD =', os.getcwd())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UPDATE_DATA = False\n\nif UPDATE_DATA:\n    %cp -v /kaggle/input/identify-contrails/contrails_2023*.h5 .","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not TRAIN:\n    checkpoint_path = 'contrails_2023-07-15_15-10-49.h5'\n    print(f'checkpoint_path = {checkpoint_path}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport datetime\nimport math\nimport pathlib\nimport random\nimport shutil\n\nfrom pytz import timezone\n\nfrom tqdm.notebook import tqdm\n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport scipy","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PRINT_TIME_FORMAT = \"%Y-%m-%d %H:%M:%S %Z%z\"\nFILE_TIME_FORMAT = \"%Y-%m-%d_%H-%M-%S\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"now_time = datetime.datetime.now(timezone('CET'))\n\nfile_time_str = now_time.strftime(FILE_TIME_FORMAT)\n\nprint('Started', now_time.strftime(PRINT_TIME_FORMAT))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import backend as backend","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('TensorFlow version:', tf.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#---------------------------------------------------------------------------79","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"class Paths:\n    train = os.path.join(DATA_DIR, 'train')\n    valid = os.path.join(DATA_DIR, 'validation')\n    test = os.path.join(DATA_DIR, 'test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sort_list = list  # list | sorted  # <DEVEL>\n\ntrain_ids = sort_list(os.listdir(Paths.train))\nvalid_ids = sort_list(os.listdir(Paths.valid))\ntest_ids = sort_list(os.listdir(Paths.test))\nprint('n_samples (train, validation, test) =', len(train_ids), len(valid_ids), len(test_ids))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ABI:\n    bands = {name: idx for idx, name in enumerate([\n        '08', '09', '10', '11', '12', '13', '14', '15', '16'])}\n    colors = {name: idx for idx, name in enumerate([\n        'red', 'blue', 'green', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'black'])}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_TIMES_BEFORE = 4\nN_TIMES_AFTER = 3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_range(data, bounds):\n    \"\"\"Maps data to the range [0, 1].\"\"\"\n    return (data - bounds[0]) / (bounds[1] - bounds[0])\n\n_T11_BOUNDS = (243, 303)\n_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n_TDIFF_BOUNDS = (-4, 2)\n\ndef get_ash_colors(sample_id, split_dir):\n    \"\"\"\n    Based on bands: 11, 14, 15\n    \n    Args:\n        sample_id(str): The id of the example i.e. '1000216489776414077'\n        split_dir(str): The split directoryu i.e. 'test', 'train', 'val'\n    \"\"\"\n    band15 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_15.npy\")\n    band14 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_14.npy\")\n    band11 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_11.npy\")\n\n    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)\n    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n    b = normalize_range(band14, _T11_BOUNDS)\n    ash_colors = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n    \n    return ash_colors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_individual_mask(sample_id, split_dir):\n    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_individual_masks.npy\"\n    pixel_mask = np.load(masks_path)\n    return pixel_mask\n\ndef get_pixel_mask(sample_id, split_dir):\n    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_pixel_masks.npy\"\n    pixel_mask = np.load(masks_path)\n    return pixel_mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check some values (DEVEL)","metadata":{}},{"cell_type":"code","source":"sample_id = train_ids[3]\n\nash_colors = get_ash_colors(sample_id, 'train')[..., N_TIMES_BEFORE]\n\nprint(ash_colors.shape)\nfor color in range(3):\n    array = ash_colors[..., color]\n    print(array.min(), array.max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pixel_mask = get_pixel_mask(sample_id, 'train')\n\nprint(pixel_mask.shape)\nprint(pixel_mask.min(), pixel_mask.max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"execution":{"iopub.execute_input":"2023-07-10T19:30:33.222846Z","iopub.status.busy":"2023-07-10T19:30:33.222338Z","iopub.status.idle":"2023-07-10T19:30:33.228013Z","shell.execute_reply":"2023-07-10T19:30:33.227016Z","shell.execute_reply.started":"2023-07-10T19:30:33.222811Z"}}},{"cell_type":"code","source":"SEED = 42","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    \n    img_size = (256, 256)\n    \n    model = 'unet'\n    \n    num_epochs = 3  # <DEVEL> else 10\n    num_classes = 1\n    batch_size = 16  # <DEVEL> else 16 or 32\n    \n    threshold = 0.40\n    \n    seed = SEED","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://keras.io/examples/keras_recipes/reproducibility_recipes/\n\n# Set the seed using keras.utils.set_random_seed. This will set:\n# 1) `numpy` seed\n# 2) `tensorflow` random seed\n# 3) `python` random seed\nkeras.utils.set_random_seed(Config.seed)\n\n# See also:\n# tf.config.experimental.enable_op_determinism()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet:\n    '''U-Net model.\n    \n    Inspired by and adapted from:\n    - https://keras.io/examples/vision/oxford_pets_image_segmentation\n    - https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580\n    - https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow/home/week/3\n    '''\n    \n    @classmethod\n    def conv2d_block(cls, input_tensor, n_filters, kernel_size=3):\n        x = input_tensor\n        for i in range(2):\n            x = tf.keras.layers.SeparableConv2D(\n                filters = n_filters, kernel_size=(kernel_size, kernel_size), padding='same')(x)\n            #? kernel_initializer = 'he_normal'\n            x = tf.keras.layers.BatchNormalization()(x)\n            x = tf.keras.layers.Activation('relu')(x)\n        return x\n\n    @classmethod\n    def encoder_block(cls, inputs, n_filters, pool_size, dropout):\n        f = cls.conv2d_block(inputs, n_filters=n_filters)\n        p = tf.keras.layers.MaxPooling2D(pool_size)(f)\n        p = tf.keras.layers.Dropout(dropout)(p)\n        return f, p\n\n    @classmethod\n    def encoder(cls, inputs, dropout=0.1):\n        f1, p1 = cls.encoder_block(inputs, n_filters=64, pool_size=(2,2), dropout=dropout)\n        f2, p2 = cls.encoder_block(p1, n_filters=128, pool_size=(2,2), dropout=dropout)\n        f3, p3 = cls.encoder_block(p2, n_filters=256, pool_size=(2,2), dropout=dropout)\n        f4, p4 = cls.encoder_block(p3, n_filters=512, pool_size=(2,2), dropout=dropout)\n        return p4, (f1, f2, f3, f4)\n\n    @classmethod\n    def bottleneck(cls, inputs):\n        bottle_neck = cls.conv2d_block(inputs, n_filters=1024)\n        return bottle_neck\n\n    @classmethod\n    def decoder_block(cls, inputs, conv_output, n_filters, kernel_size, strides, dropout):\n        u = tf.keras.layers.Conv2DTranspose(\n            n_filters, kernel_size, strides=strides, padding = 'same')(inputs)\n        u = tf.keras.layers.BatchNormalization()(u)\n        c = tf.keras.layers.concatenate([u, conv_output])\n        c = tf.keras.layers.Dropout(dropout)(c)\n        c = cls.conv2d_block(c, n_filters, kernel_size=3)\n        return c\n\n    @classmethod\n    def decoder(cls, inputs, convs, num_classes, dropout=0.1):\n        f1, f2, f3, f4 = convs\n        c6 = cls.decoder_block(inputs, f4, n_filters=512, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        c7 = cls.decoder_block(c6, f3, n_filters=256, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        c8 = cls.decoder_block(c7, f2, n_filters=128, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        c9 = cls.decoder_block(c8, f1, n_filters=64, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        if num_classes == 1:\n            activation = \"sigmoid\"\n        else:\n            activation = \"softmax\"\n        outputs = layers.Conv2D(num_classes, kernel_size=3, activation=activation, padding=\"same\")(c9)\n        return outputs\n\n    @classmethod\n    def model(cls, image_size, num_classes):\n        inputs = tf.keras.layers.Input(shape=(image_size,image_size,3))\n        encoder_output, convs = cls.encoder(inputs)\n        #model = tf.keras.Model(inputs=inputs, outputs=encoder_output)  # debug\n        bottle_neck = cls.bottleneck(encoder_output)\n        outputs = cls.decoder(bottle_neck, convs, num_classes)\n        model = tf.keras.Model(name=cls.__name__, inputs=inputs, outputs=outputs)\n        return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DeepLabV3Plus:\n    '''DeepLabV3+ model.\n    \n    Adapted from:\n    - https://keras.io/examples/vision/deeplabv3_plus/#inference-using-colormap-overlay\n    '''\n    \n    @classmethod\n    def convolution_block(\n        cls,\n        block_input,\n        num_filters=256,\n        kernel_size=3,\n        dilation_rate=1,\n        padding=\"same\",\n        use_bias=False,\n    ):\n        x = layers.Conv2D(\n            num_filters,\n            kernel_size=kernel_size,\n            dilation_rate=dilation_rate,\n            padding=\"same\",\n            use_bias=use_bias,\n            kernel_initializer=keras.initializers.HeNormal(),\n        )(block_input)\n        x = layers.BatchNormalization()(x)\n        return tf.nn.relu(x)\n\n    @classmethod\n    def DilatedSpatialPyramidPooling(cls, dspp_input):\n        dims = dspp_input.shape\n        x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n        x = cls.convolution_block(x, kernel_size=1, use_bias=True)\n        out_pool = layers.UpSampling2D(\n            size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n        )(x)\n\n        out_1 = cls.convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n        out_6 = cls.convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n        out_12 = cls.convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n        out_18 = cls.convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n\n        x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n        output = cls.convolution_block(x, kernel_size=1)\n        return output\n    \n    @classmethod\n    def model(cls, image_size, num_classes, weights):\n        \n        model_input = keras.Input(shape=(image_size, image_size, 3))\n        \n        resnet50 = keras.applications.ResNet50(\n            weights=weights, include_top=False, input_tensor=model_input,\n        )\n        resnet50.trainable = False\n        print('resnet50.trainable =', resnet50.trainable)\n        \n        x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n        x = cls.DilatedSpatialPyramidPooling(x)\n\n        input_a = layers.UpSampling2D(\n            size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n            interpolation=\"bilinear\",\n        )(x)\n        input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n        input_b = cls.convolution_block(input_b, num_filters=48, kernel_size=1)\n\n        x = layers.Concatenate(axis=-1)([input_a, input_b])\n        x = cls.convolution_block(x)\n        x = cls.convolution_block(x)\n        x = layers.UpSampling2D(\n            size=(image_size // x.shape[1], image_size // x.shape[2]),\n            interpolation=\"bilinear\",\n        )(x)\n        \n        if num_classes == 1:\n            activation = \"sigmoid\"\n        else:\n            activation = \"softmax\"\n        model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), activation=activation, padding=\"same\")(x)\n        \n        return keras.Model(name=cls.__name__, inputs=model_input, outputs=model_output)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import tensorflow_hub as hub\n#\n#model = tf.keras.Sequential([\n#    keras.Input(shape=(224, 224, 3)),\n#    hub.KerasLayer(\"/kaggle/input/resnet-50/tensorflow2/feature-vector/1\",\n#       trainable=False)\n#])\n#    \n#model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Free up RAM in case the model definition cells were run multiple times\nkeras.backend.clear_session()\n\n\n# Build model\nif Config.model == 'unet':\n    model = UNet.model(image_size=256, num_classes=1)\n    PREPROCESS = None\n\nelif Config.model == 'deeplabv3plus':\n    resnet50_weights_path = '/kaggle/input/d/alexisbcook/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n    model = DeepLabV3Plus.model(image_size=256, num_classes=1, weights=resnet50_weights_path)\n    PREPROCESS = 'resnet50'\n\nelse:\n    raise NotImplementedError(f'model \"{Config.model}\"')\n    \nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare datasets","metadata":{"execution":{"iopub.execute_input":"2023-07-10T19:30:33.222846Z","iopub.status.busy":"2023-07-10T19:30:33.222338Z","iopub.status.idle":"2023-07-10T19:30:33.228013Z","shell.execute_reply":"2023-07-10T19:30:33.227016Z","shell.execute_reply.started":"2023-07-10T19:30:33.222811Z"}}},{"cell_type":"code","source":"N_SAMPLES = None  # <DEVEL> None to take all\nN_PARTIAL = 128  # 128","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AshColorSingleFrames(keras.utils.Sequence):\n    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n\n    def __init__(self, batch_size, img_size, sample_ids, split_dir, preprocess=None, n_samples=None):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.split_dir = split_dir\n        self.sample_ids = sample_ids[:n_samples]\n        self.preprocess = preprocess\n\n    def __len__(self):\n        return math.ceil(len(self.sample_ids) / self.batch_size)\n\n    def __getitem__(self, idx):\n        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n        i = idx * self.batch_size\n        batch_sample_ids = self.sample_ids[i : i + self.batch_size]\n        \n        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n        for j, sample_id in enumerate(batch_sample_ids):\n            \n            img = get_ash_colors(sample_id, self.split_dir)[..., N_TIMES_BEFORE]\n            \n            if self.preprocess == 'resnet50':\n                img = keras.applications.resnet50.preprocess_input(img)\n            elif self.preprocess is not None:\n                raise NotImplementedError(f'preprocess \"{preprocess}\"')\n            \n            x[j] = img\n\n        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n        if self.split_dir != 'test':\n            for j, sample_id in enumerate(batch_sample_ids):\n                img = get_pixel_mask(sample_id, self.split_dir)\n                y[j] = img\n        \n        return x, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = AshColorSingleFrames(\n    Config.batch_size, Config.img_size, train_ids, 'train',\n    preprocess=PREPROCESS, n_samples=N_SAMPLES)  # <DEVEL>\nprint('number of batches:', len(train_set))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_set = AshColorSingleFrames(\n    Config.batch_size, Config.img_size, valid_ids, 'validation',\n    preprocess=PREPROCESS, n_samples=N_SAMPLES)  # <DEVEL>\nprint('number of batches:', len(valid_set))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"partial_set = AshColorSingleFrames(\n    Config.batch_size, Config.img_size, valid_ids, 'validation',\n    preprocess=PREPROCESS, n_samples=N_PARTIAL)  # <DEVEL>\nprint('number of batches:', len(partial_set))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set = AshColorSingleFrames(\n    Config.batch_size, Config.img_size, test_ids, 'test',\n    preprocess=PREPROCESS)\nprint('number of batches:', len(test_set))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check batch dimensions (x, y):\n\ntrain_set[0][0].shape, train_set[0][1].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=0.001, threshold=None):\n    '''Dice coefficient.\n    \n    Adapted from:\n    - https://stackoverflow.com/questions/72195156/correct-implementation-of-dice-loss-in-tensorflow-keras\n    - https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580\n    '''\n    \n    y_true_f = backend.flatten(tf.cast(y_true, tf.float32))\n    y_pred_f = backend.flatten(tf.cast(y_pred, tf.float32))\n    # ValueError: No gradients provided for any variable\n    if threshold is not None:\n        y_pred_f = backend.flatten(\n            tf.cast(tf.math.greater(tf.cast(y_pred, tf.float32), threshold), tf.float32))\n    intersection = backend.sum(y_true_f * y_pred_f)\n    dice = (2. * intersection + smooth) / (backend.sum(y_true_f) + backend.sum(y_pred_f) + smooth)\n    return dice\n\ndef threshold_dice_coef(y_true, y_pred, smooth=0.001):\n    return dice_coef(y_true, y_pred, smooth=smooth, threshold=Config.threshold)\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_id = train_ids[3]\n\nprint(f'Check `dice_coef()` on one of the samples: {sample_id}')\n\nmerged_mask = get_pixel_mask(sample_id, 'train')\nindiv_masks = get_individual_mask(sample_id, 'train')\n\nprint(dice_coef(tf.convert_to_tensor(merged_mask),\n                tf.convert_to_tensor(merged_mask)))\nfor idv in range(6):\n    print(dice_coef(tf.convert_to_tensor(merged_mask),\n                    tf.convert_to_tensor(indiv_masks[..., idv])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    checkpoint_path = f\"contrails_{file_time_str}.h5\"\n\nprint(f'checkpoint file: {checkpoint_path}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learning rate scheduler:\n# - https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules\n# - https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecay\n# Note: CosineDecay got warmup in v2.13.1\n\ninitial_learning_rate = 0.01\ndecay_steps = len(train_set)\ndecay_rate = 0.7\n\ncos_scheduler = keras.optimizers.schedules.CosineDecay(\n    initial_learning_rate, decay_steps)\n\nexp_scheduler = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate, decay_steps, decay_rate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configure the model for training.\n\n# We use the \"sparse\" version of categorical_crossentropy\n# because our target data is integers.\n# See also:\n# loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\nmodel.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=[dice_coef])\n#model.compile(optimizer=\"adam\", loss=dice_loss, metrics=[dice_coef])\n\ncallbacks = [\n    #keras.callbacks.LearningRateScheduler(exp_scheduler),\n    keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True)\n]","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    # Train the model, doing validation at the end of each epoch.\n    history = model.fit(\n        train_set, epochs=Config.num_epochs, validation_data=valid_set, callbacks=callbacks,\n        workers=4, use_multiprocessing=True)\nelse:\n    # Loads the weights\n    model.load_weights(checkpoint_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    print('History', history.history.keys())\n\n    for var in ['loss', 'val_loss', 'dice_coef', 'val_dice_coef']:\n        plt.figure(figsize=(10, 3))\n        plt.plot(history.history[var])\n        plt.title(f'model {var}')\n        plt.ylabel(var)\n        plt.xlabel('epoch')\n        plt.legend(['train', 'val'], loc='upper left')\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"def apply_threshold(pred, threshold):\n    return (pred > threshold).astype(np.int32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not TRAIN:    \n    # Evaluate the model\n\n    ALL_BATCHES = True\n    BATCH_IDX = 0\n    SAMPLE_IDX = 1\n\n    if ALL_BATCHES:\n        loss, acc = model.evaluate(partial_set, verbose=2)\n    else:\n        eval_images, eval_masks = partial_set[BATCH_IDX]\n        loss, acc = model.evaluate(eval_images, eval_masks, verbose=2)\n\n    print(\"Saved model, accuracy: {:5.2f}%\".format(100 * acc))\n\n    predictions = model.predict(partial_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_dice_coef(sample_set, pred_set, batch_size, threshold):\n    dice_coef_per_batch = np.full(len(sample_set), np.nan)\n    for idx in range(len(sample_set)):\n        x, y = sample_set[idx]\n        pred = pred_set[idx*batch_size:(idx + 1)*batch_size]\n        _coef = dice_coef(y, pred, threshold=threshold)\n        dice_coef_per_batch[idx] = _coef\n    return dice_coef_per_batch\n\nif not TRAIN:\n    _coefs = eval_dice_coef(\n        partial_set, predictions, batch_size=partial_set.batch_size, threshold=None)\n    print(f'w/o threshod: {_coefs.mean():.2%}')\n\n    _coefs = eval_dice_coef(\n        partial_set, predictions, batch_size=partial_set.batch_size, threshold=Config.threshold)\n    print(f'{Config.threshold}: {_coefs.mean():.2%}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_prediction(img, truth, pred):\n\n    fig, axs = plt.subplots(1, 4, figsize=(16, 8))\n\n    axs[0].imshow(img)\n    axs[0].set_title(\"Ash Color Image\")\n\n    axs[1].imshow(truth)\n    axs[1].set_title(\"Ground Truth\")\n\n    axs[2].imshow(pred)\n    axs[2].set_title(\"Prediction\")\n\n    axs[3].imshow(img)\n    axs[3].imshow(truth, cmap='Reds', alpha=.3, interpolation='none')\n    axs[3].set_title('Contrail mask on ash color image')\n\n    plt.tight_layout() \n    plt.show()\n\n    return\n\nif not TRAIN:\n    eval_images, eval_masks = partial_set[BATCH_IDX]\n    idx = SAMPLE_IDX\n    threshold = Config.threshold\n    plot_prediction(\n        eval_images[idx], eval_masks[idx], apply_threshold(predictions[idx], threshold))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make predictions on test dataset","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(test_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create a submission","metadata":{}},{"cell_type":"code","source":"def rle_encode(x, fg_val=1):\n    \"\"\"\n    Args:\n        x:  numpy array of shape (height, width), 1 - mask, 0 - background\n    Returns: run length encoding as list\n    \"\"\"\n\n    dots = np.where(\n        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if b > prev + 1:\n            run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\n\ndef list_to_string(x):\n    \"\"\"\n    Converts list to a string representation\n    Empty list returns '-'\n    \"\"\"\n    if x: # non-empty list\n        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n    else:\n        s = '-'\n    return s\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_recs = os.listdir(os.path.join(DATA_DIR, 'test'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'), index_col='record_id')[0:0]\n\nfor test_id, pred in zip(test_ids, predictions):\n    \n    mask = apply_threshold(pred, Config.threshold)\n    \n    # notice the we're converting rec to an `int` here:\n    submission.loc[int(test_id), 'encoded_pixels'] = list_to_string(rle_encode(mask))\n    \nsubmission.to_csv('submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Terminated', datetime.datetime.now(timezone('CET')).strftime(PRINT_TIME_FORMAT))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"THIS IS THE END!","metadata":{}}]}