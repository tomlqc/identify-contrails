{"metadata":{"environment":{"kernel":"python3","name":"tf2-gpu.2-11.m109","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Identify Contrails with Keras","metadata":{}},{"cell_type":"code","source":"# reinstall tensorflow-io\n# to avoid the UserWarning: unable to load libtensorflow_io_plugins.so\n\n#!pip install tensorflow-io","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-07-27T20:15:25.351181Z","iopub.execute_input":"2023-07-27T20:15:25.351554Z","iopub.status.idle":"2023-07-27T20:15:25.357140Z","shell.execute_reply.started":"2023-07-27T20:15:25.351525Z","shell.execute_reply":"2023-07-27T20:15:25.355913Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:25.362798Z","iopub.execute_input":"2023-07-27T20:15:25.363252Z","iopub.status.idle":"2023-07-27T20:15:25.372109Z","shell.execute_reply.started":"2023-07-27T20:15:25.363215Z","shell.execute_reply":"2023-07-27T20:15:25.370740Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# ==============================\n\nLOAD_CHECKPOINT = False  # <DEVEL>\nTRAIN = True  # <DEVEL>\n\nif os.path.exists('/kaggle'):\n    PLATFORM = 'kaggle'\nelse:\n    PLATFORM = 'gcp'\n\n# ==============================\n\nprint(f'PLATFORM = {PLATFORM}')\nprint()\nprint(f'LOAD_CHECKPOINT = {LOAD_CHECKPOINT}')\nprint(f'TRAIN = {TRAIN}')","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:25.382863Z","iopub.execute_input":"2023-07-27T20:15:25.383608Z","iopub.status.idle":"2023-07-27T20:15:25.391042Z","shell.execute_reply.started":"2023-07-27T20:15:25.383571Z","shell.execute_reply":"2023-07-27T20:15:25.389932Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"PLATFORM = kaggle\n\nLOAD_CHECKPOINT = False\nTRAIN = True\n","output_type":"stream"}]},{"cell_type":"code","source":"if PLATFORM == 'kaggle':\n\n    WORK_DIR = '/kaggle/working'  # preserved if notebook is saved\n    TEMP_DIR = '/kaggle/temp'  # just during current session\n\n    DATA_DIR = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n    \n    WEIGHTS_DIR = WORK_DIR\n    \n    resnet50_imagenet_weights =\\\n        '/kaggle/input/d/alexisbcook/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n    # You can write up to 20GB to the current directory (/kaggle/working/)\n    # that gets preserved as output when you create a version using \"Save & Run All\" \n    # You can also write temporary files to /kaggle/temp/,\n    # but they won't be saved outside of the current session\n\nelif PLATFORM == 'gcp':\n\n    WORK_DIR = '/home/jupyter/kaggle/working'  # preserved if notebook is saved\n    TEMP_DIR = '/home/jupyter/kaggle/temp'  # just during current session\n\n    DATA_DIR = '/home/jupyter/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n    \n    WEIGHTS_DIR = '/home/jupyter/identify-contrails-models'\n    \n    resnet50_imagenet_weights = 'imagenet'\n    \n    %cd $WORK_DIR\n    \nelse:\n    raise NotImplementedError(f'unknown platform \"{PLATFORM}\"')\n\nprint('PWD =', os.getcwd())","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:25.396454Z","iopub.execute_input":"2023-07-27T20:15:25.396817Z","iopub.status.idle":"2023-07-27T20:15:25.410364Z","shell.execute_reply.started":"2023-07-27T20:15:25.396787Z","shell.execute_reply":"2023-07-27T20:15:25.409192Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"PWD = /kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"UPDATE_DATA = False\n\nif UPDATE_DATA:\n    %cp -v /kaggle/input/identify-contrails/identify-contrails_2023*.h5 .\n    %ll","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:25.412039Z","iopub.execute_input":"2023-07-27T20:15:25.413003Z","iopub.status.idle":"2023-07-27T20:15:25.433286Z","shell.execute_reply.started":"2023-07-27T20:15:25.412958Z","shell.execute_reply":"2023-07-27T20:15:25.431769Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"if LOAD_CHECKPOINT:\n    prev_checkpoint_path = os.path.join(WEIGHTS_DIR, 'identify-contrails_2023-07-22_16-22-01.h5')  # <DEVEL>\n    print(f'prev_checkpoint_path = {prev_checkpoint_path}')\n    if not os.path.exists(prev_checkpoint_path):\n        raise IOError(f'file does not exist {prev_checkpoint_path}')","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:25.435583Z","iopub.execute_input":"2023-07-27T20:15:25.436077Z","iopub.status.idle":"2023-07-27T20:15:25.446337Z","shell.execute_reply.started":"2023-07-27T20:15:25.436033Z","shell.execute_reply":"2023-07-27T20:15:25.445018Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"!touch submission.csv\n%ll -h","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:25.503467Z","iopub.execute_input":"2023-07-27T20:15:25.504410Z","iopub.status.idle":"2023-07-27T20:15:27.767621Z","shell.execute_reply.started":"2023-07-27T20:15:25.504374Z","shell.execute_reply":"2023-07-27T20:15:27.766113Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"total 3.1G\n-rw-r--r-- 1 root  263 Jul 27 19:45 __notebook_source__.ipynb\n-rw-r--r-- 1 root 109M Jul 27 19:45 contrails_2023-07-15_15-10-49.h5\n-rw-r--r-- 1 root 109M Jul 27 19:45 contrails_2023-07-19_22-57-53.h5\n-rw-r--r-- 1 root 137M Jul 27 19:45 contrails_2023-07-20_00-27-12.h5\n-rw-r--r-- 1 root  73M Jul 27 19:45 contrails_2023-07-20_09-33-34.h5\n-rw-r--r-- 1 root 109M Jul 27 19:45 contrails_2023-07-20_13-06-15.h5\n-rw-r--r-- 1 root 137M Jul 27 19:45 contrails_2023-07-20_22-06-31.h5\n-rw-r--r-- 1 root 137M Jul 27 19:45 contrails_2023-07-20_22-39-56.h5\n-rw-r--r-- 1 root 137M Jul 27 19:45 contrails_2023-07-21_10-01-58.h5\n-rw-r--r-- 1 root 109M Jul 27 19:45 contrails_2023-07-21_23-31-01.h5\n-rw-r--r-- 1 root 109M Jul 27 19:45 contrails_2023-07-21_23-54-37.h5\n-rw-r--r-- 1 root 137M Jul 27 19:45 contrails_2023-07-22_21-49-00.h5\n-rw-r--r-- 1 root 137M Jul 27 19:45 contrails_2023-07-23_11-22-39.h5\n-rw-r--r-- 1 root 137M Jul 27 19:45 contrails_2023-07-23_11-42-50.h5\n-rw-r--r-- 1 root 137M Jul 27 19:45 identify-contrails_2023-07-25_16-16-39.h5\n-rw-r--r-- 1 root  294 Jul 27 19:45 identify-contrails_2023-07-25_16-16-39_log.csv\n-rw-r--r-- 1 root 137M Jul 27 19:45 identify-contrails_2023-07-26_22-07-48.h5\n-rw-r--r-- 1 root  432 Jul 27 19:45 identify-contrails_2023-07-26_22-07-48_log.csv\n-rw-r--r-- 1 root 137M Jul 27 19:45 identify-contrails_2023-07-26_22-45-42.h5\n-rw-r--r-- 1 root  141 Jul 27 19:45 identify-contrails_2023-07-26_22-45-42_log.csv\n-rw-r--r-- 1 root 109M Jul 27 19:45 identify-contrails_2023-07-27_09-32-28.h5\n-rw-r--r-- 1 root  182 Jul 27 19:45 identify-contrails_2023-07-27_09-32-28_log.csv\n-rw-r--r-- 1 root 533M Jul 27 19:45 identify-contrails_2023-07-27_11-26-04.h5\n-rw-r--r-- 1 root  121 Jul 27 19:45 identify-contrails_2023-07-27_11-26-04_log.csv\n-rw-r--r-- 1 root 137M Jul 27 19:45 identify-contrails_2023-07-27_17-59-26.h5\n-rw-r--r-- 1 root  119 Jul 27 19:45 identify-contrails_2023-07-27_17-59-26_log.csv\n-rw-r--r-- 1 root 137M Jul 27 19:45 identify-contrails_2023-07-27_20-46-40.h5\n-rw-r--r-- 1 root  141 Jul 27 19:45 identify-contrails_2023-07-27_20-46-40_log.csv\n-rw-r--r-- 1 root 137M Jul 27 19:45 identify-contrails_2023-07-27_20-59-57.h5\n-rw-r--r-- 1 root  138 Jul 27 19:45 identify-contrails_2023-07-27_20-59-57_log.csv\n-rw-r--r-- 1 root 137M Jul 27 19:45 identify-contrails_2023-07-27_21-36-05.h5\n-rw-r--r-- 1 root  399 Jul 27 19:45 identify-contrails_2023-07-27_21-36-05_log.csv\n-rw-r--r-- 1 root   75 Jul 27 20:15 submission.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport datetime\nimport itertools\nimport math\nimport multiprocessing\nimport pathlib\nimport random\nimport shutil\n\nfrom pprint import pprint\nfrom pytz import timezone\nfrom tqdm.notebook import tqdm\n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport scipy","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-07-27T20:15:27.770714Z","iopub.execute_input":"2023-07-27T20:15:27.771147Z","iopub.status.idle":"2023-07-27T20:15:27.905490Z","shell.execute_reply.started":"2023-07-27T20:15:27.771106Z","shell.execute_reply":"2023-07-27T20:15:27.904263Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"PRINT_TIME_FORMAT = \"%Y-%m-%d %H:%M:%S %Z%z\"\nFILE_TIME_FORMAT = \"%Y-%m-%d_%H-%M-%S\"\n\nstart_time = datetime.datetime.now(timezone('CET'))\n\nfile_time_str = start_time.strftime(FILE_TIME_FORMAT)\n\nprint('Started', start_time.strftime(PRINT_TIME_FORMAT))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:27.906958Z","iopub.execute_input":"2023-07-27T20:15:27.907318Z","iopub.status.idle":"2023-07-27T20:15:27.960254Z","shell.execute_reply.started":"2023-07-27T20:15:27.907286Z","shell.execute_reply":"2023-07-27T20:15:27.959041Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Started 2023-07-27 22:15:27 CEST+0200\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import backend as backend\n\nAUTOTUNE = tf.data.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:27.961778Z","iopub.execute_input":"2023-07-27T20:15:27.962161Z","iopub.status.idle":"2023-07-27T20:15:38.328453Z","shell.execute_reply.started":"2023-07-27T20:15:27.962128Z","shell.execute_reply":"2023-07-27T20:15:38.327306Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"print('TensorFlow version:', tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:38.332595Z","iopub.execute_input":"2023-07-27T20:15:38.333710Z","iopub.status.idle":"2023-07-27T20:15:38.340313Z","shell.execute_reply.started":"2023-07-27T20:15:38.333670Z","shell.execute_reply":"2023-07-27T20:15:38.338832Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"TensorFlow version: 2.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nprint('cpu_count: ', multiprocessing.cpu_count())","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:38.342123Z","iopub.execute_input":"2023-07-27T20:15:38.342446Z","iopub.status.idle":"2023-07-27T20:15:38.364346Z","shell.execute_reply.started":"2023-07-27T20:15:38.342418Z","shell.execute_reply":"2023-07-27T20:15:38.362871Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Num CPUs Available:  1\nNum GPUs Available:  0\ncpu_count:  4\n","output_type":"stream"}]},{"cell_type":"code","source":"#---------------------------------------------------------------------------79","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:38.366141Z","iopub.execute_input":"2023-07-27T20:15:38.366642Z","iopub.status.idle":"2023-07-27T20:15:38.377818Z","shell.execute_reply.started":"2023-07-27T20:15:38.366607Z","shell.execute_reply":"2023-07-27T20:15:38.376789Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Dataset utils","metadata":{}},{"cell_type":"code","source":"class Paths:\n    train = os.path.join(DATA_DIR, 'train')\n    valid = os.path.join(DATA_DIR, 'validation')\n    test = os.path.join(DATA_DIR, 'test')","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:38.379031Z","iopub.execute_input":"2023-07-27T20:15:38.379387Z","iopub.status.idle":"2023-07-27T20:15:38.394593Z","shell.execute_reply.started":"2023-07-27T20:15:38.379355Z","shell.execute_reply":"2023-07-27T20:15:38.393048Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_ids = sorted(os.listdir(Paths.train))\nvalid_ids = sorted(os.listdir(Paths.valid))\ntest_ids = sorted(os.listdir(Paths.test))\nprint('n_samples (train, validation, test) =', len(train_ids), len(valid_ids), len(test_ids))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:38.396276Z","iopub.execute_input":"2023-07-27T20:15:38.396738Z","iopub.status.idle":"2023-07-27T20:15:39.023650Z","shell.execute_reply.started":"2023-07-27T20:15:38.396702Z","shell.execute_reply":"2023-07-27T20:15:39.022467Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"n_samples (train, validation, test) = 20529 1856 2\n","output_type":"stream"}]},{"cell_type":"code","source":"class ABI:\n    bands = {name: idx for idx, name in enumerate([\n        '08', '09', '10', '11', '12', '13', '14', '15', '16'])}\n    colors = {name: idx for idx, name in enumerate([\n        'red', 'blue', 'green', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'black'])}","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:39.025582Z","iopub.execute_input":"2023-07-27T20:15:39.026338Z","iopub.status.idle":"2023-07-27T20:15:39.035610Z","shell.execute_reply.started":"2023-07-27T20:15:39.026296Z","shell.execute_reply":"2023-07-27T20:15:39.034345Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"N_TIMES_BEFORE = 4\nN_TIMES_AFTER = 3\nN_TIMES = N_TIMES_BEFORE + N_TIMES_AFTER + 1","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:15:39.037193Z","iopub.execute_input":"2023-07-27T20:15:39.037572Z","iopub.status.idle":"2023-07-27T20:15:39.050797Z","shell.execute_reply.started":"2023-07-27T20:15:39.037542Z","shell.execute_reply":"2023-07-27T20:15:39.049401Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"N_FRAMES = 5  # <DEVEL> centered around N_TIMES_BEFORE\nN_FRAMES_BEFORE = int((N_FRAMES - 1) / 2)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:18:26.061928Z","iopub.execute_input":"2023-07-27T20:18:26.062395Z","iopub.status.idle":"2023-07-27T20:18:26.068405Z","shell.execute_reply.started":"2023-07-27T20:18:26.062359Z","shell.execute_reply":"2023-07-27T20:18:26.067030Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def normalize_range(data, bounds):\n    \"\"\"Maps data to the range [0, 1].\"\"\"\n    return (data - bounds[0]) / (bounds[1] - bounds[0])\n\n_T11_BOUNDS = (243, 303)\n_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n_TDIFF_BOUNDS = (-4, 2)\n\ndef get_ash_colors(sample_id, split_dir):\n    \"\"\"\n    Based on bands: 11, 14, 15\n    \n    Args:\n        sample_id(str): The id of the example i.e. '1000216489776414077'\n        split_dir(str): The split directoryu i.e. 'test', 'train', 'val'\n    \"\"\"\n    band15 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_15.npy\")\n    band14 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_14.npy\")\n    band11 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_11.npy\")\n\n    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)\n    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n    b = normalize_range(band14, _T11_BOUNDS)\n    ash_colors = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n    \n    return ash_colors","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:18:28.511762Z","iopub.execute_input":"2023-07-27T20:18:28.512198Z","iopub.status.idle":"2023-07-27T20:18:28.523041Z","shell.execute_reply.started":"2023-07-27T20:18:28.512163Z","shell.execute_reply":"2023-07-27T20:18:28.521491Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def get_individual_mask(sample_id, split_dir):\n    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_individual_masks.npy\"\n    pixel_mask = np.load(masks_path)\n    return pixel_mask\n\ndef get_pixel_mask(sample_id, split_dir):\n    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_pixel_masks.npy\"\n    pixel_mask = np.load(masks_path)\n    return pixel_mask","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:18:29.117279Z","iopub.execute_input":"2023-07-27T20:18:29.118710Z","iopub.status.idle":"2023-07-27T20:18:29.125761Z","shell.execute_reply.started":"2023-07-27T20:18:29.118661Z","shell.execute_reply":"2023-07-27T20:18:29.124534Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"**Check some values**","metadata":{}},{"cell_type":"code","source":"sample_id = 7829917977180135058  # train_ids[3]\n\nprint(f'Check `ash_colors` on one of the samples: {sample_id}')\n\nash_colors = get_ash_colors(sample_id, 'train')[..., N_TIMES_BEFORE]\n\nprint(ash_colors.shape)\nfor color in range(3):\n    array = ash_colors[..., color]\n    print(array.min(), array.max())","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:18:29.999712Z","iopub.execute_input":"2023-07-27T20:18:30.000136Z","iopub.status.idle":"2023-07-27T20:18:30.027612Z","shell.execute_reply.started":"2023-07-27T20:18:30.000095Z","shell.execute_reply":"2023-07-27T20:18:30.026314Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Check `ash_colors` on one of the samples: 7829917977180135058\n(256, 256, 3)\n0.0 0.50921124\n0.097476535 0.86938816\n0.031865694 0.81146187\n","output_type":"stream"}]},{"cell_type":"code","source":"pixel_mask = get_pixel_mask(sample_id, 'train')\n\nprint(pixel_mask.shape)\nprint(pixel_mask.min(), pixel_mask.max())","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:18:30.456091Z","iopub.execute_input":"2023-07-27T20:18:30.456714Z","iopub.status.idle":"2023-07-27T20:18:30.463759Z","shell.execute_reply.started":"2023-07-27T20:18:30.456678Z","shell.execute_reply":"2023-07-27T20:18:30.462399Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"(256, 256, 1)\n0 1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{"execution":{"iopub.execute_input":"2023-07-10T19:30:33.222846Z","iopub.status.busy":"2023-07-10T19:30:33.222338Z","iopub.status.idle":"2023-07-10T19:30:33.228013Z","shell.execute_reply":"2023-07-10T19:30:33.227016Z","shell.execute_reply.started":"2023-07-10T19:30:33.222811Z"}}},{"cell_type":"markdown","source":"### Config","metadata":{}},{"cell_type":"code","source":"SEED = 42","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:18:31.813902Z","iopub.execute_input":"2023-07-27T20:18:31.814346Z","iopub.status.idle":"2023-07-27T20:18:31.819322Z","shell.execute_reply.started":"2023-07-27T20:18:31.814308Z","shell.execute_reply":"2023-07-27T20:18:31.818043Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"class Config:  # <CONFIG>\n    \n    seed = SEED\n\n    img_size = (256, 256)\n    num_classes = 1\n    \n    augment = True\n    \n    model = 'p3dresnet'  # unet | deeplabv3plus | p3dresnet\n    preprocess = None  # 'resnet50' | None\n    backbone = 'resnet50'  # 'resnet50' | None\n    backbone_weights = resnet50_imagenet_weights  # resnet50_imagenet_weights | 'imagenet' | None\n    backbone_trainable = True\n    dropout = False\n    \n    num_epochs = 2  # <DEVEL> else 10\n    batch_size = 16  # <DEVEL> else 16 or 32\n    steps_per_update = 1  # gradient accumulation\n    \n    initial_learning_rate = 0.001\n    decay_steps = 5  # number of epochs\n    decay_rate = 0.9\n\n    threshold = 'auto'","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:18:32.086876Z","iopub.execute_input":"2023-07-27T20:18:32.087321Z","iopub.status.idle":"2023-07-27T20:18:32.095490Z","shell.execute_reply.started":"2023-07-27T20:18:32.087285Z","shell.execute_reply":"2023-07-27T20:18:32.094051Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# https://keras.io/examples/keras_recipes/reproducibility_recipes/\n\n# Set the seed using keras.utils.set_random_seed. This will set:\n# 1) `numpy` seed\n# 2) `tensorflow` random seed\n# 3) `python` random seed\nkeras.utils.set_random_seed(Config.seed)\n\n# See also:\n# tf.config.experimental.enable_op_determinism()","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:18:32.434299Z","iopub.execute_input":"2023-07-27T20:18:32.434726Z","iopub.status.idle":"2023-07-27T20:18:32.441109Z","shell.execute_reply.started":"2023-07-27T20:18:32.434689Z","shell.execute_reply":"2023-07-27T20:18:32.439838Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# Mixed Precision\n# https://www.tensorflow.org/guide/mixed_precision#supported_hardware\n\nif PLATFORM == 'kaggle':\n    MIXED_PRECISION = True\nelif PLATFORM == 'gcp':\n    # No mixed precision on QCP:\n    # \"Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0.\n    # Your GPU: Tesla P100-PCIE-16GB, compute capability 6.0\"\n    MIXED_PRECISION = False\nelse:\n    raise NotImplementedError(f'unknown platform \"{PLATFORM}\"')\n\nif MIXED_PRECISION:\n    print('setting mixed_precision')\n\n    NP_FLOAT = 'float16'\n    TF_FLOAT = tf.float16\n    TF_INT = tf.uint8\n    \n    keras.mixed_precision.set_global_policy('mixed_float16')\n    final_dtype = 'float32'\n    \nelse:\n    print('no mixed_precision')\n\n    NP_FLOAT = 'float32'\n    TF_FLOAT = tf.float32\n    TF_INT = tf.uint8\n\n    final_dtype = None","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:18:32.782823Z","iopub.execute_input":"2023-07-27T20:18:32.783281Z","iopub.status.idle":"2023-07-27T20:18:32.792405Z","shell.execute_reply.started":"2023-07-27T20:18:32.783240Z","shell.execute_reply":"2023-07-27T20:18:32.790866Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"setting mixed_precision\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### U-Net","metadata":{}},{"cell_type":"code","source":"class UNet:\n    '''U-Net model.\n    \n    Inspired by and adapted from:\n    - https://keras.io/examples/vision/oxford_pets_image_segmentation\n    - https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580\n    - https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow/home/week/3\n    '''\n    \n    def __init__(self, preprocess=None, backbone=None, weights='imagenet',\n                 backbone_trainable=True, dropout=True):\n        self.preprocess = preprocess\n        self.backbone = backbone\n        self.weights = weights\n        self.backbone_trainable = backbone_trainable\n        self.dropout = dropout\n        \n    def conv2d_block(self, input_tensor, n_filters, kernel_size=3):\n        x = input_tensor\n        for i in range(2):\n            x = tf.keras.layers.SeparableConv2D(\n                filters = n_filters, kernel_size=(kernel_size, kernel_size), padding='same')(x)\n            #? kernel_initializer = 'he_normal'\n            x = tf.keras.layers.BatchNormalization()(x)\n            x = tf.keras.layers.Activation('relu')(x)\n        return x\n\n    def encoder_block(self, inputs, n_filters, pool_size, dropout):\n        f = self.conv2d_block(inputs, n_filters=n_filters)\n        p = tf.keras.layers.MaxPooling2D(pool_size)(f)\n        p = tf.keras.layers.Dropout(dropout)(p)\n        return f, p\n\n    def basic_encoder(self, inputs, dropout=0.1):\n        f1, p1 = self.encoder_block(inputs, n_filters=64, pool_size=(2,2), dropout=dropout)\n        f2, p2 = self.encoder_block(p1, n_filters=128, pool_size=(2,2), dropout=dropout)\n        f3, p3 = self.encoder_block(p2, n_filters=256, pool_size=(2,2), dropout=dropout)\n        f4, p4 = self.encoder_block(p3, n_filters=512, pool_size=(2,2), dropout=dropout)\n        return p4, (f1, f2, f3, f4)\n    \n    def effnet_encoder(self, inputs, dropout=0.1):\n        \n        effnetb3 = keras.applications.EfficientNetB3(\n            weights=self.weights, include_top=False, input_tensor=inputs,\n        )\n        effnetb3.trainable = self.backbone_trainable\n        print('backbone_trainable =', self.backbone_trainable)\n        \n        raise NotImplementedError('WIP')\n        \n        f1 = None  # effnetb3.get_layer(\"conv1_relu\").output\n        f2 = None  # effnetb3.get_layer(\"conv2_block3_out\").output\n        f3 = None  # effnetb3.get_layer(\"conv3_block4_out\").output\n        f4 = None  # effnetb3.get_layer(\"conv4_block5_out\").output\n        output = effnetb3.output\n        \n        return output, (f1, f2, f3, f4)\n    \n    def resnet_encoder(self, inputs, dropout=0.1):\n        \n        # The first Conv2D of the keras implementation of ResNet has strides=2:\n        # x = layers.Conv2D(64, 7, strides=2, use_bias=use_bias, name=\"conv1_conv\")(x)\n        # i.e. the image is downsampled first.\n        # To avoid this, we apply an upsample in front.\n        upsample = keras.layers.UpSampling2D()(inputs) \n\n        resnet50 = keras.applications.ResNet50(\n            weights=self.weights, include_top=False, input_tensor=upsample,\n        )\n        resnet50.trainable = self.backbone_trainable\n        print('backbone_trainable =', self.backbone_trainable)\n        \n        f1 = resnet50.get_layer(\"conv1_relu\").output\n        f2 = resnet50.get_layer(\"conv2_block3_out\").output\n        f3 = resnet50.get_layer(\"conv3_block4_out\").output\n        f4 = resnet50.get_layer(\"conv4_block5_out\").output\n        output = resnet50.output\n        \n        return output, (f1, f2, f3, f4)\n    \n    def encoder(self, inputs, dropout=0.1):\n        if self.backbone == 'resnet50':\n            return self.resnet_encoder(inputs, dropout)\n        elif self.backbone == 'effnetb3':\n            return self.effnet_encoder(inputs, dropout)\n        elif self.backbone is None:\n            return self.basic_encoder(inputs, dropout)\n        raise NotImplementedError(f'unknown backbone \"{self.backbone}')\n\n    def bottleneck(self, inputs):\n        bottle_neck = self.conv2d_block(inputs, n_filters=1024)\n        return bottle_neck\n\n    def decoder_block(self, inputs, conv_output, n_filters, kernel_size, strides, dropout):\n        u = tf.keras.layers.Conv2DTranspose(\n            n_filters, kernel_size, strides=strides, padding = 'same')(inputs)\n        u = tf.keras.layers.BatchNormalization()(u)\n        c = tf.keras.layers.concatenate([u, conv_output])\n        c = tf.keras.layers.Dropout(dropout)(c)\n        c = self.conv2d_block(c, n_filters, kernel_size=3)\n        return c\n\n    def decoder(self, inputs, convs, num_classes, dropout=0.1):\n        if self.backbone == 'resnet50':\n            filters = [1024, 512, 256, 64]\n        elif self.backbone is None:\n            filters = [512, 256, 128, 64]\n        else:\n            raise NotImplementedError(f'unknown backbone \"{self.backbone}')\n        f1, f2, f3, f4 = convs\n        c6 = self.decoder_block(inputs, f4, n_filters=filters[0], kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        c7 = self.decoder_block(c6, f3, n_filters=filters[1], kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        c8 = self.decoder_block(c7, f2, n_filters=filters[2], kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        c9 = self.decoder_block(c8, f1, n_filters=filters[3], kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        if num_classes == 1:\n            activation = \"sigmoid\"\n        else:\n            activation = \"softmax\"\n        outputs = layers.Conv2D(\n            num_classes, kernel_size=3, activation=activation, padding=\"same\", dtype=final_dtype)(c9)\n        return outputs\n\n    def model(self, image_size, num_classes):\n        inputs = tf.keras.layers.Input(shape=(image_size,image_size,3))\n        encoder_output, convs = self.encoder(inputs)\n        for conv in convs:\n            print(conv.name, conv.shape)\n        bottle_neck = self.bottleneck(encoder_output)\n        outputs = self.decoder(bottle_neck, convs, num_classes)\n        model = tf.keras.Model(name=self.__class__.__name__, inputs=inputs, outputs=outputs)\n        return model","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:18:34.087611Z","iopub.execute_input":"2023-07-27T20:18:34.088041Z","iopub.status.idle":"2023-07-27T20:18:34.127579Z","shell.execute_reply.started":"2023-07-27T20:18:34.088007Z","shell.execute_reply":"2023-07-27T20:18:34.126263Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"### DeepLabV3+","metadata":{}},{"cell_type":"code","source":"class DeepLabV3Plus:\n    '''DeepLabV3+ model.\n    \n    Adapted from:\n    - https://keras.io/examples/vision/deeplabv3_plus/#inference-using-colormap-overlay\n    \n    Dropout from:\n    - https://github.com/smspillaz/seg-reg\n    '''\n    \n    def __init__(self, preprocess='resnet50', weights='imagenet', backbone_trainable=True,\n                 dropout=False):\n        self.preprocess = preprocess\n        self.weights = weights\n        self.backbone_trainable = backbone_trainable\n        self.dropout = dropout\n    \n    def convolution_block(\n        self,\n        block_input,\n        num_filters=256,\n        kernel_size=3,\n        dilation_rate=1,\n        padding=\"same\",\n        use_bias=False,\n    ):\n        x = layers.Conv2D(\n            num_filters,\n            kernel_size=kernel_size,\n            dilation_rate=dilation_rate,\n            padding=\"same\",\n            use_bias=use_bias,\n            kernel_initializer=keras.initializers.HeNormal(),\n        )(block_input)\n        x = layers.BatchNormalization()(x)\n        return tf.nn.relu(x)\n\n    def DilatedSpatialPyramidPooling(self, dspp_input):\n        dims = dspp_input.shape\n        x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n        \n        x = self.convolution_block(x, kernel_size=1, use_bias=True)\n        out_pool = layers.UpSampling2D(\n            size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n        )(x)\n\n        out_1 = self.convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n        out_6 = self.convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n        out_12 = self.convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n        out_18 = self.convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n\n        x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n        output = self.convolution_block(x, kernel_size=1)\n\n        if self.dropout:\n            output = tf.keras.layers.Dropout(0.1)(output)\n        \n        return output\n    \n    def model(self, image_size, num_classes):\n        \n        model_input = keras.Input(shape=(image_size, image_size, 3))\n        \n        resnet50 = keras.applications.ResNet50(\n            weights=self.weights, include_top=False, input_tensor=model_input,\n        )\n        resnet50.trainable = self.backbone_trainable\n        print('resnet50.trainable =', resnet50.trainable)\n        \n        x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n        x = self.DilatedSpatialPyramidPooling(x)\n\n        input_a = layers.UpSampling2D(\n            size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n            interpolation=\"bilinear\",\n        )(x)\n        input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n        input_b = self.convolution_block(input_b, num_filters=48, kernel_size=1)\n\n        x = layers.Concatenate(axis=-1)([input_a, input_b])\n        x = self.convolution_block(x)\n        if self.dropout:\n            x = tf.keras.layers.Dropout(0.5)(x)\n        x = self.convolution_block(x)\n        if self.dropout:\n            x = tf.keras.layers.Dropout(0.1)(x)\n        x = layers.UpSampling2D(\n            size=(image_size // x.shape[1], image_size // x.shape[2]),\n            interpolation=\"bilinear\",\n        )(x)\n        \n        if num_classes == 1:\n            activation = \"sigmoid\"\n        else:\n            activation = \"softmax\"\n        model_output = layers.Conv2D(\n            num_classes, kernel_size=(1, 1), activation=activation, padding=\"same\", dtype=final_dtype)(x)\n        \n        return keras.Model(name=self.__class__.__name__, inputs=model_input, outputs=model_output)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:18:34.960231Z","iopub.execute_input":"2023-07-27T20:18:34.960621Z","iopub.status.idle":"2023-07-27T20:18:34.987998Z","shell.execute_reply.started":"2023-07-27T20:18:34.960590Z","shell.execute_reply":"2023-07-27T20:18:34.986620Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"class P3DResNet:\n    '''Pseudo-3D Resnet model.\n    \n    Adapted from:\n    - https://github.com/qijiezhao/pseudo-3d-pytorch/blob/master/p3d_model.py\n    - https://github.com/yfxc/pseudo-3d-tensorflow/blob/master/P3D.py\n    - https://github.com/keras-team/keras/blob/v2.13.1/keras/applications/resnet.py\n    '''\n    \n    def __init__(self):\n        \n        self.blocks = [3, 4, 6, 3]  # P3D63 modelbased on a ResNet-50-3D model\n        self.depth_3d=sum(self.layers[:3])\n        \n        self.maxpool_s = keras.layers.MaxPooling3D(pool_size=(3, 3, 1), strides=(2, 2, 1), padding='same')\n        self.maxpool_t = keras.layers.MaxPooling3D(pool_size=(1, 1, 2), strides=(1, 1, 2), padding='same')\n        #self.avgpool = keras.layers.GlobalAveragePooling2D()\n    \n    def block(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n        \"\"\"A residual block.\n\n        Args:\n          x: input tensor.\n          filters: integer, filters of the bottleneck layer.\n          kernel_size: default 3, kernel size of the bottleneck layer.\n          stride: default 1, stride of the first layer.\n          conv_shortcut: default True, use convolution shortcut if True,\n              otherwise identity shortcut.\n          name: string, block label.\n\n        Returns:\n          Output tensor for the residual block.\n        \"\"\"\n        bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n\n        if conv_shortcut:\n            shortcut = layers.Conv2D(\n                4 * filters, 1, strides=stride, name=name + \"_0_conv\"\n            )(x)\n            shortcut = layers.BatchNormalization(\n                axis=bn_axis, epsilon=1.001e-5, name=name + \"_0_bn\"\n            )(shortcut)\n        else:\n            shortcut = x\n\n        x = layers.Conv2D(filters, 1, strides=stride, name=name + \"_1_conv\")(x)\n        x = layers.BatchNormalization(\n            axis=bn_axis, epsilon=1.001e-5, name=name + \"_1_bn\"\n        )(x)\n        x = layers.Activation(\"relu\", name=name + \"_1_relu\")(x)\n\n        x = layers.Conv2D(\n            filters, kernel_size, padding=\"SAME\", name=name + \"_2_conv\"\n        )(x)\n        x = layers.BatchNormalization(\n            axis=bn_axis, epsilon=1.001e-5, name=name + \"_2_bn\"\n        )(x)\n        x = layers.Activation(\"relu\", name=name + \"_2_relu\")(x)\n\n        x = layers.Conv2D(4 * filters, 1, name=name + \"_3_conv\")(x)\n        x = layers.BatchNormalization(\n            axis=bn_axis, epsilon=1.001e-5, name=name + \"_3_bn\"\n        )(x)\n\n        x = layers.Add(name=name + \"_add\")([shortcut, x])\n        x = layers.Activation(\"relu\", name=name + \"_out\")(x)\n        return x\n    \n    def stack(x, filters, blocks, stride, name=None):\n        \"\"\"A set of stacked residual blocks.\n\n        Args:\n          x: input tensor.\n          filters: integer, filters of the bottleneck layer in a block.\n          blocks: integer, blocks in the stacked blocks.\n          stride1: default 2, stride of the first layer in the first block.\n          name: string, stack label.\n\n        Returns:\n          Output tensor for the stacked blocks.\n        \"\"\"\n        x = block1(x, filters, stride=stride1, name=name + \"_block1\")\n        for i in range(2, blocks + 1):\n            x = block1(\n                x, filters, conv_shortcut=False, name=name + \"_block\" + str(i)\n            )\n        return x\n    \n    def model(self, image_size, num_classes):\n        \n        # (B, H, W, T, C) here\n        # (B, C, T, H, W) in pseudo-3d-pytorch\n\n        model_input = keras.Input(shape=(image_size, image_size, N_FRAMES, 3))\n        \n        x = keras.layers.Conv3D(\n            64, kernel_size=(7, 7, 1), strides=(2, 2, 1), padding='same', use_bias=False\n            )(model_input)\n        x = keras.layers.BatchNormalization()(x)\n        x = keras.layers.ReLU()(x)\n        x = self.maxpool_s(x)\n        \n        x = self.stack(x, 64, blocks[0], stride=1, shortcut_type, name=\"conv2\")\n        x = self.maxpool_t(x)\n        x = self.stack(x, 128, blocks[1], stride=2, shortcut_type, name=\"conv3\")\n        x = self.maxpool_t(x)\n        x = self.stack(x, 256, blocks[2], stride=2, shortcut_type, name=\"conv4\")\n        x = self.maxpool_t(x)\n        x = self.stack(x, 512, blocks[3], stride=2, shortcut_type, name=\"conv5\")\n        #x = self.avgpool(x)\n        \n        model_output = x\n        \n        return keras.Model(name=self.__class__.__name__, inputs=model_input, outputs=model_output)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:43:20.815060Z","iopub.execute_input":"2023-07-27T20:43:20.815471Z","iopub.status.idle":"2023-07-27T20:43:20.827515Z","shell.execute_reply.started":"2023-07-27T20:43:20.815439Z","shell.execute_reply":"2023-07-27T20:43:20.826627Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# Free up RAM in case the model definition cells were run multiple times\nkeras.backend.clear_session()\n\n# Build model\nif Config.model == 'unet':\n    builder = UNet(\n        preprocess=Config.preprocess,\n        backbone=Config.backbone,\n        weights=Config.backbone_weights,\n        backbone_trainable=Config.backbone_trainable,\n        dropout=Config.dropout\n    )\n\nelif Config.model == 'deeplabv3plus':\n    builder = DeepLabV3Plus(\n        preprocess=Config.preprocess,\n        weights=Config.backbone_weights,\n        backbone_trainable=Config.backbone_trainable,\n        dropout=Config.dropout\n    )\n\nelif Config.model =='p3dresnet':\n    builder = P3DResNet()\n\nelse:\n    raise NotImplementedError(f'model \"{Config.model}\"')\n\nmodel = builder.model(image_size=Config.img_size[0], num_classes=Config.num_classes)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-27T20:43:21.717098Z","iopub.execute_input":"2023-07-27T20:43:21.718042Z","iopub.status.idle":"2023-07-27T20:43:21.809584Z","shell.execute_reply.started":"2023-07-27T20:43:21.718005Z","shell.execute_reply":"2023-07-27T20:43:21.808431Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Model: \"P3DResNet\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 256, 256, 5, 3)]  0         \n                                                                 \n conv3d (Conv3D)             (None, 128, 128, 5, 64)   9408      \n                                                                 \n batch_normalization (BatchN  (None, 128, 128, 5, 64)  256       \n ormalization)                                                   \n                                                                 \n re_lu (ReLU)                (None, 128, 128, 5, 64)   0         \n                                                                 \n max_pooling3d (MaxPooling3D  (None, 64, 64, 5, 64)    0         \n )                                                               \n                                                                 \n=================================================================\nTotal params: 9,664\nTrainable params: 9,536\nNon-trainable params: 128\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Configure datasets (keras)","metadata":{"execution":{"iopub.execute_input":"2023-07-10T19:30:33.222846Z","iopub.status.busy":"2023-07-10T19:30:33.222338Z","iopub.status.idle":"2023-07-10T19:30:33.228013Z","shell.execute_reply":"2023-07-10T19:30:33.227016Z","shell.execute_reply.started":"2023-07-10T19:30:33.222811Z"},"tags":[]}},{"cell_type":"code","source":"N_TRAIN = 1024  # 512 <DEVEL> else None (max 20529)\nN_VALID = 256  # 128 <DEVEL> else None (max 1856)\nN_PARTIAL = 128  # 128","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:36:23.767930Z","iopub.execute_input":"2023-07-27T19:36:23.768306Z","iopub.status.idle":"2023-07-27T19:36:23.788222Z","shell.execute_reply.started":"2023-07-27T19:36:23.768272Z","shell.execute_reply":"2023-07-27T19:36:23.785443Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"print('preprocess =', builder.preprocess)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:36:23.795713Z","iopub.execute_input":"2023-07-27T19:36:23.796067Z","iopub.status.idle":"2023-07-27T19:36:23.801547Z","shell.execute_reply.started":"2023-07-27T19:36:23.796036Z","shell.execute_reply":"2023-07-27T19:36:23.800779Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"preprocess = None\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Multi-frame","metadata":{}},{"cell_type":"code","source":"class AshColorMultiFrames(keras.utils.Sequence):\n    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n\n    def __init__(self, batch_size, img_size, sample_ids, split_dir, preprocess=None, n_samples=None):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.split_dir = split_dir\n        self.sample_ids = sample_ids[:n_samples]\n        self.preprocess = preprocess\n\n    def __len__(self):\n        return math.ceil(len(self.sample_ids) / self.batch_size)\n    \n    def get_sample_ids(self, idx):\n        '''Get sample ids of batch idx.'''\n        i = idx * self.batch_size\n        return self.sample_ids[i : i + self.batch_size]\n    \n    def __getitem__(self, idx):\n        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n        \n        batch_sample_ids = self.get_sample_ids(idx)\n        \n        sample_shape = self.img_size + (3,) + (N_FRAMES,)\n        batch_shape = (self.batch_size,) + sample_shape\n        x = np.zeros(batch_shape, dtype=NP_FLOAT)\n        \n        for j, sample_id in enumerate(batch_sample_ids):\n            \n            # img shape (H x W x 3 x T)\n            img = get_ash_colors(sample_id, self.split_dir)\n\n            prep_img = np.full(sample_shape, np.nan)\n            for frame_idx in range(N_FRAMES):\n                timestep_idx = N_TIMES_BEFORE - N_FRAMES_BEFORE + frame_idx\n                if self.preprocess == 'resnet50':\n                    img_t = keras.applications.resnet50.preprocess_input(img[..., timestep_idx])\n                elif self.preprocess is None:\n                    img_t = img[..., timestep_idx]\n                else:\n                    raise NotImplementedError(f'preprocess \"{self.preprocess}\"')\n                prep_img[..., frame_idx] = img_t\n            x[j] = prep_img\n\n        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n        if self.split_dir != 'test':\n            for j, sample_id in enumerate(batch_sample_ids):\n                # img shape (H x W x 1)\n                img = get_pixel_mask(sample_id, self.split_dir)\n                y[j] = img\n        \n        return x, y","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:36:23.815337Z","iopub.execute_input":"2023-07-27T19:36:23.815759Z","iopub.status.idle":"2023-07-27T19:36:23.848049Z","shell.execute_reply.started":"2023-07-27T19:36:23.815724Z","shell.execute_reply":"2023-07-27T19:36:23.847218Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"train_set = AshColorMultiFrames(\n    Config.batch_size, Config.img_size, train_ids, 'train',\n    preprocess=builder.preprocess, n_samples=N_TRAIN)\nprint('number of batches:', len(train_set), 'train')\n\nvalid_set = AshColorMultiFrames(\n    Config.batch_size, Config.img_size, valid_ids, 'validation',\n    preprocess=builder.preprocess, n_samples=N_VALID)\nprint('number of batches:', len(valid_set), 'valid')\n\npartial_set = AshColorMultiFrames(\n    Config.batch_size, Config.img_size, valid_ids, 'validation',\n    preprocess=builder.preprocess, n_samples=N_PARTIAL)\nprint('number of batches:', len(partial_set), 'partial')\n\ntest_set = AshColorMultiFrames(\n    Config.batch_size, Config.img_size, test_ids, 'test',\n    preprocess=builder.preprocess)\nprint('number of batches:', len(test_set), 'test')","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:36:23.849139Z","iopub.execute_input":"2023-07-27T19:36:23.849543Z","iopub.status.idle":"2023-07-27T19:36:23.863543Z","shell.execute_reply.started":"2023-07-27T19:36:23.849508Z","shell.execute_reply":"2023-07-27T19:36:23.862575Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"number of batches: 64 train\nnumber of batches: 16 valid\nnumber of batches: 8 partial\nnumber of batches: 1 test\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Check dimensions (x, y) of first batch:')\n\ntrain_set[0][0].shape, train_set[0][1].shape","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:36:23.876321Z","iopub.execute_input":"2023-07-27T19:36:23.876721Z","iopub.status.idle":"2023-07-27T19:36:26.020368Z","shell.execute_reply.started":"2023-07-27T19:36:23.876684Z","shell.execute_reply":"2023-07-27T19:36:26.019149Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Check dimensions (x, y) of first batch:\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"((16, 256, 256, 3, 5), (16, 256, 256, 1))"},"metadata":{}}]},{"cell_type":"markdown","source":"# Generate TFRecords","metadata":{}},{"cell_type":"code","source":"class TFDataSetCreator:\n    '''Write TFRecords files and generate a TFRecordDataset from a keras.Sequence.\n    \n    Inspired by:\n    - https://www.tensorflow.org/tutorials/load_data/tfrecord\n    - https://keras.io/examples/keras_recipes/creating_tfrecords\n    - https://keras.io/examples/keras_recipes/tfrecord\n    - https://stackoverflow.com/questions/47861084/how-to-store-numpy-arrays-as-tfrecord\n    \n    References:\n    - https://www.tensorflow.org/guide/data - Build TensorFlow input pipelines\n    - https://www.tensorflow.org/guide/data_performance - Better performance with the tf.data API\n    '''\n    \n    def __init__(self, keras_sequence, train, augment):\n        self.keras_sequence = keras_sequence\n        self.split_dir = keras_sequence.split_dir\n        self.batch_size = keras_sequence.batch_size\n        \n        self.train = train\n        self.augment = augment\n        \n        self.keep_existing = True\n        self.records_dir = os.path.join(TEMP_DIR, f'records-multi{N_FRAMES}-{self.batch_size}-{self.split_dir}')\n        self.record_paths = []\n        \n        self.progress_bar = True  # <DEVEL>\n    \n    def write_tfrec(self, batch_idx):\n        #pid = multiprocessing.current_process().pid\n        \n        record_path = os.path.join(self.records_dir, f'batch_{batch_idx:04d}.tfrec')\n        \n        if self.keep_existing and os.path.exists(record_path):\n            return record_path\n        \n        if self.progress_bar:\n            if batch_idx % 100 == 0:\n                print('o', end='')\n            else:\n                print('.', end='')\n\n        x_b, y_b = self.keras_sequence[batch_idx]\n        with tf.io.TFRecordWriter(record_path) as writer:\n            for x, y in zip(x_b, y_b):\n                feature = {\n                    \"x\": tf.train.Feature(\n                        bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(x).numpy()])),\n                    \"y\": tf.train.Feature(\n                        bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(y).numpy()])),\n                }\n                example = tf.train.Example(features=tf.train.Features(feature=feature))\n                writer.write(example.SerializeToString())\n        \n        return record_path\n    \n    def generate_tfrec(self, keep_existing=True):\n        \n        self.keep_existing = keep_existing\n        \n        records_dir = self.records_dir\n        os.makedirs(records_dir, exist_ok=True)\n        \n        n_records = len(self.keras_sequence)\n        n_procs = multiprocessing.cpu_count() * 2\n        print(f'generating {n_records} records with {n_procs} processes in: {records_dir}')\n        %ll -hd $records_dir\n\n        pool = multiprocessing.Pool(processes=n_procs)\n        batch_indexes = range(n_records)\n        record_paths = sorted(pool.map(self.write_tfrec, batch_indexes))\n        if self.progress_bar:\n            print()\n        \n        !du -sh $records_dir\n        print()\n        \n        self.record_paths = record_paths\n        return self\n    \n    @staticmethod\n    def parse_tfrecord_sample(element):\n        parse_dic = {\n            'x': tf.io.FixedLenFeature([], tf.string),  # Note that it is tf.string, not tf.float32\n            'y': tf.io.FixedLenFeature([], tf.string),  # Note that it is tf.string, not tf.float32\n        }\n        feature = tf.io.parse_single_example(element, parse_dic)\n        feature['x'] = tf.io.parse_tensor(feature['x'], out_type=TF_FLOAT)\n        feature['y'] = tf.io.parse_tensor(feature['y'], out_type=TF_INT)\n        return feature\n\n    @staticmethod\n    def prepare_sample(features):\n        '''Return (x,y) both as Tensors.'''\n        # TODO: reshape tensor\n        #return (tf.reshape(features['x'], Config.img_size + (3,)),\n        #        tf.reshape(features['y'], Config.img_size + (1,)))\n        return (features['x'][:, :, :, N_FRAMES_BEFORE],\n                features['y'])\n\n    def randomly_crop_resize_rotate(self, image, label=None):\n        \"\"\"Randomly scales image and label.\n        \n        - https://github.com/tensorflow/models/blob/.../research/deeplab/core/preprocess_utils.py\n        - https://github.com/keras-team/keras/blob/v2.13.1/keras/layers/preprocessing/image_preprocessing.py\n        \n        Args:\n        image: Image with shape [height, width, 3].\n        label: Label with shape [height, width, 1].\n        scale: The value to scale image and label. Random if None.\n\n        Returns:\n        Scaled image and label.\n        \"\"\"\n\n        if not self.train:\n            return image, label\n        \n        y1 = tf.random.uniform([1, 1], minval=0.0, maxval=0.2)\n        x1 = tf.random.uniform([1, 1], minval=0.0, maxval=0.2)\n        y2 = tf.random.uniform([1, 1], minval=0.8, maxval=1.0)\n        x2 = tf.random.uniform([1, 1], minval=0.8, maxval=1.0)\n        boxes = tf.concat([y1, x1, y2, x2], 1)\n        \n        rot90_k = tf.cast(tf.random.uniform([], minval=0., maxval=4.), tf.int32)\n\n        def transform(img, method):\n            img = tf.image.crop_and_resize(\n                tf.expand_dims(img, 0),\n                boxes, [0],\n                [Config.img_size[0], Config.img_size[0]], \n                method=method\n            )[0, ...]\n            img = tf.image.rot90(img, rot90_k)\n            return img\n        \n        image = tf.reshape(image, Config.img_size + (3,))\n        image = transform(image, 'bilinear')\n\n        if label is not None:\n            label = tf.reshape(label, Config.img_size + (1,))\n            label = transform(label, 'nearest')\n        \n        image = tf.cast(image, TF_FLOAT)\n        label = tf.cast(label, TF_INT)\n        \n        return image, label\n\n    def dataset(self, batch=True, shuffle=True):\n        dataset = (\n            tf.data.TFRecordDataset(self.record_paths, num_parallel_reads=AUTOTUNE)\n            .map(self.parse_tfrecord_sample, num_parallel_calls=AUTOTUNE)\n            .map(self.prepare_sample, num_parallel_calls=AUTOTUNE)\n        )\n        if shuffle:\n            dataset = (\n                dataset\n                .shuffle(self.batch_size * 10)\n            )\n        if self.augment:\n            dataset = (\n                dataset\n                .map(self.randomly_crop_resize_rotate, num_parallel_calls=AUTOTUNE)\n            )\n        if batch:\n            dataset = (\n                dataset\n                .batch(self.batch_size)\n            )\n        dataset = (\n            dataset\n            .prefetch(AUTOTUNE)\n        )\n        return dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:36:26.022208Z","iopub.execute_input":"2023-07-27T19:36:26.022601Z","iopub.status.idle":"2023-07-27T19:36:26.085730Z","shell.execute_reply.started":"2023-07-27T19:36:26.022565Z","shell.execute_reply":"2023-07-27T19:36:26.084530Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### Visualize data augmentation","metadata":{}},{"cell_type":"code","source":"def plot_samples(images, labels):\n    \n    if images[0].ndim != 3:\n        raise IndexError(f'Not a single image, shape: {images[0].shape}')\n    \n    fig, axs = plt.subplots(2, len(images), figsize=(10, 4))\n\n    for idx, (image, label) in enumerate(zip(images, labels)):\n        axs[0, idx].imshow(image.astype('float32'))\n        axs[1, idx].imshow(label.astype('int8'))\n\n    plt.tight_layout() \n    plt.show()\n\n    return","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:36:26.089050Z","iopub.execute_input":"2023-07-27T19:36:26.090298Z","iopub.status.idle":"2023-07-27T19:36:26.104556Z","shell.execute_reply.started":"2023-07-27T19:36:26.090259Z","shell.execute_reply":"2023-07-27T19:36:26.103358Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"if False:  # <DEVEL>\n\n    KEEP_EXISTING = False\n\n    tf.debugging.set_log_device_placement(True)\n\n    # Place tensors on the CPU\n    with tf.device('/CPU:0'):\n\n        tf_train_set = (\n            TFDataSetCreator(train_set, train=True, augment=Config.augment)\n            .generate_tfrec(KEEP_EXISTING)\n            .dataset(batch=False, shuffle=False)\n        )\n\n    elements = []\n    for _ in range(8):\n        for idx, element in enumerate(tf_train_set.take(2)):\n            if idx == 1:\n                elements.append(element)\n    plot_samples(\n        [el[0].numpy() for el in elements],\n        [el[1].numpy() for el in elements],\n    )","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:36:26.109194Z","iopub.execute_input":"2023-07-27T19:36:26.109653Z","iopub.status.idle":"2023-07-27T19:36:26.125915Z","shell.execute_reply.started":"2023-07-27T19:36:26.109616Z","shell.execute_reply":"2023-07-27T19:36:26.124267Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### Write TFRecords","metadata":{"execution":{"iopub.execute_input":"2023-07-25T11:25:26.289666Z","iopub.status.busy":"2023-07-25T11:25:26.289139Z","iopub.status.idle":"2023-07-25T11:25:26.299911Z","shell.execute_reply":"2023-07-25T11:25:26.298556Z","shell.execute_reply.started":"2023-07-25T11:25:26.289625Z"}}},{"cell_type":"code","source":"KEEP_EXISTING = True  # <DEVEL>\n\ntimeit_start = datetime.datetime.now()\n\n#tf.config.run_functions_eagerly(False)\n#tf.data.experimental.enable_debug_mode()\n\ntf.debugging.set_log_device_placement(True)\n\n# Place tensors on the CPU\nwith tf.device('/CPU:0'):\n\n    tf_train_set = (\n        TFDataSetCreator(train_set, train=True, augment=Config.augment)\n        .generate_tfrec(KEEP_EXISTING)\n        .dataset()\n    )\n\n    tf_valid_set = (\n        TFDataSetCreator(valid_set, train=False, augment=Config.augment)\n        .generate_tfrec(KEEP_EXISTING)\n        .dataset()\n    )\n\n    tf_partial_set = (\n        TFDataSetCreator(partial_set, train=False, augment=Config.augment)\n        .generate_tfrec(KEEP_EXISTING)\n        .dataset()\n    )\n\n    tf_test_set = (\n        TFDataSetCreator(test_set, train=False, augment=Config.augment)\n        .generate_tfrec(KEEP_EXISTING)\n        .dataset()\n    )\n\ntf.debugging.set_log_device_placement(False)\n\ntimeit_end = datetime.datetime.now()\nprint('datasets generated in:', timeit_end - timeit_start)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:36:26.127587Z","iopub.execute_input":"2023-07-27T19:36:26.130035Z","iopub.status.idle":"2023-07-27T19:37:28.952119Z","shell.execute_reply.started":"2023-07-27T19:36:26.129996Z","shell.execute_reply":"2023-07-27T19:37:28.950066Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"generating 64 records with 4 processes in: /kaggle/temp/records-multi5-16-train\ndrwxr-xr-x 2 root 4.0K Jul 27 19:36 \u001b[0m\u001b[01;34m/kaggle/temp/records-multi5-16-train\u001b[0m/\n.o..............................................................\n2.0G\t/kaggle/temp/records-multi5-16-train\n\ngenerating 16 records with 4 processes in: /kaggle/temp/records-multi5-16-validation\ndrwxr-xr-x 2 root 4.0K Jul 27 19:37 \u001b[0m\u001b[01;34m/kaggle/temp/records-multi5-16-validation\u001b[0m/\n..o.............\n497M\t/kaggle/temp/records-multi5-16-validation\n\ngenerating 8 records with 4 processes in: /kaggle/temp/records-multi5-16-validation\ndrwxr-xr-x 2 root 4.0K Jul 27 19:37 \u001b[0m\u001b[01;34m/kaggle/temp/records-multi5-16-validation\u001b[0m/\n\n497M\t/kaggle/temp/records-multi5-16-validation\n\ngenerating 1 records with 4 processes in: /kaggle/temp/records-multi5-16-test\ndrwxr-xr-x 2 root 4.0K Jul 27 19:37 \u001b[0m\u001b[01;34m/kaggle/temp/records-multi5-16-test\u001b[0m/\no\n32M\t/kaggle/temp/records-multi5-16-test\n\ndatasets generated in: 0:01:02.806893\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=0.001, threshold=None):\n    '''Dice coefficient.\n    \n    Adapted from:\n    - https://stackoverflow.com/questions/72195156/correct-implementation-of-dice-loss-in-tensorflow-keras\n    - https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580\n    '''\n    \n    y_true_f = backend.flatten(tf.cast(y_true, TF_FLOAT))\n    y_pred_f = backend.flatten(tf.cast(y_pred, TF_FLOAT))\n    # ValueError: No gradients provided for any variable\n    if threshold is not None:\n        y_pred_f = backend.flatten(\n            tf.cast(tf.math.greater(tf.cast(y_pred, TF_FLOAT), threshold), TF_FLOAT))\n    intersection = backend.sum(y_true_f * y_pred_f)\n    dice = (2. * intersection + smooth) / (backend.sum(y_true_f) + backend.sum(y_pred_f) + smooth)\n    return dice\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:37:28.954467Z","iopub.execute_input":"2023-07-27T19:37:28.954956Z","iopub.status.idle":"2023-07-27T19:37:28.963952Z","shell.execute_reply.started":"2023-07-27T19:37:28.954902Z","shell.execute_reply":"2023-07-27T19:37:28.962895Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"#def threshold_dice_coef(y_true, y_pred, smooth=0.001):\n#    '''Dice coefficient with threshold set to Config.threshold.'''\n#    return dice_coef(y_true, y_pred, smooth=smooth, threshold=Config.threshold)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:37:28.965541Z","iopub.execute_input":"2023-07-27T19:37:28.966208Z","iopub.status.idle":"2023-07-27T19:37:28.981656Z","shell.execute_reply.started":"2023-07-27T19:37:28.966168Z","shell.execute_reply":"2023-07-27T19:37:28.980336Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"sample_id = 7829917977180135058  # train_ids[3]\n\nprint(f'Check dice_coef() on one of the samples: {sample_id}')\n\nmerged_mask = get_pixel_mask(sample_id, 'train')\nindiv_masks = get_individual_mask(sample_id, 'train')\n\nprint(dice_coef(tf.convert_to_tensor(merged_mask),\n                tf.convert_to_tensor(merged_mask)))\nfor idv in range(6):\n    print(dice_coef(tf.convert_to_tensor(merged_mask),\n                    tf.convert_to_tensor(indiv_masks[..., idv])))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:37:28.983042Z","iopub.execute_input":"2023-07-27T19:37:28.984219Z","iopub.status.idle":"2023-07-27T19:37:29.072976Z","shell.execute_reply.started":"2023-07-27T19:37:28.984179Z","shell.execute_reply":"2023-07-27T19:37:29.071849Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Check dice_coef() on one of the samples: 7829917977180135058\ntf.Tensor(1.0, shape=(), dtype=float16)\ntf.Tensor(0.8745, shape=(), dtype=float16)\ntf.Tensor(0.836, shape=(), dtype=float16)\ntf.Tensor(0.739, shape=(), dtype=float16)\ntf.Tensor(0.8525, shape=(), dtype=float16)\ntf.Tensor(0.88, shape=(), dtype=float16)\ntf.Tensor(0.8413, shape=(), dtype=float16)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Gradient accumulation optimizer","metadata":{}},{"cell_type":"code","source":"class AccumAdam(keras.optimizers.Adam):\n    \"\"\"Adam optimizer with gradient accumulation over specified number of batches.\n    \n    References:\n    - https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer\n    \"\"\"\n    def __init__(self, steps_per_update=1, **kwargs):\n        keras.optimizers.Adam.__init__(self, **kwargs)\n\n        self.steps_per_update = steps_per_update\n        self.step = 0\n        self.accum_grads = {}\n    \n    def build(self, var_list):\n        \n        keras.optimizers.Adam.build(self, var_list)\n        \n        for var in var_list:\n            var_key = var.name\n            self.accum_grads[var_key] = tf.zeros(var.shape)\n    \n    def update_step(self, gradient, variable):\n\n        step_mod = self.iterations % self.steps_per_update\n        var_key = variable.name\n        \n        self.accum_grads[var_key] =\\\n            tf.case([(tf.equal(step_mod, 0), lambda: tf.zeros_like(gradient))],\n                    default=lambda: self.accum_grads[var_key])\n        \n        self.accum_grads[var_key] += gradient\n        \n        accum_grad =\\\n            tf.case([(step_mod == self.steps_per_update - 1, lambda: self.accum_grads[var_key])],\n                    default=lambda: tf.zeros_like(gradient))\n    \n        keras.optimizers.Adam.update_step(self, accum_grad, variable)\n\nif Config.steps_per_update == 1:\n    optimizer = keras.optimizers.Adam()\nelse:\n    optimizer = AccumAdam(Config.steps_per_update)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:37:29.074417Z","iopub.execute_input":"2023-07-27T19:37:29.075536Z","iopub.status.idle":"2023-07-27T19:37:29.096064Z","shell.execute_reply.started":"2023-07-27T19:37:29.075499Z","shell.execute_reply":"2023-07-27T19:37:29.094959Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = f'identify-contrails_{file_time_str}.h5'\nlogger_path = f'identify-contrails_{file_time_str}_log.csv'\n\nprint(f'checkpoint file: {checkpoint_path}')","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:37:29.100323Z","iopub.execute_input":"2023-07-27T19:37:29.100655Z","iopub.status.idle":"2023-07-27T19:37:29.106939Z","shell.execute_reply.started":"2023-07-27T19:37:29.100628Z","shell.execute_reply":"2023-07-27T19:37:29.105938Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"checkpoint file: identify-contrails_2023-07-27_21-36-05.h5\n","output_type":"stream"}]},{"cell_type":"code","source":"# Learning rate scheduler:\n# - https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules\n# - https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecay\n# Note: CosineDecay got warmup from v2.13.1 on\n\ncos_scheduler = keras.optimizers.schedules.CosineDecay(\n    Config.initial_learning_rate, Config.decay_steps)\n\nexp_scheduler = keras.optimizers.schedules.ExponentialDecay(\n    Config.initial_learning_rate, Config.decay_steps, Config.decay_rate)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:37:29.108600Z","iopub.execute_input":"2023-07-27T19:37:29.109653Z","iopub.status.idle":"2023-07-27T19:37:29.118724Z","shell.execute_reply.started":"2023-07-27T19:37:29.109618Z","shell.execute_reply":"2023-07-27T19:37:29.117570Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Configure the model for training.\n\n# We use the \"sparse\" version of categorical_crossentropy\n# because our target data is integers.\n# See also:\n# loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[dice_coef])\n\ncallbacks = [\n    keras.callbacks.LearningRateScheduler(exp_scheduler),\n    keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True),\n    keras.callbacks.CSVLogger(logger_path, append=True)\n]","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-07-27T19:37:29.120247Z","iopub.execute_input":"2023-07-27T19:37:29.120757Z","iopub.status.idle":"2023-07-27T19:37:29.157950Z","shell.execute_reply.started":"2023-07-27T19:37:29.120712Z","shell.execute_reply":"2023-07-27T19:37:29.156862Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"### LET'S TRAIN!","metadata":{}},{"cell_type":"code","source":"if LOAD_CHECKPOINT:\n    # Loads the weights\n    model.load_weights(prev_checkpoint_path)\n    print(f'model loaded weights from {prev_checkpoint_path}')\n\nif TRAIN:\n    # Train the model, doing validation at the end of each epoch.\n    history = model.fit(\n        tf_train_set, epochs=Config.num_epochs, validation_data=tf_valid_set, callbacks=callbacks,\n        workers=4, use_multiprocessing=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:40:15.961195Z","iopub.execute_input":"2023-07-27T19:40:15.961653Z","iopub.status.idle":"2023-07-27T19:40:54.687956Z","shell.execute_reply.started":"2023-07-27T19:40:15.961616Z","shell.execute_reply":"2023-07-27T19:40:54.686497Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Epoch 1/2\n64/64 [==============================] - 19s 289ms/step - loss: 0.0279 - dice_coef: 0.0805 - val_loss: 0.0154 - val_dice_coef: 0.0025 - lr: 0.0010\nEpoch 2/2\n64/64 [==============================] - 19s 286ms/step - loss: 0.0238 - dice_coef: 0.1367 - val_loss: 0.0124 - val_dice_coef: 0.0017 - lr: 9.7915e-04\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### History","metadata":{}},{"cell_type":"code","source":"if TRAIN:\n    print('History', history.history.keys())\n\n    for var, yrange in [('loss', [0.0, 0.02]),\n                        ('dice_coef', [0.0, 0.8])]:\n        plt.figure(figsize=(10, 3))\n        plt.plot(history.history[var])\n        plt.plot(history.history[f'val_{var}'])\n        plt.ylim(yrange[0], yrange[1])\n        plt.title(f'model {var}')\n        plt.xlabel('epoch')\n        plt.ylabel(var)\n        plt.legend(['train', 'val'], loc='upper left')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:41:19.404971Z","iopub.execute_input":"2023-07-27T19:41:19.405383Z","iopub.status.idle":"2023-07-27T19:41:20.060086Z","shell.execute_reply.started":"2023-07-27T19:41:19.405351Z","shell.execute_reply":"2023-07-27T19:41:20.059085Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"History dict_keys(['loss', 'dice_coef', 'val_loss', 'val_dice_coef', 'lr'])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x300 with 1 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x300 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"def apply_threshold(pred, threshold):\n    return (pred > threshold).astype(np.int8)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:41:21.777753Z","iopub.execute_input":"2023-07-27T19:41:21.778809Z","iopub.status.idle":"2023-07-27T19:41:21.784727Z","shell.execute_reply.started":"2023-07-27T19:41:21.778767Z","shell.execute_reply":"2023-07-27T19:41:21.783601Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"EVALUATE = True\nALL_BATCHES = True\nBATCH_IDX = 0\nSAMPLE_IDX = 11","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:41:22.816767Z","iopub.execute_input":"2023-07-27T19:41:22.817238Z","iopub.status.idle":"2023-07-27T19:41:22.825254Z","shell.execute_reply.started":"2023-07-27T19:41:22.817194Z","shell.execute_reply":"2023-07-27T19:41:22.824192Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"if EVALUATE:    \n    # Evaluate the model\n\n    if ALL_BATCHES:\n        loss, acc = model.evaluate(tf_partial_set, verbose=2)\n    else:\n        eval_images, eval_masks = tf_partial_set[BATCH_IDX]\n        loss, acc = model.evaluate(eval_images, eval_masks, verbose=2)\n\n    print(\"Model accuracy: {:5.2f}%\".format(100 * acc))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:41:24.376604Z","iopub.execute_input":"2023-07-27T19:41:24.377390Z","iopub.status.idle":"2023-07-27T19:41:25.276096Z","shell.execute_reply.started":"2023-07-27T19:41:24.377341Z","shell.execute_reply":"2023-07-27T19:41:25.274800Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"8/8 - 1s - loss: 0.0146 - dice_coef: 0.0021 - 875ms/epoch - 109ms/step\nModel accuracy:  0.21%\n","output_type":"stream"}]},{"cell_type":"code","source":"def eval_dice_coef(sample_set, pred_set, batch_size, threshold):\n    dice_coef_per_batch = np.full(len(sample_set), np.nan)\n    for idx in range(len(sample_set)):\n        x, y = sample_set[idx]\n        pred = pred_set[idx*batch_size:(idx + 1)*batch_size]\n        _coef = dice_coef(y, pred, threshold=threshold)\n        dice_coef_per_batch[idx] = _coef\n    return dice_coef_per_batch\n\nif EVALUATE:\n    \n    predictions = model.predict(partial_set)\n    \n    _coefs = eval_dice_coef(\n        partial_set, predictions, batch_size=partial_set.batch_size, threshold=None)\n    print(f'w/o threshold: {_coefs.mean():.2%}')\n    \n    if Config.threshold == 'auto':\n        best_coef = 0.\n        for threshold in np.arange(0.1, 0.8, 0.1):\n            _coefs = eval_dice_coef(\n                partial_set, predictions, batch_size=partial_set.batch_size, threshold=threshold)\n            mean_coef = _coefs.mean()\n            if mean_coef > best_coef:\n                best_coef = mean_coef\n                best_thresh = threshold\n            print(f'{threshold:.02} threshold: {mean_coef:.2%}')\n        print(f'best_threshold = {best_thresh:.02}')\n        Config.threshold = best_thresh\n        print('Config.threshold updated')\n    else:\n        threshold = Config.threshold\n        _coefs = eval_dice_coef(\n            partial_set, predictions, batch_size=partial_set.batch_size, threshold=threshold)\n        mean_coef = _coefs.mean()\n        print(f'{threshold:.02} threshold: {mean_coef:.2%}')","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:44:01.703429Z","iopub.execute_input":"2023-07-27T19:44:01.703842Z","iopub.status.idle":"2023-07-27T19:44:02.762636Z","shell.execute_reply.started":"2023-07-27T19:44:01.703790Z","shell.execute_reply":"2023-07-27T19:44:02.760520Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"8/8 [==============================] - 1s 85ms/step\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[60], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m EVALUATE:\n\u001b[1;32m     12\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(tf_partial_set)\n\u001b[0;32m---> 14\u001b[0m     _coefs \u001b[38;5;241m=\u001b[39m \u001b[43meval_dice_coef\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf_partial_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpartial_set\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw/o threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_coefs\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Config\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m:\n","Cell \u001b[0;32mIn[60], line 4\u001b[0m, in \u001b[0;36meval_dice_coef\u001b[0;34m(sample_set, pred_set, n_batches, batch_size, threshold)\u001b[0m\n\u001b[1;32m      2\u001b[0m dice_coef_per_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(n_batches, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_batches):\n\u001b[0;32m----> 4\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[43msample_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m     pred \u001b[38;5;241m=\u001b[39m pred_set[idx\u001b[38;5;241m*\u001b[39mbatch_size:(idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mbatch_size]\n\u001b[1;32m      6\u001b[0m     _coef \u001b[38;5;241m=\u001b[39m dice_coef(y, pred, threshold\u001b[38;5;241m=\u001b[39mthreshold)\n","\u001b[0;31mTypeError\u001b[0m: '_PrefetchDataset' object is not subscriptable"],"ename":"TypeError","evalue":"'_PrefetchDataset' object is not subscriptable","output_type":"error"}]},{"cell_type":"code","source":"def plot_prediction(img, truth, pred):\n\n    fig, axs = plt.subplots(1, 4, figsize=(16, 8))\n\n    axs[0].imshow(img)\n    axs[0].set_title(\"Ash Color Image\")\n\n    axs[1].imshow(truth)\n    axs[1].set_title(\"Ground Truth\")\n\n    axs[2].imshow(pred)\n    axs[2].set_title(\"Prediction\")\n\n    axs[3].imshow(img)\n    axs[3].imshow(truth, cmap='Reds', alpha=.3, interpolation='none')\n    axs[3].set_title('Contrail mask on ash color image')\n\n    plt.tight_layout() \n    plt.show()\n\n    return\n\nif EVALUATE:\n    eval_images, eval_masks = partial_set[BATCH_IDX]\n    idx = SAMPLE_IDX\n    threshold = Config.threshold\n    plot_prediction(\n        eval_images[idx], eval_masks[idx], apply_threshold(predictions[idx], threshold))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:39:21.027979Z","iopub.status.idle":"2023-07-27T19:39:21.028595Z","shell.execute_reply.started":"2023-07-27T19:39:21.028324Z","shell.execute_reply":"2023-07-27T19:39:21.028351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make predictions on test dataset","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(tf_test_set)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:39:21.030529Z","iopub.status.idle":"2023-07-27T19:39:21.031441Z","shell.execute_reply.started":"2023-07-27T19:39:21.031179Z","shell.execute_reply":"2023-07-27T19:39:21.031203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:39:21.032840Z","iopub.status.idle":"2023-07-27T19:39:21.035734Z","shell.execute_reply.started":"2023-07-27T19:39:21.035469Z","shell.execute_reply":"2023-07-27T19:39:21.035495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create a submission","metadata":{}},{"cell_type":"code","source":"def rle_encode(x, fg_val=1):\n    \"\"\"\n    Args:\n        x:  numpy array of shape (height, width), 1 - mask, 0 - background\n    Returns: run length encoding as list\n    \"\"\"\n\n    dots = np.where(\n        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if b > prev + 1:\n            run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\n\ndef list_to_string(x):\n    \"\"\"\n    Converts list to a string representation\n    Empty list returns '-'\n    \"\"\"\n    if x: # non-empty list\n        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n    else:\n        s = '-'\n    return s\n","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:39:21.036948Z","iopub.status.idle":"2023-07-27T19:39:21.037865Z","shell.execute_reply.started":"2023-07-27T19:39:21.037613Z","shell.execute_reply":"2023-07-27T19:39:21.037636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_recs = os.listdir(os.path.join(DATA_DIR, 'test'))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:39:21.039238Z","iopub.status.idle":"2023-07-27T19:39:21.040073Z","shell.execute_reply.started":"2023-07-27T19:39:21.039812Z","shell.execute_reply":"2023-07-27T19:39:21.039836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'), index_col='record_id')[0:0]\n\nfor test_id, pred in zip(test_ids, predictions):\n    \n    mask = apply_threshold(pred, Config.threshold)\n    \n    # notice the we're converting rec to an `int` here:\n    submission.loc[int(test_id), 'encoded_pixels'] = list_to_string(rle_encode(mask))\n    \nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:39:21.041529Z","iopub.status.idle":"2023-07-27T19:39:21.042494Z","shell.execute_reply.started":"2023-07-27T19:39:21.042229Z","shell.execute_reply":"2023-07-27T19:39:21.042255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def strf_timedelta(timedelta):\n    total_seconds = timedelta.total_seconds()\n    hours, remainder = divmod(total_seconds, 3600)\n    minutes, seconds = divmod(remainder, 60)\n    return '{:02}:{:02}:{:02}'.format(int(hours), int(minutes), int(seconds))\n\nend_time = datetime.datetime.now(timezone('CET'))\n\nprint('Terminated', end_time.strftime(PRINT_TIME_FORMAT),\n      'in', strf_timedelta(end_time - start_time))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:39:21.043966Z","iopub.status.idle":"2023-07-27T19:39:21.044850Z","shell.execute_reply.started":"2023-07-27T19:39:21.044583Z","shell.execute_reply":"2023-07-27T19:39:21.044608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"THIS IS THE END!","metadata":{}}]}