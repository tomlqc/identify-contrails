{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Identify Contrails with Keras","metadata":{}},{"cell_type":"code","source":"# reinstall tensorflow-io\n# to avoid the UserWarning: unable to load libtensorflow_io_plugins.so\n\n#!pip install tensorflow-io","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:25:54.938188Z","iopub.execute_input":"2023-07-22T12:25:54.938571Z","iopub.status.idle":"2023-07-22T12:25:54.968753Z","shell.execute_reply.started":"2023-07-22T12:25:54.938534Z","shell.execute_reply":"2023-07-22T12:25:54.967477Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:25:54.970360Z","iopub.execute_input":"2023-07-22T12:25:54.971603Z","iopub.status.idle":"2023-07-22T12:25:54.984155Z","shell.execute_reply.started":"2023-07-22T12:25:54.971557Z","shell.execute_reply":"2023-07-22T12:25:54.983034Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# ==============================\n\nLOAD_CHECKPOINT = False  # <DEVEL>\nTRAIN = True  # <DEVEL>\n\nif os.path.exists('/kaggle'):\n    PLATFORM = 'kaggle'\nelse:\n    PLATFORM = 'gcp'\n\n# ==============================\n\nprint(f'PLATFORM = {PLATFORM}')\nprint()\nprint(f'LOAD_CHECKPOINT = {LOAD_CHECKPOINT}')\nprint(f'TRAIN = {TRAIN}')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:25:54.985622Z","iopub.execute_input":"2023-07-22T12:25:54.986249Z","iopub.status.idle":"2023-07-22T12:25:54.999352Z","shell.execute_reply.started":"2023-07-22T12:25:54.986210Z","shell.execute_reply":"2023-07-22T12:25:54.998373Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"PLATFORM = kaggle\n\nLOAD_CHECKPOINT = False\nTRAIN = True\n","output_type":"stream"}]},{"cell_type":"code","source":"if PLATFORM == 'kaggle':\n\n    WORK_DIR = '/kaggle/working'  # preserved if notebook is saved\n    TEMP_DIR = '/kaggle/temp'  # just during current session\n\n    DATA_DIR = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n    \n    WEIGHTS_DIR = WORK_DIR\n    \n    resnet50_imagenet_weights =\\\n        '/kaggle/input/d/alexisbcook/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n    # You can write up to 20GB to the current directory (/kaggle/working/)\n    # that gets preserved as output when you create a version using \"Save & Run All\" \n    # You can also write temporary files to /kaggle/temp/,\n    # but they won't be saved outside of the current session\n\nelif PLATFORM == 'gcp':\n\n    WORK_DIR = '/home/jupyter/kaggle/working'  # preserved if notebook is saved\n    TEMP_DIR = '/home/jupyter/kaggle/temp'  # just during current session  <DEVEL> CHECK THIS PATH!\n\n    DATA_DIR = '/home/jupyter/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n    \n    WEIGHTS_DIR = '/home/jupyter/identify-contrails-models'\n    \n    resnet50_imagenet_weights = 'imagenet'\n    \n    %cd $WORK_DIR\n\nprint('PWD =', os.getcwd())","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:25:55.001797Z","iopub.execute_input":"2023-07-22T12:25:55.002381Z","iopub.status.idle":"2023-07-22T12:25:55.013332Z","shell.execute_reply.started":"2023-07-22T12:25:55.002344Z","shell.execute_reply":"2023-07-22T12:25:55.011863Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"PWD = /kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"UPDATE_DATA = False\n\nif UPDATE_DATA:\n    %cp -v /kaggle/input/identify-contrails/contrails_2023*.h5 .\n    %ll","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:25:55.479732Z","iopub.execute_input":"2023-07-22T12:25:55.480443Z","iopub.status.idle":"2023-07-22T12:25:55.488431Z","shell.execute_reply.started":"2023-07-22T12:25:55.480398Z","shell.execute_reply":"2023-07-22T12:25:55.487266Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"if LOAD_CHECKPOINT:\n    prev_checkpoint_path = os.path.join(WEIGHTS_DIR, 'contrails_2023-07-20_22-39-56.h5')  # <DEVEL>\n    print(f'prev_checkpoint_path = {prev_checkpoint_path}')\n    if not os.path.exists(prev_checkpoint_path):\n        raise IOError(f'file does not exist {prev_checkpoint_path}')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:25:56.497574Z","iopub.execute_input":"2023-07-22T12:25:56.498981Z","iopub.status.idle":"2023-07-22T12:25:56.505810Z","shell.execute_reply.started":"2023-07-22T12:25:56.498921Z","shell.execute_reply":"2023-07-22T12:25:56.504876Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!touch submission.csv\n%ll -h","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:25:57.619923Z","iopub.execute_input":"2023-07-22T12:25:57.621222Z","iopub.status.idle":"2023-07-22T12:25:59.864929Z","shell.execute_reply.started":"2023-07-22T12:25:57.621172Z","shell.execute_reply":"2023-07-22T12:25:59.863076Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"total 1.2G\n---------- 1 root  263 Jul 22 12:23 __notebook_source__.ipynb\n-rw-r--r-- 1 root 109M Jul 22 12:23 contrails_2023-07-15_15-10-49.h5\n-rw-r--r-- 1 root 109M Jul 22 12:23 contrails_2023-07-19_22-57-53.h5\n-rw-r--r-- 1 root 137M Jul 22 12:23 contrails_2023-07-20_00-27-12.h5\n-rw-r--r-- 1 root  73M Jul 22 12:23 contrails_2023-07-20_09-33-34.h5\n-rw-r--r-- 1 root 109M Jul 22 12:23 contrails_2023-07-20_13-06-15.h5\n-rw-r--r-- 1 root 137M Jul 22 12:23 contrails_2023-07-20_22-06-31.h5\n-rw-r--r-- 1 root 137M Jul 22 12:23 contrails_2023-07-20_22-39-56.h5\n-rw-r--r-- 1 root 137M Jul 22 12:23 contrails_2023-07-21_10-01-58.h5\n-rw-r--r-- 1 root 109M Jul 22 12:23 contrails_2023-07-21_23-31-01.h5\n-rw-r--r-- 1 root 109M Jul 22 12:23 contrails_2023-07-21_23-54-37.h5\n-rw-r--r-- 1 root   75 Jul 22 12:25 submission.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport datetime\nimport math\nimport pathlib\nimport random\nimport shutil\n\nfrom multiprocessing import Pool\nfrom pytz import timezone\nfrom tqdm.notebook import tqdm\n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport scipy","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-07-22T12:26:03.761502Z","iopub.execute_input":"2023-07-22T12:26:03.762001Z","iopub.status.idle":"2023-07-22T12:26:03.893470Z","shell.execute_reply.started":"2023-07-22T12:26:03.761956Z","shell.execute_reply":"2023-07-22T12:26:03.892259Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"PRINT_TIME_FORMAT = \"%Y-%m-%d %H:%M:%S %Z%z\"\nFILE_TIME_FORMAT = \"%Y-%m-%d_%H-%M-%S\"\n\nstart_time = datetime.datetime.now(timezone('CET'))\n\nfile_time_str = start_time.strftime(FILE_TIME_FORMAT)\n\nprint('Started', start_time.strftime(PRINT_TIME_FORMAT))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:04.710673Z","iopub.execute_input":"2023-07-22T12:26:04.711151Z","iopub.status.idle":"2023-07-22T12:26:04.766769Z","shell.execute_reply.started":"2023-07-22T12:26:04.711114Z","shell.execute_reply":"2023-07-22T12:26:04.765486Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Started 2023-07-22 14:26:04 CEST+0200\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import backend as backend\n\nAUTOTUNE = tf.data.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:06.483229Z","iopub.execute_input":"2023-07-22T12:26:06.483723Z","iopub.status.idle":"2023-07-22T12:26:16.678258Z","shell.execute_reply.started":"2023-07-22T12:26:06.483664Z","shell.execute_reply":"2023-07-22T12:26:16.676939Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"print('TensorFlow version:', tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:16.680451Z","iopub.execute_input":"2023-07-22T12:26:16.681330Z","iopub.status.idle":"2023-07-22T12:26:16.688017Z","shell.execute_reply.started":"2023-07-22T12:26:16.681288Z","shell.execute_reply":"2023-07-22T12:26:16.686804Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"TensorFlow version: 2.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:16.689789Z","iopub.execute_input":"2023-07-22T12:26:16.690187Z","iopub.status.idle":"2023-07-22T12:26:16.710734Z","shell.execute_reply.started":"2023-07-22T12:26:16.690145Z","shell.execute_reply":"2023-07-22T12:26:16.709789Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Num CPUs Available:  1\nNum GPUs Available:  0\n","output_type":"stream"}]},{"cell_type":"code","source":"#---------------------------------------------------------------------------79","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:16.714012Z","iopub.execute_input":"2023-07-22T12:26:16.714620Z","iopub.status.idle":"2023-07-22T12:26:16.724738Z","shell.execute_reply.started":"2023-07-22T12:26:16.714568Z","shell.execute_reply":"2023-07-22T12:26:16.723355Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Setup dataset","metadata":{}},{"cell_type":"code","source":"class Paths:\n    train = os.path.join(DATA_DIR, 'train')\n    valid = os.path.join(DATA_DIR, 'validation')\n    test = os.path.join(DATA_DIR, 'test')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:16.726517Z","iopub.execute_input":"2023-07-22T12:26:16.726976Z","iopub.status.idle":"2023-07-22T12:26:16.739979Z","shell.execute_reply.started":"2023-07-22T12:26:16.726939Z","shell.execute_reply":"2023-07-22T12:26:16.738821Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"sort_list = sorted  # list | sorted  # <DEVEL>\n\ntrain_ids = sort_list(os.listdir(Paths.train))\nvalid_ids = sort_list(os.listdir(Paths.valid))\ntest_ids = sort_list(os.listdir(Paths.test))\nprint('n_samples (train, validation, test) =', len(train_ids), len(valid_ids), len(test_ids))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:16.741874Z","iopub.execute_input":"2023-07-22T12:26:16.742333Z","iopub.status.idle":"2023-07-22T12:26:17.113995Z","shell.execute_reply.started":"2023-07-22T12:26:16.742287Z","shell.execute_reply":"2023-07-22T12:26:17.112772Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"n_samples (train, validation, test) = 20529 1856 2\n","output_type":"stream"}]},{"cell_type":"code","source":"class ABI:\n    bands = {name: idx for idx, name in enumerate([\n        '08', '09', '10', '11', '12', '13', '14', '15', '16'])}\n    colors = {name: idx for idx, name in enumerate([\n        'red', 'blue', 'green', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'black'])}","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:17.852981Z","iopub.execute_input":"2023-07-22T12:26:17.853420Z","iopub.status.idle":"2023-07-22T12:26:17.861133Z","shell.execute_reply.started":"2023-07-22T12:26:17.853385Z","shell.execute_reply":"2023-07-22T12:26:17.859777Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"N_TIMES_BEFORE = 4\nN_TIMES_AFTER = 3","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:18.424920Z","iopub.execute_input":"2023-07-22T12:26:18.425478Z","iopub.status.idle":"2023-07-22T12:26:18.431792Z","shell.execute_reply.started":"2023-07-22T12:26:18.425428Z","shell.execute_reply":"2023-07-22T12:26:18.430802Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def normalize_range(data, bounds):\n    \"\"\"Maps data to the range [0, 1].\"\"\"\n    return (data - bounds[0]) / (bounds[1] - bounds[0])\n\n_T11_BOUNDS = (243, 303)\n_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n_TDIFF_BOUNDS = (-4, 2)\n\ndef get_ash_colors(sample_id, split_dir):\n    \"\"\"\n    Based on bands: 11, 14, 15\n    \n    Args:\n        sample_id(str): The id of the example i.e. '1000216489776414077'\n        split_dir(str): The split directoryu i.e. 'test', 'train', 'val'\n    \"\"\"\n    band15 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_15.npy\")\n    band14 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_14.npy\")\n    band11 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_11.npy\")\n\n    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)\n    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n    b = normalize_range(band14, _T11_BOUNDS)\n    ash_colors = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n    \n    return ash_colors","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:19.641518Z","iopub.execute_input":"2023-07-22T12:26:19.642059Z","iopub.status.idle":"2023-07-22T12:26:19.655629Z","shell.execute_reply.started":"2023-07-22T12:26:19.642008Z","shell.execute_reply":"2023-07-22T12:26:19.654517Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def get_individual_mask(sample_id, split_dir):\n    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_individual_masks.npy\"\n    pixel_mask = np.load(masks_path)\n    return pixel_mask\n\ndef get_pixel_mask(sample_id, split_dir):\n    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_pixel_masks.npy\"\n    pixel_mask = np.load(masks_path)\n    return pixel_mask","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:20.840506Z","iopub.execute_input":"2023-07-22T12:26:20.840972Z","iopub.status.idle":"2023-07-22T12:26:20.848963Z","shell.execute_reply.started":"2023-07-22T12:26:20.840935Z","shell.execute_reply":"2023-07-22T12:26:20.847610Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Check some values","metadata":{}},{"cell_type":"code","source":"sample_id = 7829917977180135058  # train_ids[3]\n\nprint(f'Check `ash_colors` on one of the samples: {sample_id}')\n\nash_colors = get_ash_colors(sample_id, 'train')[..., N_TIMES_BEFORE]\n\nprint(ash_colors.shape)\nfor color in range(3):\n    array = ash_colors[..., color]\n    print(array.min(), array.max())","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:22.861551Z","iopub.execute_input":"2023-07-22T12:26:22.862360Z","iopub.status.idle":"2023-07-22T12:26:23.001149Z","shell.execute_reply.started":"2023-07-22T12:26:22.862307Z","shell.execute_reply":"2023-07-22T12:26:22.999864Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Check `ash_colors` on one of the samples: 7829917977180135058\n(256, 256, 3)\n0.0 0.50921124\n0.097476535 0.86938816\n0.031865694 0.81146187\n","output_type":"stream"}]},{"cell_type":"code","source":"pixel_mask = get_pixel_mask(sample_id, 'train')\n\nprint(pixel_mask.shape)\nprint(pixel_mask.min(), pixel_mask.max())","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:24.137488Z","iopub.execute_input":"2023-07-22T12:26:24.138028Z","iopub.status.idle":"2023-07-22T12:26:24.155257Z","shell.execute_reply.started":"2023-07-22T12:26:24.137983Z","shell.execute_reply":"2023-07-22T12:26:24.154306Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"(256, 256, 1)\n0 1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{"execution":{"iopub.execute_input":"2023-07-10T19:30:33.222846Z","iopub.status.busy":"2023-07-10T19:30:33.222338Z","iopub.status.idle":"2023-07-10T19:30:33.228013Z","shell.execute_reply":"2023-07-10T19:30:33.227016Z","shell.execute_reply.started":"2023-07-10T19:30:33.222811Z"}}},{"cell_type":"code","source":"SEED = 42","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:26.362070Z","iopub.execute_input":"2023-07-22T12:26:26.362539Z","iopub.status.idle":"2023-07-22T12:26:26.367865Z","shell.execute_reply.started":"2023-07-22T12:26:26.362500Z","shell.execute_reply":"2023-07-22T12:26:26.366375Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class Config:  # <CONFIG>\n    \n    seed = SEED\n\n    img_size = (256, 256)\n    \n    model = 'unet'  # unet | deeplabv3plus\n    preprocess = None\n    backbone_trainable = True\n    \n    num_epochs = 15  # <DEVEL> else 10\n    num_classes = 1\n    batch_size = 16  # <DEVEL> else 16 or 32\n    \n    threshold = 'auto'","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:27.799104Z","iopub.execute_input":"2023-07-22T12:26:27.800711Z","iopub.status.idle":"2023-07-22T12:26:27.809003Z","shell.execute_reply.started":"2023-07-22T12:26:27.800622Z","shell.execute_reply":"2023-07-22T12:26:27.807630Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# https://keras.io/examples/keras_recipes/reproducibility_recipes/\n\n# Set the seed using keras.utils.set_random_seed. This will set:\n# 1) `numpy` seed\n# 2) `tensorflow` random seed\n# 3) `python` random seed\nkeras.utils.set_random_seed(Config.seed)\n\n# See also:\n# tf.config.experimental.enable_op_determinism()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:29.076531Z","iopub.execute_input":"2023-07-22T12:26:29.077017Z","iopub.status.idle":"2023-07-22T12:26:29.083621Z","shell.execute_reply.started":"2023-07-22T12:26:29.076980Z","shell.execute_reply":"2023-07-22T12:26:29.082321Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class UNet:\n    '''U-Net model.\n    \n    Inspired by and adapted from:\n    - https://keras.io/examples/vision/oxford_pets_image_segmentation\n    - https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580\n    - https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow/home/week/3\n    '''\n    \n    def __init__(self, preprocess=None, weights=None):\n        self.preprocess = preprocess\n        self.weights = weights\n        \n    def conv2d_block(self, input_tensor, n_filters, kernel_size=3):\n        x = input_tensor\n        for i in range(2):\n            x = tf.keras.layers.SeparableConv2D(\n                filters = n_filters, kernel_size=(kernel_size, kernel_size), padding='same')(x)\n            #? kernel_initializer = 'he_normal'\n            x = tf.keras.layers.BatchNormalization()(x)\n            x = tf.keras.layers.Activation('relu')(x)\n        return x\n\n    def encoder_block(self, inputs, n_filters, pool_size, dropout):\n        f = self.conv2d_block(inputs, n_filters=n_filters)\n        p = tf.keras.layers.MaxPooling2D(pool_size)(f)\n        p = tf.keras.layers.Dropout(dropout)(p)\n        return f, p\n\n    def encoder(self, inputs, dropout=0.1):\n        f1, p1 = self.encoder_block(inputs, n_filters=64, pool_size=(2,2), dropout=dropout)\n        f2, p2 = self.encoder_block(p1, n_filters=128, pool_size=(2,2), dropout=dropout)\n        f3, p3 = self.encoder_block(p2, n_filters=256, pool_size=(2,2), dropout=dropout)\n        f4, p4 = self.encoder_block(p3, n_filters=512, pool_size=(2,2), dropout=dropout)\n        return p4, (f1, f2, f3, f4)\n\n    def bottleneck(self, inputs):\n        bottle_neck = self.conv2d_block(inputs, n_filters=1024)\n        return bottle_neck\n\n    def decoder_block(self, inputs, conv_output, n_filters, kernel_size, strides, dropout):\n        u = tf.keras.layers.Conv2DTranspose(\n            n_filters, kernel_size, strides=strides, padding = 'same')(inputs)\n        u = tf.keras.layers.BatchNormalization()(u)\n        c = tf.keras.layers.concatenate([u, conv_output])\n        c = tf.keras.layers.Dropout(dropout)(c)\n        c = self.conv2d_block(c, n_filters, kernel_size=3)\n        return c\n\n    def decoder(self, inputs, convs, num_classes, dropout=0.1):\n        f1, f2, f3, f4 = convs\n        c6 = self.decoder_block(inputs, f4, n_filters=512, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        c7 = self.decoder_block(c6, f3, n_filters=256, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        c8 = self.decoder_block(c7, f2, n_filters=128, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        c9 = self.decoder_block(c8, f1, n_filters=64, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        if num_classes == 1:\n            activation = \"sigmoid\"\n        else:\n            activation = \"softmax\"\n        outputs = layers.Conv2D(num_classes, kernel_size=3, activation=activation, padding=\"same\")(c9)\n        return outputs\n\n    def model(self, image_size, num_classes):\n        inputs = tf.keras.layers.Input(shape=(image_size,image_size,3))\n        encoder_output, convs = self.encoder(inputs)\n        #model = tf.keras.Model(inputs=inputs, outputs=encoder_output)  # debug\n        bottle_neck = self.bottleneck(encoder_output)\n        outputs = self.decoder(bottle_neck, convs, num_classes)\n        model = tf.keras.Model(name=self.__class__.__name__, inputs=inputs, outputs=outputs)\n        return model","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:32.792066Z","iopub.execute_input":"2023-07-22T12:26:32.793090Z","iopub.status.idle":"2023-07-22T12:26:32.818985Z","shell.execute_reply.started":"2023-07-22T12:26:32.793042Z","shell.execute_reply":"2023-07-22T12:26:32.817716Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class DeepLabV3Plus:\n    '''DeepLabV3+ model.\n    \n    Adapted from:\n    - https://keras.io/examples/vision/deeplabv3_plus/#inference-using-colormap-overlay\n    '''\n    \n    def __init__(self, preprocess='resnet50', weights='imagenet', resnet50_trainable=True):\n        self.preprocess = preprocess\n        self.weights = weights\n        self.resnet50_trainable = resnet50_trainable\n    \n    def convolution_block(\n        self,\n        block_input,\n        num_filters=256,\n        kernel_size=3,\n        dilation_rate=1,\n        padding=\"same\",\n        use_bias=False,\n    ):\n        x = layers.Conv2D(\n            num_filters,\n            kernel_size=kernel_size,\n            dilation_rate=dilation_rate,\n            padding=\"same\",\n            use_bias=use_bias,\n            kernel_initializer=keras.initializers.HeNormal(),\n        )(block_input)\n        x = layers.BatchNormalization()(x)\n        return tf.nn.relu(x)\n\n    def DilatedSpatialPyramidPooling(self, dspp_input):\n        dims = dspp_input.shape\n        x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n        x = self.convolution_block(x, kernel_size=1, use_bias=True)\n        out_pool = layers.UpSampling2D(\n            size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n        )(x)\n\n        out_1 = self.convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n        out_6 = self.convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n        out_12 = self.convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n        out_18 = self.convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n\n        x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n        output = self.convolution_block(x, kernel_size=1)\n        return output\n    \n    def model(self, image_size, num_classes):\n        \n        model_input = keras.Input(shape=(image_size, image_size, 3))\n        \n        resnet50 = keras.applications.ResNet50(\n            weights=self.weights, include_top=False, input_tensor=model_input,\n        )\n        resnet50.trainable = self.resnet50_trainable\n        print('resnet50.trainable =', resnet50.trainable)\n        \n        x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n        x = self.DilatedSpatialPyramidPooling(x)\n\n        input_a = layers.UpSampling2D(\n            size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n            interpolation=\"bilinear\",\n        )(x)\n        input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n        input_b = self.convolution_block(input_b, num_filters=48, kernel_size=1)\n\n        x = layers.Concatenate(axis=-1)([input_a, input_b])\n        x = self.convolution_block(x)\n        x = self.convolution_block(x)\n        x = layers.UpSampling2D(\n            size=(image_size // x.shape[1], image_size // x.shape[2]),\n            interpolation=\"bilinear\",\n        )(x)\n        \n        if num_classes == 1:\n            activation = \"sigmoid\"\n        else:\n            activation = \"softmax\"\n        model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), activation=activation, padding=\"same\")(x)\n        \n        return keras.Model(name=self.__class__.__name__, inputs=model_input, outputs=model_output)    ","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:33.336147Z","iopub.execute_input":"2023-07-22T12:26:33.336903Z","iopub.status.idle":"2023-07-22T12:26:33.357150Z","shell.execute_reply.started":"2023-07-22T12:26:33.336859Z","shell.execute_reply":"2023-07-22T12:26:33.356154Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Free up RAM in case the model definition cells were run multiple times\nkeras.backend.clear_session()\n\n# Build model\nif Config.model == 'unet':\n    builder = UNet()\n\nelif Config.model == 'deeplabv3plus':\n    builder = DeepLabV3Plus(\n        preprocess=Config.preprocess,\n        weights=resnet50_imagenet_weights,\n        resnet50_trainable=Config.backbone_trainable,\n    )\n    \nelse:\n    raise NotImplementedError(f'model \"{Config.model}\"')\n    \nmodel = builder.model(image_size=Config.img_size[0], num_classes=Config.num_classes)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:35.645497Z","iopub.execute_input":"2023-07-22T12:26:35.645972Z","iopub.status.idle":"2023-07-22T12:26:37.502292Z","shell.execute_reply.started":"2023-07-22T12:26:35.645926Z","shell.execute_reply":"2023-07-22T12:26:37.499858Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Model: \"UNet\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n separable_conv2d (SeparableCon  (None, 256, 256, 64  283        ['input_1[0][0]']                \n v2D)                           )                                                                 \n                                                                                                  \n batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['separable_conv2d[0][0]']       \n alization)                     )                                                                 \n                                                                                                  \n activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    \n                                )                                                                 \n                                                                                                  \n separable_conv2d_1 (SeparableC  (None, 256, 256, 64  4736       ['activation[0][0]']             \n onv2D)                         )                                                                 \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['separable_conv2d_1[0][0]']     \n rmalization)                   )                                                                 \n                                                                                                  \n activation_1 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[0][0]']  \n                                )                                                                 \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['activation_1[0][0]']           \n                                )                                                                 \n                                                                                                  \n dropout (Dropout)              (None, 128, 128, 64  0           ['max_pooling2d[0][0]']          \n                                )                                                                 \n                                                                                                  \n separable_conv2d_2 (SeparableC  (None, 128, 128, 12  8896       ['dropout[0][0]']                \n onv2D)                         8)                                                                \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 128, 128, 12  512        ['separable_conv2d_2[0][0]']     \n rmalization)                   8)                                                                \n                                                                                                  \n activation_2 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_2[0][0]']  \n                                8)                                                                \n                                                                                                  \n separable_conv2d_3 (SeparableC  (None, 128, 128, 12  17664      ['activation_2[0][0]']           \n onv2D)                         8)                                                                \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['separable_conv2d_3[0][0]']     \n rmalization)                   8)                                                                \n                                                                                                  \n activation_3 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[0][0]']  \n                                8)                                                                \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['activation_3[0][0]']           \n                                                                                                  \n dropout_1 (Dropout)            (None, 64, 64, 128)  0           ['max_pooling2d_1[0][0]']        \n                                                                                                  \n separable_conv2d_4 (SeparableC  (None, 64, 64, 256)  34176      ['dropout_1[0][0]']              \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 64, 64, 256)  1024       ['separable_conv2d_4[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_4[0][0]']  \n                                                                                                  \n separable_conv2d_5 (SeparableC  (None, 64, 64, 256)  68096      ['activation_4[0][0]']           \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['separable_conv2d_5[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n activation_5 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[0][0]']  \n                                                                                                  \n max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['activation_5[0][0]']           \n                                                                                                  \n dropout_2 (Dropout)            (None, 32, 32, 256)  0           ['max_pooling2d_2[0][0]']        \n                                                                                                  \n separable_conv2d_6 (SeparableC  (None, 32, 32, 512)  133888     ['dropout_2[0][0]']              \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 32, 32, 512)  2048       ['separable_conv2d_6[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n activation_6 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_6[0][0]']  \n                                                                                                  \n separable_conv2d_7 (SeparableC  (None, 32, 32, 512)  267264     ['activation_6[0][0]']           \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 32, 32, 512)  2048       ['separable_conv2d_7[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n activation_7 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_7[0][0]']  \n                                                                                                  \n max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['activation_7[0][0]']           \n                                                                                                  \n dropout_3 (Dropout)            (None, 16, 16, 512)  0           ['max_pooling2d_3[0][0]']        \n                                                                                                  \n separable_conv2d_8 (SeparableC  (None, 16, 16, 1024  529920     ['dropout_3[0][0]']              \n onv2D)                         )                                                                 \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 16, 16, 1024  4096       ['separable_conv2d_8[0][0]']     \n rmalization)                   )                                                                 \n                                                                                                  \n activation_8 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_8[0][0]']  \n                                )                                                                 \n                                                                                                  \n separable_conv2d_9 (SeparableC  (None, 16, 16, 1024  1058816    ['activation_8[0][0]']           \n onv2D)                         )                                                                 \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 16, 16, 1024  4096       ['separable_conv2d_9[0][0]']     \n rmalization)                   )                                                                 \n                                                                                                  \n activation_9 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_9[0][0]']  \n                                )                                                                 \n                                                                                                  \n conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  4719104    ['activation_9[0][0]']           \n ose)                                                                                             \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_transpose[0][0]']       \n ormalization)                                                                                    \n                                                                                                  \n concatenate (Concatenate)      (None, 32, 32, 1024  0           ['batch_normalization_10[0][0]', \n                                )                                 'activation_7[0][0]']           \n                                                                                                  \n dropout_4 (Dropout)            (None, 32, 32, 1024  0           ['concatenate[0][0]']            \n                                )                                                                 \n                                                                                                  \n separable_conv2d_10 (Separable  (None, 32, 32, 512)  534016     ['dropout_4[0][0]']              \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 32, 32, 512)  2048       ['separable_conv2d_10[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n activation_10 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_11[0][0]'] \n                                                                                                  \n separable_conv2d_11 (Separable  (None, 32, 32, 512)  267264     ['activation_10[0][0]']          \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_12 (BatchN  (None, 32, 32, 512)  2048       ['separable_conv2d_11[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n activation_11 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_12[0][0]'] \n                                                                                                  \n conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  1179904    ['activation_11[0][0]']          \n spose)                                                                                           \n                                                                                                  \n batch_normalization_13 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_transpose_1[0][0]']     \n ormalization)                                                                                    \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['batch_normalization_13[0][0]', \n                                                                  'activation_5[0][0]']           \n                                                                                                  \n dropout_5 (Dropout)            (None, 64, 64, 512)  0           ['concatenate_1[0][0]']          \n                                                                                                  \n separable_conv2d_12 (Separable  (None, 64, 64, 256)  135936     ['dropout_5[0][0]']              \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_14 (BatchN  (None, 64, 64, 256)  1024       ['separable_conv2d_12[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n activation_12 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_14[0][0]'] \n                                                                                                  \n separable_conv2d_13 (Separable  (None, 64, 64, 256)  68096      ['activation_12[0][0]']          \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_15 (BatchN  (None, 64, 64, 256)  1024       ['separable_conv2d_13[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n activation_13 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_15[0][0]'] \n                                                                                                  \n conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  295040     ['activation_13[0][0]']          \n spose)                         8)                                                                \n                                                                                                  \n batch_normalization_16 (BatchN  (None, 128, 128, 12  512        ['conv2d_transpose_2[0][0]']     \n ormalization)                  8)                                                                \n                                                                                                  \n concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['batch_normalization_16[0][0]', \n                                6)                                'activation_3[0][0]']           \n                                                                                                  \n dropout_6 (Dropout)            (None, 128, 128, 25  0           ['concatenate_2[0][0]']          \n                                6)                                                                \n                                                                                                  \n separable_conv2d_14 (Separable  (None, 128, 128, 12  35200      ['dropout_6[0][0]']              \n Conv2D)                        8)                                                                \n                                                                                                  \n batch_normalization_17 (BatchN  (None, 128, 128, 12  512        ['separable_conv2d_14[0][0]']    \n ormalization)                  8)                                                                \n                                                                                                  \n activation_14 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_17[0][0]'] \n                                8)                                                                \n                                                                                                  \n separable_conv2d_15 (Separable  (None, 128, 128, 12  17664      ['activation_14[0][0]']          \n Conv2D)                        8)                                                                \n                                                                                                  \n batch_normalization_18 (BatchN  (None, 128, 128, 12  512        ['separable_conv2d_15[0][0]']    \n ormalization)                  8)                                                                \n                                                                                                  \n activation_15 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_18[0][0]'] \n                                8)                                                                \n                                                                                                  \n conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  73792      ['activation_15[0][0]']          \n spose)                         )                                                                 \n                                                                                                  \n batch_normalization_19 (BatchN  (None, 256, 256, 64  256        ['conv2d_transpose_3[0][0]']     \n ormalization)                  )                                                                 \n                                                                                                  \n concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['batch_normalization_19[0][0]', \n                                8)                                'activation_1[0][0]']           \n                                                                                                  \n dropout_7 (Dropout)            (None, 256, 256, 12  0           ['concatenate_3[0][0]']          \n                                8)                                                                \n                                                                                                  \n separable_conv2d_16 (Separable  (None, 256, 256, 64  9408       ['dropout_7[0][0]']              \n Conv2D)                        )                                                                 \n                                                                                                  \n batch_normalization_20 (BatchN  (None, 256, 256, 64  256        ['separable_conv2d_16[0][0]']    \n ormalization)                  )                                                                 \n                                                                                                  \n activation_16 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_20[0][0]'] \n                                )                                                                 \n                                                                                                  \n separable_conv2d_17 (Separable  (None, 256, 256, 64  4736       ['activation_16[0][0]']          \n Conv2D)                        )                                                                 \n                                                                                                  \n batch_normalization_21 (BatchN  (None, 256, 256, 64  256        ['separable_conv2d_17[0][0]']    \n ormalization)                  )                                                                 \n                                                                                                  \n activation_17 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_21[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d (Conv2D)                (None, 256, 256, 1)  577         ['activation_17[0][0]']          \n                                                                                                  \n==================================================================================================\nTotal params: 9,491,868\nTrainable params: 9,478,172\nNon-trainable params: 13,696\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prepare datasets","metadata":{"execution":{"iopub.execute_input":"2023-07-10T19:30:33.222846Z","iopub.status.busy":"2023-07-10T19:30:33.222338Z","iopub.status.idle":"2023-07-10T19:30:33.228013Z","shell.execute_reply":"2023-07-10T19:30:33.227016Z","shell.execute_reply.started":"2023-07-10T19:30:33.222811Z"}}},{"cell_type":"code","source":"N_TRAIN = 5120  # 512 <DEVEL> else None\nN_VALID = None  # 128 <DEVEL> else None\nN_PARTIAL = None  # 128","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:47.271602Z","iopub.execute_input":"2023-07-22T12:26:47.272110Z","iopub.status.idle":"2023-07-22T12:26:47.279192Z","shell.execute_reply.started":"2023-07-22T12:26:47.272066Z","shell.execute_reply":"2023-07-22T12:26:47.277728Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"print('preprocess =', builder.preprocess)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:26:50.877382Z","iopub.execute_input":"2023-07-22T12:26:50.877985Z","iopub.status.idle":"2023-07-22T12:26:50.885428Z","shell.execute_reply.started":"2023-07-22T12:26:50.877941Z","shell.execute_reply":"2023-07-22T12:26:50.884145Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"preprocess = None\n","output_type":"stream"}]},{"cell_type":"code","source":"class AshColorSingleFrames(keras.utils.Sequence):\n    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n\n    def __init__(self, batch_size, img_size, sample_ids, split_dir, preprocess=None, n_samples=None):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.split_dir = split_dir\n        self.sample_ids = sample_ids[:n_samples]\n        self.preprocess = preprocess\n\n    def __len__(self):\n        return math.ceil(len(self.sample_ids) / self.batch_size)\n\n    def __getitem__(self, idx):\n        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n        i = idx * self.batch_size\n        batch_sample_ids = self.sample_ids[i : i + self.batch_size]\n        \n        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n        for j, sample_id in enumerate(batch_sample_ids):\n            \n            img = get_ash_colors(sample_id, self.split_dir)[..., N_TIMES_BEFORE]\n            \n            if self.preprocess == 'resnet50':\n                img = keras.applications.resnet50.preprocess_input(img)\n            elif self.preprocess is not None:\n                raise NotImplementedError(f'preprocess \"{preprocess}\"')\n            \n            x[j] = img\n\n        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n        if self.split_dir != 'test':\n            for j, sample_id in enumerate(batch_sample_ids):\n                img = get_pixel_mask(sample_id, self.split_dir)\n                y[j] = img\n        \n        return x, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = AshColorSingleFrames(\n    Config.batch_size, Config.img_size, train_ids, 'train',\n    preprocess=builder.preprocess, n_samples=N_TRAIN)\nprint('number of batches:', len(train_set), 'train')\n\nvalid_set = AshColorSingleFrames(\n    Config.batch_size, Config.img_size, valid_ids, 'validation',\n    preprocess=builder.preprocess, n_samples=N_VALID)\nprint('number of batches:', len(valid_set), 'valid')\n\npartial_set = AshColorSingleFrames(\n    Config.batch_size, Config.img_size, valid_ids, 'validation',\n    preprocess=builder.preprocess, n_samples=N_PARTIAL)\nprint('number of batches:', len(partial_set), 'partial')\n\ntest_set = AshColorSingleFrames(\n    Config.batch_size, Config.img_size, test_ids, 'test',\n    preprocess=builder.preprocess)\nprint('number of batches:', len(test_set), 'test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Check dimensions (x, y) of first batch:')\n\ntrain_set[0][0].shape, train_set[0][1].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generate TFRecords","metadata":{}},{"cell_type":"code","source":"#%rm -r $TEMP_DIR  # <DEVEL>","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TFDataSetCreator:\n    \n    def __init__(self, keras_sequence):\n        self.keras_sequence = keras_sequence\n        self.split_dir = keras_sequence.split_dir\n        self.batch_size = keras_sequence.batch_size\n        self.record_paths = []\n\n    def generate_tfrec(self, keep_existing=True):\n\n        records_dir = os.path.join(TEMP_DIR, f'records-{self.batch_size}-{self.split_dir}')\n        os.makedirs(records_dir, exist_ok=True)\n        print(f'generating records in: {records_dir}')\n        %ll -h $TEMP_DIR\n\n        record_paths = []\n        for i_b in tqdm(range(len(self.keras_sequence))):\n            record_path = os.path.join(records_dir, f'batch_{i_b:04d}.tfrec')\n            record_paths.append(record_path)\n            if keep_existing and os.path.exists(record_path):\n                continue\n            x_b, y_b = self.keras_sequence[i_b]\n            with tf.io.TFRecordWriter(record_path) as writer:\n                for x, y in zip(x_b, y_b):\n                    feature = {\n                        \"x\": tf.train.Feature(\n                            bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(x).numpy()])),\n                        \"y\": tf.train.Feature(\n                            bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(y).numpy()])),\n                    }\n                    example = tf.train.Example(features=tf.train.Features(feature=feature))\n                    writer.write(example.SerializeToString())\n\n        !du -sh $records_dir\n        self.record_paths = record_paths\n        return self\n    \n    @staticmethod\n    def parse_tfrecord_sample(element):\n        parse_dic = {\n            'x': tf.io.FixedLenFeature([], tf.string),  # Note that it is tf.string, not tf.float32\n            'y': tf.io.FixedLenFeature([], tf.string),  # Note that it is tf.string, not tf.float32\n        }\n        feature = tf.io.parse_single_example(element, parse_dic)\n        feature['x'] = tf.io.parse_tensor(feature['x'], out_type=tf.float32)\n        feature['y'] = tf.io.parse_tensor(feature['y'], out_type=tf.uint8)\n        return feature\n\n    @staticmethod\n    def prepare_sample(features):\n        return features['x'], features['y']\n\n    def dataset(self):\n        dataset = (\n            tf.data.TFRecordDataset(self.record_paths, num_parallel_reads=AUTOTUNE)\n            .map(self.parse_tfrecord_sample, num_parallel_calls=AUTOTUNE)\n            .map(self.prepare_sample, num_parallel_calls=AUTOTUNE)\n            .shuffle(self.batch_size * 10)\n            .batch(self.batch_size)\n            .prefetch(AUTOTUNE)\n        )\n        return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def func(x):\n#    return x*x\n#\n#with Pool(processes=4) as pool:\n#    print(pool.map(func, range(10)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KEEP_EXISTING = True  # <DEVEL>\n\ntf_train_set = (\n    TFDataSetCreator(train_set)\n    .generate_tfrec(KEEP_EXISTING)\n    .dataset()\n)\n\ntf_valid_set = (\n    TFDataSetCreator(valid_set)\n    .generate_tfrec(KEEP_EXISTING)\n    .dataset()\n)\n\ntf_test_set = (\n    TFDataSetCreator(test_set)\n    .generate_tfrec(KEEP_EXISTING)\n    .dataset()\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for raw_record in tf_train_set.take(2):\n#    print(raw_record)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=0.001, threshold=None):\n    '''Dice coefficient.\n    \n    Adapted from:\n    - https://stackoverflow.com/questions/72195156/correct-implementation-of-dice-loss-in-tensorflow-keras\n    - https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580\n    '''\n    \n    y_true_f = backend.flatten(tf.cast(y_true, tf.float32))\n    y_pred_f = backend.flatten(tf.cast(y_pred, tf.float32))\n    # ValueError: No gradients provided for any variable\n    if threshold is not None:\n        y_pred_f = backend.flatten(\n            tf.cast(tf.math.greater(tf.cast(y_pred, tf.float32), threshold), tf.float32))\n    intersection = backend.sum(y_true_f * y_pred_f)\n    dice = (2. * intersection + smooth) / (backend.sum(y_true_f) + backend.sum(y_pred_f) + smooth)\n    return dice\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def threshold_dice_coef(y_true, y_pred, smooth=0.001):\n#    '''Dice coefficient with threshold set to Config.threshold.'''\n#    return dice_coef(y_true, y_pred, smooth=smooth, threshold=Config.threshold)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_id = 7829917977180135058  # train_ids[3]\n\nprint(f'Check dice_coef() on one of the samples: {sample_id}')\n\nmerged_mask = get_pixel_mask(sample_id, 'train')\nindiv_masks = get_individual_mask(sample_id, 'train')\n\nprint(dice_coef(tf.convert_to_tensor(merged_mask),\n                tf.convert_to_tensor(merged_mask)))\nfor idv in range(6):\n    print(dice_coef(tf.convert_to_tensor(merged_mask),\n                    tf.convert_to_tensor(indiv_masks[..., idv])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = f\"contrails_{file_time_str}.h5\"\n\nprint(f'checkpoint file: {checkpoint_path}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learning rate scheduler:\n# - https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules\n# - https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecay\n# Note: CosineDecay got warmup from v2.13.1 on\n\ninitial_learning_rate = 0.01\ndecay_steps = len(train_set)\ndecay_rate = 0.7\n\ncos_scheduler = keras.optimizers.schedules.CosineDecay(\n    initial_learning_rate, decay_steps)\n\nexp_scheduler = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate, decay_steps, decay_rate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configure the model for training.\n\n# We use the \"sparse\" version of categorical_crossentropy\n# because our target data is integers.\n# See also:\n# loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\nmodel.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=[dice_coef])\n\ncallbacks = [\n    #keras.callbacks.LearningRateScheduler(exp_scheduler),\n    keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True)\n]","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_CHECKPOINT:\n    # Loads the weights\n    model.load_weights(prev_checkpoint_path)\n    print(f'model loaded weights from {prev_checkpoint_path}')\n\nif TRAIN:\n    # Train the model, doing validation at the end of each epoch.\n    history = model.fit(\n        tf_train_set, epochs=Config.num_epochs, validation_data=tf_valid_set, callbacks=callbacks,\n        workers=4, use_multiprocessing=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    print('History', history.history.keys())\n\n    for var, yrange in [('loss', [0.0, 0.2]),\n                        ('dice_coef', [0.0, 0.8])]:\n        plt.figure(figsize=(10, 3))\n        plt.plot(history.history[var])\n        plt.plot(history.history[f'val_{var}'])\n        plt.ylim(yrange[0], yrange[1])\n        plt.title(f'model {var}')\n        plt.xlabel('epoch')\n        plt.ylabel(var)\n        plt.legend(['train', 'val'], loc='upper left')\n        plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"def apply_threshold(pred, threshold):\n    return (pred > threshold).astype(np.int8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EVALUATE = True\nALL_BATCHES = True\nBATCH_IDX = 0\nSAMPLE_IDX = 11","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if EVALUATE:    \n    # Evaluate the model\n\n    if ALL_BATCHES:\n        loss, acc = model.evaluate(partial_set, verbose=2)\n    else:\n        eval_images, eval_masks = partial_set[BATCH_IDX]\n        loss, acc = model.evaluate(eval_images, eval_masks, verbose=2)\n\n    print(\"Model accuracy: {:5.2f}%\".format(100 * acc))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_dice_coef(sample_set, pred_set, batch_size, threshold):\n    dice_coef_per_batch = np.full(len(sample_set), np.nan)\n    for idx in range(len(sample_set)):\n        x, y = sample_set[idx]\n        pred = pred_set[idx*batch_size:(idx + 1)*batch_size]\n        _coef = dice_coef(y, pred, threshold=threshold)\n        dice_coef_per_batch[idx] = _coef\n    return dice_coef_per_batch\n\nif EVALUATE:\n    \n    predictions = model.predict(partial_set)\n    \n    _coefs = eval_dice_coef(\n        partial_set, predictions, batch_size=partial_set.batch_size, threshold=None)\n    print(f'w/o threshold: {_coefs.mean():.2%}')\n    \n    if Config.threshold == 'auto':\n        best_coef = 0.\n        for threshold in np.arange(0.1, 0.8, 0.1):\n            _coefs = eval_dice_coef(\n                partial_set, predictions, batch_size=partial_set.batch_size, threshold=threshold)\n            mean_coef = _coefs.mean()\n            if mean_coef > best_coef:\n                best_coef = mean_coef\n                best_thresh = threshold\n            print(f'{threshold:.02} threshold: {mean_coef:.2%}')\n        print(f'best_threshold = {best_thresh:.02}')\n        Config.threshold = best_thresh\n        print('Config.threshold updated')\n    else:\n        threshold = Config.threshold\n        _coefs = eval_dice_coef(\n            partial_set, predictions, batch_size=partial_set.batch_size, threshold=threshold)\n        mean_coef = _coefs.mean()\n        print(f'{threshold:.02} threshold: {mean_coef:.2%}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_prediction(img, truth, pred):\n\n    fig, axs = plt.subplots(1, 4, figsize=(16, 8))\n\n    axs[0].imshow(img)\n    axs[0].set_title(\"Ash Color Image\")\n\n    axs[1].imshow(truth)\n    axs[1].set_title(\"Ground Truth\")\n\n    axs[2].imshow(pred)\n    axs[2].set_title(\"Prediction\")\n\n    axs[3].imshow(img)\n    axs[3].imshow(truth, cmap='Reds', alpha=.3, interpolation='none')\n    axs[3].set_title('Contrail mask on ash color image')\n\n    plt.tight_layout() \n    plt.show()\n\n    return\n\nif EVALUATE:\n    eval_images, eval_masks = partial_set[BATCH_IDX]\n    idx = SAMPLE_IDX\n    threshold = Config.threshold\n    plot_prediction(\n        eval_images[idx], eval_masks[idx], apply_threshold(predictions[idx], threshold))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make predictions on test dataset","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(test_set)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predictions)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create a submission","metadata":{}},{"cell_type":"code","source":"def rle_encode(x, fg_val=1):\n    \"\"\"\n    Args:\n        x:  numpy array of shape (height, width), 1 - mask, 0 - background\n    Returns: run length encoding as list\n    \"\"\"\n\n    dots = np.where(\n        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if b > prev + 1:\n            run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\n\ndef list_to_string(x):\n    \"\"\"\n    Converts list to a string representation\n    Empty list returns '-'\n    \"\"\"\n    if x: # non-empty list\n        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n    else:\n        s = '-'\n    return s\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_recs = os.listdir(os.path.join(DATA_DIR, 'test'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'), index_col='record_id')[0:0]\n\nfor test_id, pred in zip(test_ids, predictions):\n    \n    mask = apply_threshold(pred, Config.threshold)\n    \n    # notice the we're converting rec to an `int` here:\n    submission.loc[int(test_id), 'encoded_pixels'] = list_to_string(rle_encode(mask))\n    \nsubmission.to_csv('submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def strf_timedelta(timedelta):\n    total_seconds = timedelta.total_seconds()\n    hours, remainder = divmod(total_seconds, 3600)\n    minutes, seconds = divmod(remainder, 60)\n    return '{:02}:{:02}:{:02}'.format(int(hours), int(minutes), int(seconds))\n\nend_time = datetime.datetime.now(timezone('CET'))\n\nprint('Terminated', end_time.strftime(PRINT_TIME_FORMAT),\n      'in', strf_timedelta(end_time - start_time))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"THIS IS THE END!","metadata":{}}]}