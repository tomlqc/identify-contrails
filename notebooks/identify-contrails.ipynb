{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Identify Contrails with Keras","metadata":{}},{"cell_type":"code","source":"# reinstall tensorflow-io\n# to avoid the UserWarning: unable to load libtensorflow_io_plugins.so\n\n#!pip install tensorflow-io","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:05.675583Z","iopub.execute_input":"2023-07-14T20:53:05.676001Z","iopub.status.idle":"2023-07-14T20:53:05.681034Z","shell.execute_reply.started":"2023-07-14T20:53:05.675965Z","shell.execute_reply":"2023-07-14T20:53:05.679922Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport math\nimport pathlib\nimport random\nimport shutil\n\nfrom tqdm.notebook import tqdm\n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-14T20:53:05.686389Z","iopub.execute_input":"2023-07-14T20:53:05.686739Z","iopub.status.idle":"2023-07-14T20:53:05.696244Z","shell.execute_reply.started":"2023-07-14T20:53:05.686712Z","shell.execute_reply":"2023-07-14T20:53:05.695175Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import backend as backend","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:05.700014Z","iopub.execute_input":"2023-07-14T20:53:05.700289Z","iopub.status.idle":"2023-07-14T20:53:05.715531Z","shell.execute_reply.started":"2023-07-14T20:53:05.700245Z","shell.execute_reply":"2023-07-14T20:53:05.714527Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:05.717442Z","iopub.execute_input":"2023-07-14T20:53:05.717879Z","iopub.status.idle":"2023-07-14T20:53:05.729154Z","shell.execute_reply.started":"2023-07-14T20:53:05.717843Z","shell.execute_reply":"2023-07-14T20:53:05.728228Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"'2.12.0'"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:05.731208Z","iopub.execute_input":"2023-07-14T20:53:05.731641Z","iopub.status.idle":"2023-07-14T20:53:05.738553Z","shell.execute_reply.started":"2023-07-14T20:53:05.731609Z","shell.execute_reply":"2023-07-14T20:53:05.737433Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Num GPUs Available:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"%pwd","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:05.740294Z","iopub.execute_input":"2023-07-14T20:53:05.740809Z","iopub.status.idle":"2023-07-14T20:53:05.752173Z","shell.execute_reply.started":"2023-07-14T20:53:05.740779Z","shell.execute_reply":"2023-07-14T20:53:05.751310Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"#---------------------------------------------------------------------------79","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:05.753915Z","iopub.execute_input":"2023-07-14T20:53:05.754165Z","iopub.status.idle":"2023-07-14T20:53:05.759929Z","shell.execute_reply.started":"2023-07-14T20:53:05.754144Z","shell.execute_reply":"2023-07-14T20:53:05.758941Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"Following U-Net model is adapted from:\n- https://keras.io/examples/vision/oxford_pets_image_segmentation\n- https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580","metadata":{}},{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"WORK_DIR = '/kaggle/working'  # preserved if notebook is saved\nTEMP_DIR = '/kaggle/temp'  # just during current session\n\nDATA_DIR = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n\nclass Paths:\n    train = os.path.join(DATA_DIR, 'train')\n    valid = os.path.join(DATA_DIR, 'validation')\n    test = os.path.join(DATA_DIR, 'test')","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:05.761749Z","iopub.execute_input":"2023-07-14T20:53:05.762052Z","iopub.status.idle":"2023-07-14T20:53:05.770956Z","shell.execute_reply.started":"2023-07-14T20:53:05.762024Z","shell.execute_reply":"2023-07-14T20:53:05.770026Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"train_ids = os.listdir(Paths.train)\nvalid_ids = os.listdir(Paths.valid)\ntest_ids = os.listdir(Paths.test)\nprint(len(train_ids), len(valid_ids), len(test_ids))","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:05.773217Z","iopub.execute_input":"2023-07-14T20:53:05.773902Z","iopub.status.idle":"2023-07-14T20:53:06.006551Z","shell.execute_reply.started":"2023-07-14T20:53:05.773871Z","shell.execute_reply":"2023-07-14T20:53:06.005461Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"20529 1856 2\n","output_type":"stream"}]},{"cell_type":"code","source":"class ABI:\n    bands = {name: idx for idx, name in enumerate([\n        '08', '09', '10', '11', '12', '13', '14', '15', '16'])}\n    colors = {name: idx for idx, name in enumerate([\n        'red', 'blue', 'green', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'black'])}","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.008443Z","iopub.execute_input":"2023-07-14T20:53:06.009084Z","iopub.status.idle":"2023-07-14T20:53:06.015370Z","shell.execute_reply.started":"2023-07-14T20:53:06.009049Z","shell.execute_reply":"2023-07-14T20:53:06.014310Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"N_TIMES_BEFORE = 4\nN_TIMES_AFTER = 3","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.017049Z","iopub.execute_input":"2023-07-14T20:53:06.017819Z","iopub.status.idle":"2023-07-14T20:53:06.033934Z","shell.execute_reply.started":"2023-07-14T20:53:06.017701Z","shell.execute_reply":"2023-07-14T20:53:06.032954Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"def normalize_range(data, bounds):\n    \"\"\"Maps data to the range [0, 1].\"\"\"\n    return (data - bounds[0]) / (bounds[1] - bounds[0])\n\n_T11_BOUNDS = (243, 303)\n_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n_TDIFF_BOUNDS = (-4, 2)\n\ndef get_ash_colors(sample_id, split_dir):\n    \"\"\"\n    Based on bands: 11, 14, 15\n    \n    Args:\n        sample_id(str): The id of the example i.e. '1000216489776414077'\n        split_dir(str): The split directoryu i.e. 'test', 'train', 'val'\n    \"\"\"\n    band15 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_15.npy\")\n    band14 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_14.npy\")\n    band11 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_11.npy\")\n\n    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)\n    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n    b = normalize_range(band14, _T11_BOUNDS)\n    ash_colors = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n    \n    return ash_colors","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.037491Z","iopub.execute_input":"2023-07-14T20:53:06.037826Z","iopub.status.idle":"2023-07-14T20:53:06.047156Z","shell.execute_reply.started":"2023-07-14T20:53:06.037802Z","shell.execute_reply":"2023-07-14T20:53:06.046271Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"def get_individual_mask(sample_id, split_dir):\n    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_individual_masks.npy\"\n    pixel_mask = np.load(masks_path)\n    return pixel_mask","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.048936Z","iopub.execute_input":"2023-07-14T20:53:06.049630Z","iopub.status.idle":"2023-07-14T20:53:06.057778Z","shell.execute_reply.started":"2023-07-14T20:53:06.049596Z","shell.execute_reply":"2023-07-14T20:53:06.056893Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"def get_pixel_mask(sample_id, split_dir):\n    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_pixel_masks.npy\"\n    pixel_mask = np.load(masks_path)\n    return pixel_mask","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.059313Z","iopub.execute_input":"2023-07-14T20:53:06.060079Z","iopub.status.idle":"2023-07-14T20:53:06.068531Z","shell.execute_reply.started":"2023-07-14T20:53:06.060047Z","shell.execute_reply":"2023-07-14T20:53:06.067534Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"### Check some values (DEVEL)","metadata":{}},{"cell_type":"code","source":"sample_id = train_ids[3]\n\nash_colors = get_ash_colors(sample_id, 'train')[..., N_TIMES_BEFORE]\n\nprint(ash_colors.shape)\nfor color in range(3):\n    array = ash_colors[..., color]\n    print(array.min(), array.max())","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.070374Z","iopub.execute_input":"2023-07-14T20:53:06.071180Z","iopub.status.idle":"2023-07-14T20:53:06.155016Z","shell.execute_reply.started":"2023-07-14T20:53:06.071147Z","shell.execute_reply":"2023-07-14T20:53:06.154006Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"(256, 256, 3)\n0.0 0.50921124\n0.097476535 0.86938816\n0.031865694 0.81146187\n","output_type":"stream"}]},{"cell_type":"code","source":"pixel_mask = get_pixel_mask(sample_id, 'train')\n\nprint(pixel_mask.shape)\nprint(pixel_mask.min(), pixel_mask.max())","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.156556Z","iopub.execute_input":"2023-07-14T20:53:06.156892Z","iopub.status.idle":"2023-07-14T20:53:06.168891Z","shell.execute_reply.started":"2023-07-14T20:53:06.156860Z","shell.execute_reply":"2023-07-14T20:53:06.167909Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"(256, 256, 1)\n0 1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:30:33.222338Z","iopub.execute_input":"2023-07-10T19:30:33.222846Z","iopub.status.idle":"2023-07-10T19:30:33.228013Z","shell.execute_reply.started":"2023-07-10T19:30:33.222811Z","shell.execute_reply":"2023-07-10T19:30:33.227016Z"}}},{"cell_type":"code","source":"SEED = 42","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.171462Z","iopub.execute_input":"2023-07-14T20:53:06.172182Z","iopub.status.idle":"2023-07-14T20:53:06.176597Z","shell.execute_reply.started":"2023-07-14T20:53:06.172145Z","shell.execute_reply":"2023-07-14T20:53:06.175294Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"class Config:\n    \n    img_size = (256, 256)\n    \n    train = True\n    \n    num_epochs = 5  # <DEVEL> else 10\n    num_classes = 1\n    batch_size = 16  # <DEVEL> else 32\n    \n    seed = SEED\n","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.178358Z","iopub.execute_input":"2023-07-14T20:53:06.178819Z","iopub.status.idle":"2023-07-14T20:53:06.189293Z","shell.execute_reply.started":"2023-07-14T20:53:06.178785Z","shell.execute_reply":"2023-07-14T20:53:06.188218Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# https://keras.io/examples/keras_recipes/reproducibility_recipes/\n\n# Set the seed using keras.utils.set_random_seed. This will set:\n# 1) `numpy` seed\n# 2) `tensorflow` random seed\n# 3) `python` random seed\nkeras.utils.set_random_seed(Config.seed)\n\n# See also:\n# tf.config.experimental.enable_op_determinism()","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.190733Z","iopub.execute_input":"2023-07-14T20:53:06.191814Z","iopub.status.idle":"2023-07-14T20:53:06.255130Z","shell.execute_reply.started":"2023-07-14T20:53:06.191779Z","shell.execute_reply":"2023-07-14T20:53:06.253901Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"def get_model(img_size, num_classes):\n    \n    inputs = keras.Input(shape=img_size + (3,))\n\n    ### [First half of the network: downsampling inputs] ###\n\n    # Entry block\n    x = layers.Conv2D(24, 3, strides=2, padding=\"same\")(inputs)\n    x = layers.BatchNormalization()(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    # Blocks 1, 2, 3 are identical apart from the feature depth.\n    for filters in [64, 128, 256, 512]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    ### [Second half of the network: upsampling inputs] ###\n\n    for filters in [512, 256, 128, 64, 32]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.UpSampling2D(2)(x)\n\n        # Project residual\n        residual = layers.UpSampling2D(2)(previous_block_activation)\n        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    # Add a per-pixel classification layer\n    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n\n    # Define the model\n    model = keras.Model(inputs, outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.264271Z","iopub.execute_input":"2023-07-14T20:53:06.265296Z","iopub.status.idle":"2023-07-14T20:53:06.279351Z","shell.execute_reply.started":"2023-07-14T20:53:06.265244Z","shell.execute_reply":"2023-07-14T20:53:06.277928Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"Model inspired by:\n- file:///D:/Courses/2023-07_Advanced-Computer-Vision-with-TensorFlow/lecture-notes/C3_W3_Image-Segmentation.pdf","metadata":{}},{"cell_type":"code","source":"def conv2d_block(input_tensor, n_filters, kernel_size=3):\n    x = input_tensor\n    for i in range(2):\n        x = tf.keras.layers.SeparableConv2D(\n            filters = n_filters, kernel_size=(kernel_size, kernel_size), padding='same')(x)\n        #? kernel_initializer = 'he_normal'\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation('relu')(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.280911Z","iopub.execute_input":"2023-07-14T20:53:06.282496Z","iopub.status.idle":"2023-07-14T20:53:06.292988Z","shell.execute_reply.started":"2023-07-14T20:53:06.282461Z","shell.execute_reply":"2023-07-14T20:53:06.291977Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"def encoder_block(inputs, n_filters, pool_size, dropout):\n    f = conv2d_block(inputs, n_filters=n_filters)\n    p = tf.keras.layers.MaxPooling2D(pool_size)(f)\n    p = tf.keras.layers.Dropout(dropout)(p)\n    return f, p","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.294512Z","iopub.execute_input":"2023-07-14T20:53:06.295215Z","iopub.status.idle":"2023-07-14T20:53:06.307700Z","shell.execute_reply.started":"2023-07-14T20:53:06.295176Z","shell.execute_reply":"2023-07-14T20:53:06.306781Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"def encoder(inputs, dropout=0.1):\n    f1, p1 = encoder_block(inputs, n_filters=64, pool_size=(2,2), dropout=dropout)\n    f2, p2 = encoder_block(p1, n_filters=128, pool_size=(2,2), dropout=dropout)\n    f3, p3 = encoder_block(p2, n_filters=256, pool_size=(2,2), dropout=dropout)\n    f4, p4 = encoder_block(p3, n_filters=512, pool_size=(2,2), dropout=dropout)\n    return p4, (f1, f2, f3, f4)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.309157Z","iopub.execute_input":"2023-07-14T20:53:06.309798Z","iopub.status.idle":"2023-07-14T20:53:06.319382Z","shell.execute_reply.started":"2023-07-14T20:53:06.309766Z","shell.execute_reply":"2023-07-14T20:53:06.318472Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"def bottleneck(inputs):\n    bottle_neck = conv2d_block(inputs, n_filters=1024)\n    return bottle_neck","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.321144Z","iopub.execute_input":"2023-07-14T20:53:06.321836Z","iopub.status.idle":"2023-07-14T20:53:06.330357Z","shell.execute_reply.started":"2023-07-14T20:53:06.321804Z","shell.execute_reply":"2023-07-14T20:53:06.329374Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"def decoder_block(inputs, conv_output, n_filters, kernel_size, strides, dropout):\n    u = tf.keras.layers.Conv2DTranspose(\n        n_filters, kernel_size, strides=strides, padding = 'same')(inputs)\n    u = tf.keras.layers.BatchNormalization()(u)\n    c = tf.keras.layers.concatenate([u, conv_output])\n    c = tf.keras.layers.Dropout(dropout)(c)\n    c = conv2d_block(c, n_filters, kernel_size=3)\n    return c","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:53:06.331846Z","iopub.execute_input":"2023-07-14T20:53:06.332553Z","iopub.status.idle":"2023-07-14T20:53:06.342445Z","shell.execute_reply.started":"2023-07-14T20:53:06.332522Z","shell.execute_reply":"2023-07-14T20:53:06.341428Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"def decoder(inputs, convs, num_classes, dropout=0.1):\n    f1, f2, f3, f4 = convs\n    c6 = decoder_block(inputs, f4, n_filters=512, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n    c7 = decoder_block(c6, f3, n_filters=256, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n    c8 = decoder_block(c7, f2, n_filters=128, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n    c9 = decoder_block(c8, f1, n_filters=64, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n    if num_classes == 1:\n        activation = \"sigmoid\"\n    else:\n        activation = \"softmax\"\n    outputs = layers.Conv2D(num_classes, kernel_size=3, activation=activation, padding=\"same\")(c9)\n    return outputs","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:54:14.879350Z","iopub.execute_input":"2023-07-14T20:54:14.879798Z","iopub.status.idle":"2023-07-14T20:54:14.890838Z","shell.execute_reply.started":"2023-07-14T20:54:14.879761Z","shell.execute_reply":"2023-07-14T20:54:14.889628Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"def unet(image_size, num_classes):\n    inputs = tf.keras.layers.Input(shape=(image_size,image_size,3))\n    encoder_output, convs = encoder(inputs)\n    #model = tf.keras.Model(inputs=inputs, outputs=encoder_output)  # debug\n    bottle_neck = bottleneck(encoder_output)\n    outputs = decoder(bottle_neck, convs, num_classes)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:54:15.371645Z","iopub.execute_input":"2023-07-14T20:54:15.372388Z","iopub.status.idle":"2023-07-14T20:54:15.378644Z","shell.execute_reply.started":"2023-07-14T20:54:15.372341Z","shell.execute_reply":"2023-07-14T20:54:15.377598Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"# Free up RAM in case the model definition cells were run multiple times\nkeras.backend.clear_session()\n\n# Build model\n#model = get_model(Config.img_size, Config.num_classes)\nmodel = unet(image_size=256, num_classes=1)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:54:15.955163Z","iopub.execute_input":"2023-07-14T20:54:15.955846Z","iopub.status.idle":"2023-07-14T20:54:16.819978Z","shell.execute_reply.started":"2023-07-14T20:54:15.955813Z","shell.execute_reply":"2023-07-14T20:54:16.819206Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n separable_conv2d (SeparableCon  (None, 256, 256, 64  283        ['input_1[0][0]']                \n v2D)                           )                                                                 \n                                                                                                  \n batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['separable_conv2d[0][0]']       \n alization)                     )                                                                 \n                                                                                                  \n activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    \n                                )                                                                 \n                                                                                                  \n separable_conv2d_1 (SeparableC  (None, 256, 256, 64  4736       ['activation[0][0]']             \n onv2D)                         )                                                                 \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['separable_conv2d_1[0][0]']     \n rmalization)                   )                                                                 \n                                                                                                  \n activation_1 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[0][0]']  \n                                )                                                                 \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['activation_1[0][0]']           \n                                )                                                                 \n                                                                                                  \n dropout (Dropout)              (None, 128, 128, 64  0           ['max_pooling2d[0][0]']          \n                                )                                                                 \n                                                                                                  \n separable_conv2d_2 (SeparableC  (None, 128, 128, 12  8896       ['dropout[0][0]']                \n onv2D)                         8)                                                                \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 128, 128, 12  512        ['separable_conv2d_2[0][0]']     \n rmalization)                   8)                                                                \n                                                                                                  \n activation_2 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_2[0][0]']  \n                                8)                                                                \n                                                                                                  \n separable_conv2d_3 (SeparableC  (None, 128, 128, 12  17664      ['activation_2[0][0]']           \n onv2D)                         8)                                                                \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['separable_conv2d_3[0][0]']     \n rmalization)                   8)                                                                \n                                                                                                  \n activation_3 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[0][0]']  \n                                8)                                                                \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['activation_3[0][0]']           \n                                                                                                  \n dropout_1 (Dropout)            (None, 64, 64, 128)  0           ['max_pooling2d_1[0][0]']        \n                                                                                                  \n separable_conv2d_4 (SeparableC  (None, 64, 64, 256)  34176      ['dropout_1[0][0]']              \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 64, 64, 256)  1024       ['separable_conv2d_4[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_4[0][0]']  \n                                                                                                  \n separable_conv2d_5 (SeparableC  (None, 64, 64, 256)  68096      ['activation_4[0][0]']           \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['separable_conv2d_5[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n activation_5 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[0][0]']  \n                                                                                                  \n max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['activation_5[0][0]']           \n                                                                                                  \n dropout_2 (Dropout)            (None, 32, 32, 256)  0           ['max_pooling2d_2[0][0]']        \n                                                                                                  \n separable_conv2d_6 (SeparableC  (None, 32, 32, 512)  133888     ['dropout_2[0][0]']              \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 32, 32, 512)  2048       ['separable_conv2d_6[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n activation_6 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_6[0][0]']  \n                                                                                                  \n separable_conv2d_7 (SeparableC  (None, 32, 32, 512)  267264     ['activation_6[0][0]']           \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 32, 32, 512)  2048       ['separable_conv2d_7[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n activation_7 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_7[0][0]']  \n                                                                                                  \n max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['activation_7[0][0]']           \n                                                                                                  \n dropout_3 (Dropout)            (None, 16, 16, 512)  0           ['max_pooling2d_3[0][0]']        \n                                                                                                  \n separable_conv2d_8 (SeparableC  (None, 16, 16, 1024  529920     ['dropout_3[0][0]']              \n onv2D)                         )                                                                 \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 16, 16, 1024  4096       ['separable_conv2d_8[0][0]']     \n rmalization)                   )                                                                 \n                                                                                                  \n activation_8 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_8[0][0]']  \n                                )                                                                 \n                                                                                                  \n separable_conv2d_9 (SeparableC  (None, 16, 16, 1024  1058816    ['activation_8[0][0]']           \n onv2D)                         )                                                                 \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 16, 16, 1024  4096       ['separable_conv2d_9[0][0]']     \n rmalization)                   )                                                                 \n                                                                                                  \n activation_9 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_9[0][0]']  \n                                )                                                                 \n                                                                                                  \n conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  4719104    ['activation_9[0][0]']           \n ose)                                                                                             \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_transpose[0][0]']       \n ormalization)                                                                                    \n                                                                                                  \n concatenate (Concatenate)      (None, 32, 32, 1024  0           ['batch_normalization_10[0][0]', \n                                )                                 'activation_7[0][0]']           \n                                                                                                  \n dropout_4 (Dropout)            (None, 32, 32, 1024  0           ['concatenate[0][0]']            \n                                )                                                                 \n                                                                                                  \n separable_conv2d_10 (Separable  (None, 32, 32, 512)  534016     ['dropout_4[0][0]']              \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 32, 32, 512)  2048       ['separable_conv2d_10[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n activation_10 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_11[0][0]'] \n                                                                                                  \n separable_conv2d_11 (Separable  (None, 32, 32, 512)  267264     ['activation_10[0][0]']          \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_12 (BatchN  (None, 32, 32, 512)  2048       ['separable_conv2d_11[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n activation_11 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_12[0][0]'] \n                                                                                                  \n conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  1179904    ['activation_11[0][0]']          \n spose)                                                                                           \n                                                                                                  \n batch_normalization_13 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_transpose_1[0][0]']     \n ormalization)                                                                                    \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['batch_normalization_13[0][0]', \n                                                                  'activation_5[0][0]']           \n                                                                                                  \n dropout_5 (Dropout)            (None, 64, 64, 512)  0           ['concatenate_1[0][0]']          \n                                                                                                  \n separable_conv2d_12 (Separable  (None, 64, 64, 256)  135936     ['dropout_5[0][0]']              \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_14 (BatchN  (None, 64, 64, 256)  1024       ['separable_conv2d_12[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n activation_12 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_14[0][0]'] \n                                                                                                  \n separable_conv2d_13 (Separable  (None, 64, 64, 256)  68096      ['activation_12[0][0]']          \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_15 (BatchN  (None, 64, 64, 256)  1024       ['separable_conv2d_13[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n activation_13 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_15[0][0]'] \n                                                                                                  \n conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  295040     ['activation_13[0][0]']          \n spose)                         8)                                                                \n                                                                                                  \n batch_normalization_16 (BatchN  (None, 128, 128, 12  512        ['conv2d_transpose_2[0][0]']     \n ormalization)                  8)                                                                \n                                                                                                  \n concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['batch_normalization_16[0][0]', \n                                6)                                'activation_3[0][0]']           \n                                                                                                  \n dropout_6 (Dropout)            (None, 128, 128, 25  0           ['concatenate_2[0][0]']          \n                                6)                                                                \n                                                                                                  \n separable_conv2d_14 (Separable  (None, 128, 128, 12  35200      ['dropout_6[0][0]']              \n Conv2D)                        8)                                                                \n                                                                                                  \n batch_normalization_17 (BatchN  (None, 128, 128, 12  512        ['separable_conv2d_14[0][0]']    \n ormalization)                  8)                                                                \n                                                                                                  \n activation_14 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_17[0][0]'] \n                                8)                                                                \n                                                                                                  \n separable_conv2d_15 (Separable  (None, 128, 128, 12  17664      ['activation_14[0][0]']          \n Conv2D)                        8)                                                                \n                                                                                                  \n batch_normalization_18 (BatchN  (None, 128, 128, 12  512        ['separable_conv2d_15[0][0]']    \n ormalization)                  8)                                                                \n                                                                                                  \n activation_15 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_18[0][0]'] \n                                8)                                                                \n                                                                                                  \n conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  73792      ['activation_15[0][0]']          \n spose)                         )                                                                 \n                                                                                                  \n batch_normalization_19 (BatchN  (None, 256, 256, 64  256        ['conv2d_transpose_3[0][0]']     \n ormalization)                  )                                                                 \n                                                                                                  \n concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['batch_normalization_19[0][0]', \n                                8)                                'activation_1[0][0]']           \n                                                                                                  \n dropout_7 (Dropout)            (None, 256, 256, 12  0           ['concatenate_3[0][0]']          \n                                8)                                                                \n                                                                                                  \n separable_conv2d_16 (Separable  (None, 256, 256, 64  9408       ['dropout_7[0][0]']              \n Conv2D)                        )                                                                 \n                                                                                                  \n batch_normalization_20 (BatchN  (None, 256, 256, 64  256        ['separable_conv2d_16[0][0]']    \n ormalization)                  )                                                                 \n                                                                                                  \n activation_16 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_20[0][0]'] \n                                )                                                                 \n                                                                                                  \n separable_conv2d_17 (Separable  (None, 256, 256, 64  4736       ['activation_16[0][0]']          \n Conv2D)                        )                                                                 \n                                                                                                  \n batch_normalization_21 (BatchN  (None, 256, 256, 64  256        ['separable_conv2d_17[0][0]']    \n ormalization)                  )                                                                 \n                                                                                                  \n activation_17 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_21[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d (Conv2D)                (None, 256, 256, 1)  577         ['activation_17[0][0]']          \n                                                                                                  \n==================================================================================================\nTotal params: 9,491,868\nTrainable params: 9,478,172\nNon-trainable params: 13,696\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prepare datasets","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:30:33.222338Z","iopub.execute_input":"2023-07-10T19:30:33.222846Z","iopub.status.idle":"2023-07-10T19:30:33.228013Z","shell.execute_reply.started":"2023-07-10T19:30:33.222811Z","shell.execute_reply":"2023-07-10T19:30:33.227016Z"}}},{"cell_type":"code","source":"N_SAMPLES = None  # None to take all","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:54:23.884174Z","iopub.execute_input":"2023-07-14T20:54:23.884576Z","iopub.status.idle":"2023-07-14T20:54:23.889675Z","shell.execute_reply.started":"2023-07-14T20:54:23.884545Z","shell.execute_reply":"2023-07-14T20:54:23.888488Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"class AshColorSingleFrames(keras.utils.Sequence):\n    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n\n    def __init__(self, batch_size, img_size, sample_ids, split_dir, n_samples=None):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.split_dir = split_dir\n        self.sample_ids = sample_ids[:n_samples]\n\n    def __len__(self):\n        return math.ceil(len(self.sample_ids) / self.batch_size)\n\n    def __getitem__(self, idx):\n        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n        i = idx * self.batch_size\n        batch_sample_ids = self.sample_ids[i : i + self.batch_size]\n        \n        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n        for j, sample_id in enumerate(batch_sample_ids):\n            img = get_ash_colors(sample_id, self.split_dir)\n            x[j] = img[..., N_TIMES_BEFORE]\n\n        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n        if self.split_dir != 'test':\n            for j, sample_id in enumerate(batch_sample_ids):\n                img = get_pixel_mask(sample_id, self.split_dir)\n                y[j] = img\n        \n        return x, y","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:54:25.153470Z","iopub.execute_input":"2023-07-14T20:54:25.153820Z","iopub.status.idle":"2023-07-14T20:54:25.164388Z","shell.execute_reply.started":"2023-07-14T20:54:25.153792Z","shell.execute_reply":"2023-07-14T20:54:25.162779Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"train_set = AshColorSingleFrames(Config.batch_size, Config.img_size, train_ids, 'train',\n                                 n_samples=N_SAMPLES)  # <DEVEL>\nprint('number of batches:', len(train_set))","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:54:25.339979Z","iopub.execute_input":"2023-07-14T20:54:25.340354Z","iopub.status.idle":"2023-07-14T20:54:25.346979Z","shell.execute_reply.started":"2023-07-14T20:54:25.340325Z","shell.execute_reply":"2023-07-14T20:54:25.345849Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"number of batches: 1284\n","output_type":"stream"}]},{"cell_type":"code","source":"valid_set = AshColorSingleFrames(Config.batch_size, Config.img_size, valid_ids, 'validation',\n                                 n_samples=N_SAMPLES)  # <DEVEL>\nprint('number of batches:', len(valid_set))","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:54:25.535639Z","iopub.execute_input":"2023-07-14T20:54:25.536002Z","iopub.status.idle":"2023-07-14T20:54:25.544423Z","shell.execute_reply.started":"2023-07-14T20:54:25.535972Z","shell.execute_reply":"2023-07-14T20:54:25.543304Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"number of batches: 116\n","output_type":"stream"}]},{"cell_type":"code","source":"test_set = AshColorSingleFrames(Config.batch_size, Config.img_size, test_ids, 'test')\nprint('number of batches:', len(test_set))","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:54:25.687369Z","iopub.execute_input":"2023-07-14T20:54:25.687714Z","iopub.status.idle":"2023-07-14T20:54:25.693965Z","shell.execute_reply.started":"2023-07-14T20:54:25.687687Z","shell.execute_reply":"2023-07-14T20:54:25.692999Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"number of batches: 1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Check batch dimensions (x, y):","metadata":{}},{"cell_type":"code","source":"train_set[0][0].shape, train_set[0][1].shape","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:54:26.532309Z","iopub.execute_input":"2023-07-14T20:54:26.533399Z","iopub.status.idle":"2023-07-14T20:54:27.848072Z","shell.execute_reply.started":"2023-07-14T20:54:26.533361Z","shell.execute_reply":"2023-07-14T20:54:27.847149Z"},"trusted":true},"execution_count":104,"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"((16, 256, 256, 3), (16, 256, 256, 1))"},"metadata":{}}]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"`dice_coef` adapted from:\n- https://stackoverflow.com/questions/72195156/correct-implementation-of-dice-loss-in-tensorflow-keras\n- https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580","metadata":{}},{"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=0.001, threshold=0.5):\n    y_true_f = backend.flatten(tf.cast(y_true, tf.float32))\n    y_pred_f = backend.flatten(tf.cast(y_pred, tf.float32))\n    # ValueError: No gradients provided for any variable\n    #y_pred_f = backend.flatten(tf.cast(tf.math.greater(tf.cast(y_pred, tf.float32), threshold), tf.float32))\n    intersection = backend.sum(y_true_f * y_pred_f)\n    dice = (2. * intersection + smooth) / (backend.sum(y_true_f) + backend.sum(y_pred_f) + smooth)\n    return dice\n\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:54:29.657317Z","iopub.execute_input":"2023-07-14T20:54:29.657686Z","iopub.status.idle":"2023-07-14T20:54:29.666297Z","shell.execute_reply.started":"2023-07-14T20:54:29.657656Z","shell.execute_reply":"2023-07-14T20:54:29.665337Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":"Check `dice_coef()` on one of the samples.","metadata":{}},{"cell_type":"code","source":"sample_id = train_ids[3]\n\nmerged_mask = get_pixel_mask(sample_id, 'train')\nindiv_masks = get_individual_mask(sample_id, 'train')\n\nprint(dice_coef(tf.convert_to_tensor(merged_mask),\n                tf.convert_to_tensor(merged_mask)))\nfor idv in range(6):\n    print(dice_coef(tf.convert_to_tensor(merged_mask),\n                    tf.convert_to_tensor(indiv_masks[..., idv])))","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:54:33.421888Z","iopub.execute_input":"2023-07-14T20:54:33.422559Z","iopub.status.idle":"2023-07-14T20:54:33.475988Z","shell.execute_reply.started":"2023-07-14T20:54:33.422524Z","shell.execute_reply":"2023-07-14T20:54:33.474976Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"tf.Tensor(1.0, shape=(), dtype=float32)\ntf.Tensor(0.8743467, shape=(), dtype=float32)\ntf.Tensor(0.83587146, shape=(), dtype=float32)\ntf.Tensor(0.7393573, shape=(), dtype=float32)\ntf.Tensor(0.8522139, shape=(), dtype=float32)\ntf.Tensor(0.87988245, shape=(), dtype=float32)\ntf.Tensor(0.84089667, shape=(), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Learning rate scheduler:\n- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules\n- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecay - warmup only from v2.13.1 on","metadata":{}},{"cell_type":"code","source":"initial_learning_rate = 0.02\ndecay_steps = len(train_set)\ndecay_rate = 0.7\n\ncos_scheduler = keras.optimizers.schedules.CosineDecay(\n    initial_learning_rate, decay_steps)\n\nexp_scheduler = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate, decay_steps, decay_rate)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:54:34.595095Z","iopub.execute_input":"2023-07-14T20:54:34.595462Z","iopub.status.idle":"2023-07-14T20:54:34.601877Z","shell.execute_reply.started":"2023-07-14T20:54:34.595432Z","shell.execute_reply":"2023-07-14T20:54:34.600942Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"# Configure the model for training.\n# We use the \"sparse\" version of categorical_crossentropy\n# because our target data is integers.\n\nmodel.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=[dice_coef])\n#model.compile(optimizer=\"adam\", loss=dice_loss, metrics=[dice_coef])\n\ncallbacks = [\n    keras.callbacks.LearningRateScheduler(exp_scheduler),\n    keras.callbacks.ModelCheckpoint(\"contrails-unet.h5\", save_best_only=True)\n]","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:54:36.077295Z","iopub.execute_input":"2023-07-14T20:54:36.078013Z","iopub.status.idle":"2023-07-14T20:54:36.098284Z","shell.execute_reply.started":"2023-07-14T20:54:36.077974Z","shell.execute_reply":"2023-07-14T20:54:36.097401Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"# Train the model, doing validation at the end of each epoch.\nmodel.fit(train_set, epochs=Config.num_epochs, validation_data=valid_set, callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:54:36.619858Z","iopub.execute_input":"2023-07-14T20:54:36.620494Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"2023-07-14 20:54:43.554724: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":" 360/1284 [=======>......................] - ETA: 17:53 - loss: 0.0372 - dice_coef: 0.0075","output_type":"stream"}]},{"cell_type":"code","source":"#keras.backend.clear_session()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make predictions on test dataset","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(test_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create a submission","metadata":{}},{"cell_type":"code","source":"def rle_encode(x, fg_val=1):\n    \"\"\"\n    Args:\n        x:  numpy array of shape (height, width), 1 - mask, 0 - background\n    Returns: run length encoding as list\n    \"\"\"\n\n    dots = np.where(\n        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if b > prev + 1:\n            run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\n\ndef list_to_string(x):\n    \"\"\"\n    Converts list to a string representation\n    Empty list returns '-'\n    \"\"\"\n    if x: # non-empty list\n        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n    else:\n        s = '-'\n    return s\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_recs = os.listdir(os.path.join(DATA_DIR, 'test'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'), index_col='record_id')[0:0]\n\nfor test_id, mask in zip(test_ids, predictions):\n    \n    # notice the we're converting rec to an `int` here:\n    submission.loc[int(test_id), 'encoded_pixels'] = list_to_string(rle_encode(mask))\n    \nsubmission.to_csv('submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"UPDATED 00:16","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}