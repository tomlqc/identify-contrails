{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Identify Contrails with Keras","metadata":{}},{"cell_type":"code","source":"# reinstall tensorflow-io\n# to avoid the UserWarning: unable to load libtensorflow_io_plugins.so\n\n#!pip install tensorflow-io","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.539293Z","iopub.execute_input":"2023-07-10T19:27:19.539823Z","iopub.status.idle":"2023-07-10T19:27:19.544578Z","shell.execute_reply.started":"2023-07-10T19:27:19.539784Z","shell.execute_reply":"2023-07-10T19:27:19.543730Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"%pwd","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.563000Z","iopub.execute_input":"2023-07-10T19:27:19.563795Z","iopub.status.idle":"2023-07-10T19:27:19.570966Z","shell.execute_reply.started":"2023-07-10T19:27:19.563757Z","shell.execute_reply":"2023-07-10T19:27:19.569698Z"},"trusted":true},"execution_count":103,"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport pathlib\nimport random\nimport shutil\n\nfrom tqdm.notebook import tqdm\n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-10T19:27:19.581077Z","iopub.execute_input":"2023-07-10T19:27:19.582362Z","iopub.status.idle":"2023-07-10T19:27:19.587988Z","shell.execute_reply.started":"2023-07-10T19:27:19.582321Z","shell.execute_reply":"2023-07-10T19:27:19.587073Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"# This notebook is inspired by:\n\n# Visualization:\n# - https://www.kaggle.com/code/inversion/visualizing-contrails\n# - https://www.kaggle.com/code/pranavnadimpali/comprehensive-eda-submission\n\n# Models:\n# - https://keras.io/examples/vision/oxford_pets_image_segmentation/\n# - https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.603065Z","iopub.execute_input":"2023-07-10T19:27:19.603913Z","iopub.status.idle":"2023-07-10T19:27:19.608325Z","shell.execute_reply.started":"2023-07-10T19:27:19.603874Z","shell.execute_reply":"2023-07-10T19:27:19.607460Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"#---------------------------------------------------------------------------79","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.635002Z","iopub.execute_input":"2023-07-10T19:27:19.635649Z","iopub.status.idle":"2023-07-10T19:27:19.639380Z","shell.execute_reply.started":"2023-07-10T19:27:19.635584Z","shell.execute_reply":"2023-07-10T19:27:19.638553Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"class ABI:\n    bands = {name: idx for idx, name in enumerate([\n        '08', '09', '10', '11', '12', '13', '14', '15', '16'])}\n    colors = {name: idx for idx, name in enumerate([\n        'red', 'blue', 'green', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'black'])}","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.645355Z","iopub.execute_input":"2023-07-10T19:27:19.645976Z","iopub.status.idle":"2023-07-10T19:27:19.652667Z","shell.execute_reply.started":"2023-07-10T19:27:19.645942Z","shell.execute_reply":"2023-07-10T19:27:19.651648Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"N_TIMES_BEFORE = 4\nN_TIMES_AFTER = 3","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.658104Z","iopub.execute_input":"2023-07-10T19:27:19.658870Z","iopub.status.idle":"2023-07-10T19:27:19.664601Z","shell.execute_reply.started":"2023-07-10T19:27:19.658835Z","shell.execute_reply":"2023-07-10T19:27:19.663177Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"WORK_DIR = '/kaggle/working'  # preserved if notebook is saved\nTEMP_DIR = '/kaggle/temp'  # just during current session\n\nDATA_DIR = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n\nclass Paths:\n    train = os.path.join(DATA_DIR, 'train')\n    valid = os.path.join(DATA_DIR, 'validation')\n","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.676274Z","iopub.execute_input":"2023-07-10T19:27:19.676707Z","iopub.status.idle":"2023-07-10T19:27:19.682192Z","shell.execute_reply.started":"2023-07-10T19:27:19.676676Z","shell.execute_reply":"2023-07-10T19:27:19.681327Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"markdown","source":"## Data Analysis and Visualization","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:12:44.041834Z","iopub.execute_input":"2023-07-09T16:12:44.042298Z","iopub.status.idle":"2023-07-09T16:12:44.046633Z","shell.execute_reply.started":"2023-07-09T16:12:44.042265Z","shell.execute_reply":"2023-07-09T16:12:44.045618Z"}}},{"cell_type":"code","source":"DRAW = False","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.686748Z","iopub.execute_input":"2023-07-10T19:27:19.687710Z","iopub.status.idle":"2023-07-10T19:27:19.707922Z","shell.execute_reply.started":"2023-07-10T19:27:19.687675Z","shell.execute_reply":"2023-07-10T19:27:19.706755Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"train_ids = os.listdir(Paths.train)\nvalid_ids = os.listdir(Paths.valid)\nprint(len(train_ids), len(valid_ids))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.709569Z","iopub.execute_input":"2023-07-10T19:27:19.710503Z","iopub.status.idle":"2023-07-10T19:27:19.730715Z","shell.execute_reply.started":"2023-07-10T19:27:19.710467Z","shell.execute_reply":"2023-07-10T19:27:19.729674Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"20529 1856\n","output_type":"stream"}]},{"cell_type":"code","source":"pixel_mask = np.load(os.path.join(DATA_DIR, 'train', train_ids[3], 'human_pixel_masks.npy'))\nprint(pixel_mask.shape)\nprint(pixel_mask.min(), pixel_mask.max())","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.732344Z","iopub.execute_input":"2023-07-10T19:27:19.732910Z","iopub.status.idle":"2023-07-10T19:27:19.741199Z","shell.execute_reply.started":"2023-07-10T19:27:19.732875Z","shell.execute_reply":"2023-07-10T19:27:19.740007Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"(256, 256, 1)\n0 1\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_ids = train_ids","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.743308Z","iopub.execute_input":"2023-07-10T19:27:19.743675Z","iopub.status.idle":"2023-07-10T19:27:19.748571Z","shell.execute_reply.started":"2023-07-10T19:27:19.743643Z","shell.execute_reply":"2023-07-10T19:27:19.747765Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"def plot_bands_over_time(sample_id, split_dir):\n    \"\"\"\n    \n    Adapted from:\n    https://www.kaggle.com/code/pranavnadimpali/comprehensive-eda-submission\n    \n    Args: \n        sample_id(str): The id of the example i.e. '1000216489776414077'\n        split_dir(str): The split directoryu i.e. 'test', 'train', 'val'\n    \"\"\"\n    fig, axs = plt.subplots(8, len(ABI.bands), figsize=(16, 16)) \n\n    for band, j in ABI.bands.items():\n        img = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_{band}.npy\")\n        for i in range(8):\n            axs[i, j].imshow(img[..., i]) \n            axs[i, j].set_title(f\"Band {band}\\nTime Step {i+1}\") \n\n    plt.tight_layout()  \n    plt.show()\n    \nif DRAW:\n    plot_bands_over_time(sample_ids[3], 'train')","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.749618Z","iopub.execute_input":"2023-07-10T19:27:19.749961Z","iopub.status.idle":"2023-07-10T19:27:19.759619Z","shell.execute_reply.started":"2023-07-10T19:27:19.749932Z","shell.execute_reply":"2023-07-10T19:27:19.758672Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"def normalize_range(data, bounds):\n    \"\"\"Maps data to the range [0, 1].\"\"\"\n    return (data - bounds[0]) / (bounds[1] - bounds[0])\n\n_T11_BOUNDS = (243, 303)\n_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n_TDIFF_BOUNDS = (-4, 2)\n\ndef get_ash_colors(sample_id, split_dir):\n    \"\"\"\n    Based on bands: 11, 14, 15\n    \n    Args:\n        sample_id(str): The id of the example i.e. '1000216489776414077'\n        split_dir(str): The split directoryu i.e. 'test', 'train', 'val'\n    \"\"\"\n    band15 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_15.npy\")\n    band14 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_14.npy\")\n    band11 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_11.npy\")\n\n    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)\n    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n    b = normalize_range(band14, _T11_BOUNDS)\n    ash_colors = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n    \n    return ash_colors","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.761399Z","iopub.execute_input":"2023-07-10T19:27:19.762064Z","iopub.status.idle":"2023-07-10T19:27:19.772302Z","shell.execute_reply.started":"2023-07-10T19:27:19.761913Z","shell.execute_reply":"2023-07-10T19:27:19.771244Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"def get_pixel_mask(sample_id, split_dir):\n    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_pixel_masks.npy\"\n    pixel_mask = np.load(masks_path)\n    return pixel_mask","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.777696Z","iopub.execute_input":"2023-07-10T19:27:19.778528Z","iopub.status.idle":"2023-07-10T19:27:19.787211Z","shell.execute_reply.started":"2023-07-10T19:27:19.778490Z","shell.execute_reply":"2023-07-10T19:27:19.786020Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"def plot_ash_colors(sample_id, split_dir, plot, time_step=4):\n\n    ash_colors = get_ash_colors(sample_id, split_dir)\n    img = ash_colors[..., time_step] # 5th image corresponds to ground truth\n    \n    ground_truth = get_pixel_mask(sample_id, split_dir)\n    \n    if plot:\n        fig, axs = plt.subplots(1, 3, figsize=(16, 8))\n\n        axs[0].imshow(img)\n        axs[0].set_title(\"Ash Color Image\")\n\n        axs[1].imshow(ground_truth)\n        axs[1].set_title(\"Ground Truth\")\n\n        axs[2].imshow(img)\n        axs[2].imshow(ground_truth, cmap='Reds', alpha=.3, interpolation='none')\n        axs[2].set_title('Contrail mask on ash color image')\n\n\n        plt.tight_layout() \n        plt.show()\n\n    return img\n    \nif DRAW:\n    plot_ash_colors(sample_ids[3], 'train', True)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.789161Z","iopub.execute_input":"2023-07-10T19:27:19.789742Z","iopub.status.idle":"2023-07-10T19:27:19.803614Z","shell.execute_reply.started":"2023-07-10T19:27:19.789707Z","shell.execute_reply":"2023-07-10T19:27:19.802342Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"def plot_three_bands(sample_id, split_dir, bands, timestep=4):\n    \"\"\"\n    \n    Adapted from:\n    https://www.kaggle.com/code/pranavnadimpali/comprehensive-eda-submission\n    \n    Args: \n        sample_id(str): The id of the example i.e. '1000216489776414077'\n        split_dir(str): The split directoryu i.e. 'test', 'train', 'val'\n    \"\"\"\n    fig, axs = plt.subplots(1, 3, figsize=(16, 16)) \n\n    for j, band in enumerate(bands):\n        img = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_{band}.npy\")\n        axs[j].imshow(img[..., timestep]) \n        axs[j].set_title(f\"Band {band}\\nTime Step {timestep+1}\") \n\n    plt.tight_layout()  \n    plt.show()\n    \nif DRAW:\n    plot_three_bands(sample_ids[3], 'train', ['11', '14', '15'])\n    plot_three_bands(sample_ids[3], 'train', ['08', '09', '10'])\n    plot_three_bands(sample_ids[3], 'train', ['12', '13', '16'])","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-07-10T19:27:19.805424Z","iopub.execute_input":"2023-07-10T19:27:19.805961Z","iopub.status.idle":"2023-07-10T19:27:19.816523Z","shell.execute_reply.started":"2023-07-10T19:27:19.805925Z","shell.execute_reply":"2023-07-10T19:27:19.815339Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"ash_path = pathlib.Path(os.path.join(TEMP_DIR, 'ash_colors_images'))\nash_path.mkdir(exist_ok=True, parents=True)\n\nash_path.resolve()  # get absolute path","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.821059Z","iopub.execute_input":"2023-07-10T19:27:19.821429Z","iopub.status.idle":"2023-07-10T19:27:19.839308Z","shell.execute_reply.started":"2023-07-10T19:27:19.821397Z","shell.execute_reply":"2023-07-10T19:27:19.837364Z"},"trusted":true},"execution_count":119,"outputs":[{"execution_count":119,"output_type":"execute_result","data":{"text/plain":"PosixPath('/kaggle/temp/ash_colors_images')"},"metadata":{}}]},{"cell_type":"code","source":"#shutil.rmtree(ash_path)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.841101Z","iopub.execute_input":"2023-07-10T19:27:19.842006Z","iopub.status.idle":"2023-07-10T19:27:19.846788Z","shell.execute_reply.started":"2023-07-10T19:27:19.841971Z","shell.execute_reply":"2023-07-10T19:27:19.845467Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"split_dir = 'train'\n\n# 1 images take about 3 MB with all 8 timesteps. \n# train set has 20529 samples, i.e. it would take 60 GB.\n\nif False:\n\n    print('convert to ash colors')\n    for sample_id in tqdm(train_ids[:100]):\n\n        ash_colors = get_ash_colors(sample_id, split_dir)\n        #pixel_mask = get_pixel_mask(sample_id, split_dir)\n    \n    # 59.68it/s\n    # 1 s/sample\n\nif False:\n    print('convert to ash colors and write')\n    for sample_id in tqdm(train_ids[:100]):\n\n        ash_colors = get_ash_colors(sample_id, split_dir)\n        #pixel_mask = get_pixel_mask(sample_id, split_dir)\n\n        ash_colors = ash_colors.astype(np.float16)\n\n        image_path = ash_path/f\"{sample_id}.npy\"\n        np.save(str(image_path), ash_colors)\n        \n    # 21.64it/s\n    # 3 s/sample\n        \nif False:\n    print('read')\n    for sample_id in tqdm(train_ids[:100]):\n\n        image_path = ash_path/f\"{sample_id}.npy\"\n        np.load(str(image_path))\n    \n    # 634.78it/s\n    # 0.1 s/sample\n    # But is this true or are the files still cached by the OS?","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:27:19.855075Z","iopub.execute_input":"2023-07-10T19:27:19.855664Z","iopub.status.idle":"2023-07-10T19:27:19.864461Z","shell.execute_reply.started":"2023-07-10T19:27:19.855618Z","shell.execute_reply":"2023-07-10T19:27:19.863557Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"markdown","source":"## Build model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import backend as backend","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:52:03.037974Z","iopub.execute_input":"2023-07-10T19:52:03.039237Z","iopub.status.idle":"2023-07-10T19:52:03.044246Z","shell.execute_reply.started":"2023-07-10T19:52:03.039191Z","shell.execute_reply":"2023-07-10T19:52:03.043154Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"SEED = 42","metadata":{"execution":{"iopub.status.busy":"2023-07-10T20:03:24.549187Z","iopub.execute_input":"2023-07-10T20:03:24.549639Z","iopub.status.idle":"2023-07-10T20:03:24.554872Z","shell.execute_reply.started":"2023-07-10T20:03:24.549604Z","shell.execute_reply":"2023-07-10T20:03:24.553633Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"class Config:\n    \n    img_size = (256, 256)\n    \n    train = True\n    \n    num_epochs = 10\n    num_classes = 1\n    batch_size = 32\n    \n    seed = SEED\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-10T20:03:26.055044Z","iopub.execute_input":"2023-07-10T20:03:26.055483Z","iopub.status.idle":"2023-07-10T20:03:26.061388Z","shell.execute_reply.started":"2023-07-10T20:03:26.055447Z","shell.execute_reply":"2023-07-10T20:03:26.059946Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"# https://keras.io/examples/keras_recipes/reproducibility_recipes/\n\n# Set the seed using keras.utils.set_random_seed. This will set:\n# 1) `numpy` seed\n# 2) `tensorflow` random seed\n# 3) `python` random seed\nkeras.utils.set_random_seed(Config.seed)\n\n# See also:\n# tf.config.experimental.enable_op_determinism()","metadata":{"execution":{"iopub.status.busy":"2023-07-10T20:03:27.019701Z","iopub.execute_input":"2023-07-10T20:03:27.020106Z","iopub.status.idle":"2023-07-10T20:03:27.054292Z","shell.execute_reply.started":"2023-07-10T20:03:27.020076Z","shell.execute_reply":"2023-07-10T20:03:27.053015Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"markdown","source":"Following U-Net model is adapted from: https://keras.io/examples/vision/oxford_pets_image_segmentation","metadata":{}},{"cell_type":"code","source":"def get_model(img_size, num_classes):\n    inputs = keras.Input(shape=img_size + (3,))\n\n    ### [First half of the network: downsampling inputs] ###\n\n    # Entry block\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n    x = layers.BatchNormalization()(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    # Blocks 1, 2, 3 are identical apart from the feature depth.\n    for filters in [64, 128, 256]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    ### [Second half of the network: upsampling inputs] ###\n\n    for filters in [256, 128, 64, 32]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.UpSampling2D(2)(x)\n\n        # Project residual\n        residual = layers.UpSampling2D(2)(previous_block_activation)\n        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    # Add a per-pixel classification layer\n    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n\n    # Define the model\n    model = keras.Model(inputs, outputs)\n    return model\n\n\n# Free up RAM in case the model definition cells were run multiple times\nkeras.backend.clear_session()\n\n# Build model\nmodel = get_model(Config.img_size, Config.num_classes)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-10T20:03:28.379536Z","iopub.execute_input":"2023-07-10T20:03:28.380011Z","iopub.status.idle":"2023-07-10T20:03:29.372053Z","shell.execute_reply.started":"2023-07-10T20:03:28.379972Z","shell.execute_reply":"2023-07-10T20:03:29.370981Z"},"trusted":true},"execution_count":168,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d (Conv2D)                (None, 128, 128, 32  896         ['input_1[0][0]']                \n                                )                                                                 \n                                                                                                  \n batch_normalization (BatchNorm  (None, 128, 128, 32  128        ['conv2d[0][0]']                 \n alization)                     )                                                                 \n                                                                                                  \n activation (Activation)        (None, 128, 128, 32  0           ['batch_normalization[0][0]']    \n                                )                                                                 \n                                                                                                  \n separable_conv2d (SeparableCon  (None, 128, 128, 64  2400       ['activation[0][0]']             \n v2D)                           )                                                                 \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 128, 128, 64  256        ['separable_conv2d[0][0]']       \n rmalization)                   )                                                                 \n                                                                                                  \n activation_1 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_1[0][0]']  \n                                )                                                                 \n                                                                                                  \n separable_conv2d_1 (SeparableC  (None, 128, 128, 64  4736       ['activation_1[0][0]']           \n onv2D)                         )                                                                 \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 128, 128, 64  256        ['separable_conv2d_1[0][0]']     \n rmalization)                   )                                                                 \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 64, 64, 64)   0           ['batch_normalization_2[0][0]']  \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 64, 64, 64)   2112        ['batch_normalization[0][0]']    \n                                                                                                  \n add (Add)                      (None, 64, 64, 64)   0           ['max_pooling2d[0][0]',          \n                                                                  'conv2d_1[0][0]']               \n                                                                                                  \n activation_2 (Activation)      (None, 64, 64, 64)   0           ['add[0][0]']                    \n                                                                                                  \n separable_conv2d_2 (SeparableC  (None, 64, 64, 128)  8896       ['activation_2[0][0]']           \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 64, 64, 128)  512        ['separable_conv2d_2[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n activation_3 (Activation)      (None, 64, 64, 128)  0           ['batch_normalization_3[0][0]']  \n                                                                                                  \n separable_conv2d_3 (SeparableC  (None, 64, 64, 128)  17664      ['activation_3[0][0]']           \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 64, 64, 128)  512        ['separable_conv2d_3[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0          ['batch_normalization_4[0][0]']  \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 32, 32, 128)  8320        ['add[0][0]']                    \n                                                                                                  \n add_1 (Add)                    (None, 32, 32, 128)  0           ['max_pooling2d_1[0][0]',        \n                                                                  'conv2d_2[0][0]']               \n                                                                                                  \n activation_4 (Activation)      (None, 32, 32, 128)  0           ['add_1[0][0]']                  \n                                                                                                  \n separable_conv2d_4 (SeparableC  (None, 32, 32, 256)  34176      ['activation_4[0][0]']           \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 32, 32, 256)  1024       ['separable_conv2d_4[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n activation_5 (Activation)      (None, 32, 32, 256)  0           ['batch_normalization_5[0][0]']  \n                                                                                                  \n separable_conv2d_5 (SeparableC  (None, 32, 32, 256)  68096      ['activation_5[0][0]']           \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 32, 32, 256)  1024       ['separable_conv2d_5[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0          ['batch_normalization_6[0][0]']  \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 16, 16, 256)  33024       ['add_1[0][0]']                  \n                                                                                                  \n add_2 (Add)                    (None, 16, 16, 256)  0           ['max_pooling2d_2[0][0]',        \n                                                                  'conv2d_3[0][0]']               \n                                                                                                  \n activation_6 (Activation)      (None, 16, 16, 256)  0           ['add_2[0][0]']                  \n                                                                                                  \n conv2d_transpose (Conv2DTransp  (None, 16, 16, 256)  590080     ['activation_6[0][0]']           \n ose)                                                                                             \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_transpose[0][0]']       \n rmalization)                                                                                     \n                                                                                                  \n activation_7 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_7[0][0]']  \n                                                                                                  \n conv2d_transpose_1 (Conv2DTran  (None, 16, 16, 256)  590080     ['activation_7[0][0]']           \n spose)                                                                                           \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_transpose_1[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 256)  0          ['add_2[0][0]']                  \n                                                                                                  \n up_sampling2d (UpSampling2D)   (None, 32, 32, 256)  0           ['batch_normalization_8[0][0]']  \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 32, 32, 256)  65792       ['up_sampling2d_1[0][0]']        \n                                                                                                  \n add_3 (Add)                    (None, 32, 32, 256)  0           ['up_sampling2d[0][0]',          \n                                                                  'conv2d_4[0][0]']               \n                                                                                                  \n activation_8 (Activation)      (None, 32, 32, 256)  0           ['add_3[0][0]']                  \n                                                                                                  \n conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 128)  295040     ['activation_8[0][0]']           \n spose)                                                                                           \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_transpose_2[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n activation_9 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_9[0][0]']  \n                                                                                                  \n conv2d_transpose_3 (Conv2DTran  (None, 32, 32, 128)  147584     ['activation_9[0][0]']           \n spose)                                                                                           \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 32, 32, 128)  512        ['conv2d_transpose_3[0][0]']     \n ormalization)                                                                                    \n                                                                                                  \n up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 256)  0          ['add_3[0][0]']                  \n                                                                                                  \n up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 128)  0          ['batch_normalization_10[0][0]'] \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 64, 64, 128)  32896       ['up_sampling2d_3[0][0]']        \n                                                                                                  \n add_4 (Add)                    (None, 64, 64, 128)  0           ['up_sampling2d_2[0][0]',        \n                                                                  'conv2d_5[0][0]']               \n                                                                                                  \n activation_10 (Activation)     (None, 64, 64, 128)  0           ['add_4[0][0]']                  \n                                                                                                  \n conv2d_transpose_4 (Conv2DTran  (None, 64, 64, 64)  73792       ['activation_10[0][0]']          \n spose)                                                                                           \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 64, 64, 64)  256         ['conv2d_transpose_4[0][0]']     \n ormalization)                                                                                    \n                                                                                                  \n activation_11 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_11[0][0]'] \n                                                                                                  \n conv2d_transpose_5 (Conv2DTran  (None, 64, 64, 64)  36928       ['activation_11[0][0]']          \n spose)                                                                                           \n                                                                                                  \n batch_normalization_12 (BatchN  (None, 64, 64, 64)  256         ['conv2d_transpose_5[0][0]']     \n ormalization)                                                                                    \n                                                                                                  \n up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 12  0          ['add_4[0][0]']                  \n                                8)                                                                \n                                                                                                  \n up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 64  0          ['batch_normalization_12[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 128, 128, 64  8256        ['up_sampling2d_5[0][0]']        \n                                )                                                                 \n                                                                                                  \n add_5 (Add)                    (None, 128, 128, 64  0           ['up_sampling2d_4[0][0]',        \n                                )                                 'conv2d_6[0][0]']               \n                                                                                                  \n activation_12 (Activation)     (None, 128, 128, 64  0           ['add_5[0][0]']                  \n                                )                                                                 \n                                                                                                  \n conv2d_transpose_6 (Conv2DTran  (None, 128, 128, 32  18464      ['activation_12[0][0]']          \n spose)                         )                                                                 \n                                                                                                  \n batch_normalization_13 (BatchN  (None, 128, 128, 32  128        ['conv2d_transpose_6[0][0]']     \n ormalization)                  )                                                                 \n                                                                                                  \n activation_13 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_13[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_transpose_7 (Conv2DTran  (None, 128, 128, 32  9248       ['activation_13[0][0]']          \n spose)                         )                                                                 \n                                                                                                  \n batch_normalization_14 (BatchN  (None, 128, 128, 32  128        ['conv2d_transpose_7[0][0]']     \n ormalization)                  )                                                                 \n                                                                                                  \n up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 64  0          ['add_5[0][0]']                  \n                                )                                                                 \n                                                                                                  \n up_sampling2d_6 (UpSampling2D)  (None, 256, 256, 32  0          ['batch_normalization_14[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 256, 256, 32  2080        ['up_sampling2d_7[0][0]']        \n                                )                                                                 \n                                                                                                  \n add_6 (Add)                    (None, 256, 256, 32  0           ['up_sampling2d_6[0][0]',        \n                                )                                 'conv2d_7[0][0]']               \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 256, 256, 1)  289         ['add_6[0][0]']                  \n                                                                                                  \n==================================================================================================\nTotal params: 2,058,401\nTrainable params: 2,054,625\nNon-trainable params: 3,776\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train model","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:30:33.222338Z","iopub.execute_input":"2023-07-10T19:30:33.222846Z","iopub.status.idle":"2023-07-10T19:30:33.228013Z","shell.execute_reply.started":"2023-07-10T19:30:33.222811Z","shell.execute_reply":"2023-07-10T19:30:33.227016Z"}}},{"cell_type":"code","source":"class AshColorSingleFrames(keras.utils.Sequence):\n    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n\n    def __init__(self, batch_size, img_size, sample_ids, split_dir):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.split_dir = split_dir\n        self.sample_ids = sample_ids\n\n    def __len__(self):\n        return len(self.sample_ids) // self.batch_size\n\n    def __getitem__(self, idx):\n        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n        i = idx * self.batch_size\n        batch_sample_ids = self.sample_ids[i : i + self.batch_size]\n        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n        for j, sample_id in enumerate(batch_sample_ids):\n            img = get_ash_colors(sample_id, self.split_dir)\n            x[j] = img[..., N_TIMES_BEFORE]\n        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n        for j, sample_id in enumerate(batch_sample_ids):\n            img = get_pixel_mask(sample_id, self.split_dir)\n            y[j] = img\n        return x, y","metadata":{"execution":{"iopub.status.busy":"2023-07-10T20:03:32.366489Z","iopub.execute_input":"2023-07-10T20:03:32.366965Z","iopub.status.idle":"2023-07-10T20:03:32.377058Z","shell.execute_reply.started":"2023-07-10T20:03:32.366924Z","shell.execute_reply":"2023-07-10T20:03:32.375470Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"code","source":"train_set = AshColorSingleFrames(4, Config.img_size, train_ids, 'train')\nprint('number of batches:', len(train_set))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T20:03:33.204990Z","iopub.execute_input":"2023-07-10T20:03:33.205438Z","iopub.status.idle":"2023-07-10T20:03:33.212229Z","shell.execute_reply.started":"2023-07-10T20:03:33.205403Z","shell.execute_reply":"2023-07-10T20:03:33.210658Z"},"trusted":true},"execution_count":170,"outputs":[{"name":"stdout","text":"number of batches: 5132\n","output_type":"stream"}]},{"cell_type":"code","source":"valid_set = AshColorSingleFrames(4, Config.img_size, valid_ids, 'valid')\nprint('number of batches:', len(valid_set))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T20:03:34.018677Z","iopub.execute_input":"2023-07-10T20:03:34.019101Z","iopub.status.idle":"2023-07-10T20:03:34.026916Z","shell.execute_reply.started":"2023-07-10T20:03:34.019070Z","shell.execute_reply":"2023-07-10T20:03:34.025449Z"},"trusted":true},"execution_count":171,"outputs":[{"name":"stdout","text":"number of batches: 464\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Check batch dimensions (x, y):","metadata":{}},{"cell_type":"code","source":"train_set[0][0].shape, train_set[0][1].shape","metadata":{"execution":{"iopub.status.busy":"2023-07-10T20:03:35.658653Z","iopub.execute_input":"2023-07-10T20:03:35.659938Z","iopub.status.idle":"2023-07-10T20:03:35.799529Z","shell.execute_reply.started":"2023-07-10T20:03:35.659888Z","shell.execute_reply":"2023-07-10T20:03:35.798571Z"},"trusted":true},"execution_count":172,"outputs":[{"execution_count":172,"output_type":"execute_result","data":{"text/plain":"((4, 256, 256, 3), (4, 256, 256, 1))"},"metadata":{}}]},{"cell_type":"markdown","source":"`dice_coef` adapted from:\n- https://stackoverflow.com/questions/72195156/correct-implementation-of-dice-loss-in-tensorflow-keras\n- https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580","metadata":{}},{"cell_type":"code","source":"def dice_coef(y_true, y_pred, threshold=0.5, smooth=0.001):\n    y_true_f = backend.flatten(tf.cast(y_true, tf.float32))\n    y_pred_f = backend.flatten(y_pred)\n    intersection = backend.sum(y_true_f * y_pred_f)\n    dice = (2. * intersection + smooth) / (backend.sum(y_true_f) + backend.sum(y_pred_f) + smooth)\n    return dice\n\n\ndef dice_coef_loss(y_true, y_pred, smooth):\n    return 1 - dice_coef(y_true, y_pred, smooth)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T20:03:37.203130Z","iopub.execute_input":"2023-07-10T20:03:37.203537Z","iopub.status.idle":"2023-07-10T20:03:37.210120Z","shell.execute_reply.started":"2023-07-10T20:03:37.203504Z","shell.execute_reply":"2023-07-10T20:03:37.208860Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"code","source":"# Configure the model for training.\n# We use the \"sparse\" version of categorical_crossentropy\n# because our target data is integers.\nmodel.compile(optimizer=\"rmsprop\", loss=dice_loss)\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\"contrails-unet.h5\", save_best_only=True)\n]\n\n# Train the model, doing validation at the end of each epoch.\nmodel.fit(train_set, epochs=Config.num_epochs, validation_data=valid_set, callbacks=callbacks)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adapted from: https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580","metadata":{}}]}