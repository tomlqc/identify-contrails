{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Identify Contrails with Keras","metadata":{}},{"cell_type":"code","source":"# reinstall tensorflow-io\n# to avoid the UserWarning: unable to load libtensorflow_io_plugins.so\n\n#!pip install tensorflow-io","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:42.864201Z","iopub.execute_input":"2023-07-10T22:05:42.864579Z","iopub.status.idle":"2023-07-10T22:05:42.869990Z","shell.execute_reply.started":"2023-07-10T22:05:42.864547Z","shell.execute_reply":"2023-07-10T22:05:42.869057Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%pwd","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:42.894174Z","iopub.execute_input":"2023-07-10T22:05:42.894905Z","iopub.status.idle":"2023-07-10T22:05:42.919032Z","shell.execute_reply.started":"2023-07-10T22:05:42.894844Z","shell.execute_reply":"2023-07-10T22:05:42.917902Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport math\nimport pathlib\nimport random\nimport shutil\n\nfrom tqdm.notebook import tqdm\n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-10T22:05:42.926603Z","iopub.execute_input":"2023-07-10T22:05:42.927366Z","iopub.status.idle":"2023-07-10T22:05:43.048158Z","shell.execute_reply.started":"2023-07-10T22:05:42.927324Z","shell.execute_reply":"2023-07-10T22:05:43.047189Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# This notebook is inspired by:\n\n# Visualization:\n# - https://www.kaggle.com/code/inversion/visualizing-contrails\n# - https://www.kaggle.com/code/pranavnadimpali/comprehensive-eda-submission\n\n# Models:\n# - https://keras.io/examples/vision/oxford_pets_image_segmentation/\n# - https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.050011Z","iopub.execute_input":"2023-07-10T22:05:43.050445Z","iopub.status.idle":"2023-07-10T22:05:43.057950Z","shell.execute_reply.started":"2023-07-10T22:05:43.050412Z","shell.execute_reply":"2023-07-10T22:05:43.057035Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#---------------------------------------------------------------------------79","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.059630Z","iopub.execute_input":"2023-07-10T22:05:43.060336Z","iopub.status.idle":"2023-07-10T22:05:43.065072Z","shell.execute_reply.started":"2023-07-10T22:05:43.060300Z","shell.execute_reply":"2023-07-10T22:05:43.064114Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"class ABI:\n    bands = {name: idx for idx, name in enumerate([\n        '08', '09', '10', '11', '12', '13', '14', '15', '16'])}\n    colors = {name: idx for idx, name in enumerate([\n        'red', 'blue', 'green', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'black'])}","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.067857Z","iopub.execute_input":"2023-07-10T22:05:43.068581Z","iopub.status.idle":"2023-07-10T22:05:43.075982Z","shell.execute_reply.started":"2023-07-10T22:05:43.068550Z","shell.execute_reply":"2023-07-10T22:05:43.074823Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"N_TIMES_BEFORE = 4\nN_TIMES_AFTER = 3","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.077779Z","iopub.execute_input":"2023-07-10T22:05:43.078126Z","iopub.status.idle":"2023-07-10T22:05:43.084471Z","shell.execute_reply.started":"2023-07-10T22:05:43.078095Z","shell.execute_reply":"2023-07-10T22:05:43.083369Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"WORK_DIR = '/kaggle/working'  # preserved if notebook is saved\nTEMP_DIR = '/kaggle/temp'  # just during current session\n\nDATA_DIR = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n\nclass Paths:\n    train = os.path.join(DATA_DIR, 'train')\n    valid = os.path.join(DATA_DIR, 'validation')\n    test = os.path.join(DATA_DIR, 'test')","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.086329Z","iopub.execute_input":"2023-07-10T22:05:43.086819Z","iopub.status.idle":"2023-07-10T22:05:43.095231Z","shell.execute_reply.started":"2023-07-10T22:05:43.086786Z","shell.execute_reply":"2023-07-10T22:05:43.094063Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Data Analysis and Visualization","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:12:44.041834Z","iopub.execute_input":"2023-07-09T16:12:44.042298Z","iopub.status.idle":"2023-07-09T16:12:44.046633Z","shell.execute_reply.started":"2023-07-09T16:12:44.042265Z","shell.execute_reply":"2023-07-09T16:12:44.045618Z"}}},{"cell_type":"code","source":"DRAW = False","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.096840Z","iopub.execute_input":"2023-07-10T22:05:43.097324Z","iopub.status.idle":"2023-07-10T22:05:43.106082Z","shell.execute_reply.started":"2023-07-10T22:05:43.097292Z","shell.execute_reply":"2023-07-10T22:05:43.105209Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_ids = os.listdir(Paths.train)\nvalid_ids = os.listdir(Paths.valid)\ntest_ids = os.listdir(Paths.test)\nprint(len(train_ids), len(valid_ids), len(test_ids))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.107799Z","iopub.execute_input":"2023-07-10T22:05:43.108068Z","iopub.status.idle":"2023-07-10T22:05:43.341058Z","shell.execute_reply.started":"2023-07-10T22:05:43.108046Z","shell.execute_reply":"2023-07-10T22:05:43.340054Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"20529 1856 2\n","output_type":"stream"}]},{"cell_type":"code","source":"pixel_mask = np.load(os.path.join(DATA_DIR, 'train', train_ids[3], 'human_pixel_masks.npy'))\nprint(pixel_mask.shape)\nprint(pixel_mask.min(), pixel_mask.max())","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.342645Z","iopub.execute_input":"2023-07-10T22:05:43.343033Z","iopub.status.idle":"2023-07-10T22:05:43.357931Z","shell.execute_reply.started":"2023-07-10T22:05:43.343002Z","shell.execute_reply":"2023-07-10T22:05:43.356944Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"(256, 256, 1)\n0 1\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_ids = train_ids","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.363039Z","iopub.execute_input":"2023-07-10T22:05:43.363345Z","iopub.status.idle":"2023-07-10T22:05:43.368430Z","shell.execute_reply.started":"2023-07-10T22:05:43.363319Z","shell.execute_reply":"2023-07-10T22:05:43.367052Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def plot_bands_over_time(sample_id, split_dir):\n    \"\"\"\n    \n    Adapted from:\n    https://www.kaggle.com/code/pranavnadimpali/comprehensive-eda-submission\n    \n    Args: \n        sample_id(str): The id of the example i.e. '1000216489776414077'\n        split_dir(str): The split directoryu i.e. 'test', 'train', 'val'\n    \"\"\"\n    fig, axs = plt.subplots(8, len(ABI.bands), figsize=(16, 16)) \n\n    for band, j in ABI.bands.items():\n        img = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_{band}.npy\")\n        for i in range(8):\n            axs[i, j].imshow(img[..., i]) \n            axs[i, j].set_title(f\"Band {band}\\nTime Step {i+1}\") \n\n    plt.tight_layout()  \n    plt.show()\n    \nif DRAW:\n    plot_bands_over_time(sample_ids[3], 'train')","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.370209Z","iopub.execute_input":"2023-07-10T22:05:43.370930Z","iopub.status.idle":"2023-07-10T22:05:43.381166Z","shell.execute_reply.started":"2023-07-10T22:05:43.370896Z","shell.execute_reply":"2023-07-10T22:05:43.380018Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def normalize_range(data, bounds):\n    \"\"\"Maps data to the range [0, 1].\"\"\"\n    return (data - bounds[0]) / (bounds[1] - bounds[0])\n\n_T11_BOUNDS = (243, 303)\n_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n_TDIFF_BOUNDS = (-4, 2)\n\ndef get_ash_colors(sample_id, split_dir):\n    \"\"\"\n    Based on bands: 11, 14, 15\n    \n    Args:\n        sample_id(str): The id of the example i.e. '1000216489776414077'\n        split_dir(str): The split directoryu i.e. 'test', 'train', 'val'\n    \"\"\"\n    band15 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_15.npy\")\n    band14 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_14.npy\")\n    band11 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_11.npy\")\n\n    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)\n    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n    b = normalize_range(band14, _T11_BOUNDS)\n    ash_colors = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n    \n    return ash_colors","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.383054Z","iopub.execute_input":"2023-07-10T22:05:43.383511Z","iopub.status.idle":"2023-07-10T22:05:43.393671Z","shell.execute_reply.started":"2023-07-10T22:05:43.383478Z","shell.execute_reply":"2023-07-10T22:05:43.392643Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_individual_mask(sample_id, split_dir):\n    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_individual_masks.npy\"\n    pixel_mask = np.load(masks_path)\n    return pixel_mask","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.395272Z","iopub.execute_input":"2023-07-10T22:05:43.395946Z","iopub.status.idle":"2023-07-10T22:05:43.406988Z","shell.execute_reply.started":"2023-07-10T22:05:43.395912Z","shell.execute_reply":"2023-07-10T22:05:43.405952Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def get_pixel_mask(sample_id, split_dir):\n    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_pixel_masks.npy\"\n    pixel_mask = np.load(masks_path)\n    return pixel_mask","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.408643Z","iopub.execute_input":"2023-07-10T22:05:43.409052Z","iopub.status.idle":"2023-07-10T22:05:43.417189Z","shell.execute_reply.started":"2023-07-10T22:05:43.408995Z","shell.execute_reply":"2023-07-10T22:05:43.416217Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def plot_ash_colors(sample_id, split_dir, plot, time_step=4):\n\n    ash_colors = get_ash_colors(sample_id, split_dir)\n    img = ash_colors[..., time_step] # 5th image corresponds to ground truth\n    \n    ground_truth = get_pixel_mask(sample_id, split_dir)\n    \n    if plot:\n        fig, axs = plt.subplots(1, 3, figsize=(16, 8))\n\n        axs[0].imshow(img)\n        axs[0].set_title(\"Ash Color Image\")\n\n        axs[1].imshow(ground_truth)\n        axs[1].set_title(\"Ground Truth\")\n\n        axs[2].imshow(img)\n        axs[2].imshow(ground_truth, cmap='Reds', alpha=.3, interpolation='none')\n        axs[2].set_title('Contrail mask on ash color image')\n\n\n        plt.tight_layout() \n        plt.show()\n\n    return img\n    \nif DRAW:\n    plot_ash_colors(sample_ids[3], 'train', True)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.419778Z","iopub.execute_input":"2023-07-10T22:05:43.420648Z","iopub.status.idle":"2023-07-10T22:05:43.429515Z","shell.execute_reply.started":"2023-07-10T22:05:43.420615Z","shell.execute_reply":"2023-07-10T22:05:43.428841Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def plot_three_bands(sample_id, split_dir, bands, timestep=4):\n    \"\"\"\n    \n    Adapted from:\n    https://www.kaggle.com/code/pranavnadimpali/comprehensive-eda-submission\n    \n    Args: \n        sample_id(str): The id of the example i.e. '1000216489776414077'\n        split_dir(str): The split directoryu i.e. 'test', 'train', 'val'\n    \"\"\"\n    fig, axs = plt.subplots(1, 3, figsize=(16, 16)) \n\n    for j, band in enumerate(bands):\n        img = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_{band}.npy\")\n        axs[j].imshow(img[..., timestep]) \n        axs[j].set_title(f\"Band {band}\\nTime Step {timestep+1}\") \n\n    plt.tight_layout()  \n    plt.show()\n    \nif DRAW:\n    plot_three_bands(sample_ids[3], 'train', ['11', '14', '15'])\n    plot_three_bands(sample_ids[3], 'train', ['08', '09', '10'])\n    plot_three_bands(sample_ids[3], 'train', ['12', '13', '16'])","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-07-10T22:05:43.430902Z","iopub.execute_input":"2023-07-10T22:05:43.432118Z","iopub.status.idle":"2023-07-10T22:05:43.443314Z","shell.execute_reply.started":"2023-07-10T22:05:43.432044Z","shell.execute_reply":"2023-07-10T22:05:43.442359Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"ash_path = pathlib.Path(os.path.join(TEMP_DIR, 'ash_colors_images'))\nash_path.mkdir(exist_ok=True, parents=True)\n\nash_path.resolve()  # get absolute path","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.444756Z","iopub.execute_input":"2023-07-10T22:05:43.445911Z","iopub.status.idle":"2023-07-10T22:05:43.457140Z","shell.execute_reply.started":"2023-07-10T22:05:43.445865Z","shell.execute_reply":"2023-07-10T22:05:43.456138Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"PosixPath('/kaggle/temp/ash_colors_images')"},"metadata":{}}]},{"cell_type":"code","source":"#shutil.rmtree(ash_path)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.458786Z","iopub.execute_input":"2023-07-10T22:05:43.459584Z","iopub.status.idle":"2023-07-10T22:05:43.465114Z","shell.execute_reply.started":"2023-07-10T22:05:43.459549Z","shell.execute_reply":"2023-07-10T22:05:43.463954Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"split_dir = 'train'\n\n# 1 images take about 3 MB with all 8 timesteps. \n# train set has 20529 samples, i.e. it would take 60 GB.\n\nif False:\n\n    print('convert to ash colors')\n    for sample_id in tqdm(train_ids[:100]):\n\n        ash_colors = get_ash_colors(sample_id, split_dir)\n        #pixel_mask = get_pixel_mask(sample_id, split_dir)\n    \n    # 59.68it/s\n    # 1 s/sample\n\nif False:\n    print('convert to ash colors and write')\n    for sample_id in tqdm(train_ids[:100]):\n\n        ash_colors = get_ash_colors(sample_id, split_dir)\n        #pixel_mask = get_pixel_mask(sample_id, split_dir)\n\n        ash_colors = ash_colors.astype(np.float16)\n\n        image_path = ash_path/f\"{sample_id}.npy\"\n        np.save(str(image_path), ash_colors)\n        \n    # 21.64it/s\n    # 3 s/sample\n        \nif False:\n    print('read')\n    for sample_id in tqdm(train_ids[:100]):\n\n        image_path = ash_path/f\"{sample_id}.npy\"\n        np.load(str(image_path))\n    \n    # 634.78it/s\n    # 0.1 s/sample\n    # But is this true or are the files still cached by the OS?","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.466790Z","iopub.execute_input":"2023-07-10T22:05:43.468056Z","iopub.status.idle":"2023-07-10T22:05:43.480798Z","shell.execute_reply.started":"2023-07-10T22:05:43.468029Z","shell.execute_reply":"2023-07-10T22:05:43.479697Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Build model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import backend as backend","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:43.482472Z","iopub.execute_input":"2023-07-10T22:05:43.482907Z","iopub.status.idle":"2023-07-10T22:05:51.052548Z","shell.execute_reply.started":"2023-07-10T22:05:43.482842Z","shell.execute_reply":"2023-07-10T22:05:51.051440Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:51.054074Z","iopub.execute_input":"2023-07-10T22:05:51.054859Z","iopub.status.idle":"2023-07-10T22:05:51.061371Z","shell.execute_reply.started":"2023-07-10T22:05:51.054823Z","shell.execute_reply":"2023-07-10T22:05:51.060338Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'2.12.0'"},"metadata":{}}]},{"cell_type":"code","source":"SEED = 42","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:51.062949Z","iopub.execute_input":"2023-07-10T22:05:51.063618Z","iopub.status.idle":"2023-07-10T22:05:51.070801Z","shell.execute_reply.started":"2023-07-10T22:05:51.063586Z","shell.execute_reply":"2023-07-10T22:05:51.069833Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class Config:\n    \n    img_size = (256, 256)\n    \n    train = True\n    \n    num_epochs = 1  # 10\n    num_classes = 1\n    batch_size = 32\n    \n    warmup = 0\n    lr = 3e-4\n\n    seed = SEED\n","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:51.072259Z","iopub.execute_input":"2023-07-10T22:05:51.072612Z","iopub.status.idle":"2023-07-10T22:05:51.080455Z","shell.execute_reply.started":"2023-07-10T22:05:51.072582Z","shell.execute_reply":"2023-07-10T22:05:51.079539Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# https://keras.io/examples/keras_recipes/reproducibility_recipes/\n\n# Set the seed using keras.utils.set_random_seed. This will set:\n# 1) `numpy` seed\n# 2) `tensorflow` random seed\n# 3) `python` random seed\nkeras.utils.set_random_seed(Config.seed)\n\n# See also:\n# tf.config.experimental.enable_op_determinism()","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:51.082088Z","iopub.execute_input":"2023-07-10T22:05:51.082465Z","iopub.status.idle":"2023-07-10T22:05:51.093684Z","shell.execute_reply.started":"2023-07-10T22:05:51.082436Z","shell.execute_reply":"2023-07-10T22:05:51.092720Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Following U-Net model is adapted from: https://keras.io/examples/vision/oxford_pets_image_segmentation","metadata":{}},{"cell_type":"code","source":"def get_model(img_size, num_classes):\n    inputs = keras.Input(shape=img_size + (3,))\n\n    ### [First half of the network: downsampling inputs] ###\n\n    # Entry block\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n    x = layers.BatchNormalization()(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    # Blocks 1, 2, 3 are identical apart from the feature depth.\n    for filters in [64, 128, 256]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    ### [Second half of the network: upsampling inputs] ###\n\n    for filters in [256, 128, 64, 32]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.UpSampling2D(2)(x)\n\n        # Project residual\n        residual = layers.UpSampling2D(2)(previous_block_activation)\n        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    # Add a per-pixel classification layer\n    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n\n    # Define the model\n    model = keras.Model(inputs, outputs)\n    return model\n\n\n# Free up RAM in case the model definition cells were run multiple times\nkeras.backend.clear_session()\n\n# Build model\nmodel = get_model(Config.img_size, Config.num_classes)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:51.095194Z","iopub.execute_input":"2023-07-10T22:05:51.096023Z","iopub.status.idle":"2023-07-10T22:05:54.933468Z","shell.execute_reply.started":"2023-07-10T22:05:51.095991Z","shell.execute_reply":"2023-07-10T22:05:54.932667Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d (Conv2D)                (None, 128, 128, 32  896         ['input_1[0][0]']                \n                                )                                                                 \n                                                                                                  \n batch_normalization (BatchNorm  (None, 128, 128, 32  128        ['conv2d[0][0]']                 \n alization)                     )                                                                 \n                                                                                                  \n activation (Activation)        (None, 128, 128, 32  0           ['batch_normalization[0][0]']    \n                                )                                                                 \n                                                                                                  \n separable_conv2d (SeparableCon  (None, 128, 128, 64  2400       ['activation[0][0]']             \n v2D)                           )                                                                 \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 128, 128, 64  256        ['separable_conv2d[0][0]']       \n rmalization)                   )                                                                 \n                                                                                                  \n activation_1 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_1[0][0]']  \n                                )                                                                 \n                                                                                                  \n separable_conv2d_1 (SeparableC  (None, 128, 128, 64  4736       ['activation_1[0][0]']           \n onv2D)                         )                                                                 \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 128, 128, 64  256        ['separable_conv2d_1[0][0]']     \n rmalization)                   )                                                                 \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 64, 64, 64)   0           ['batch_normalization_2[0][0]']  \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 64, 64, 64)   2112        ['batch_normalization[0][0]']    \n                                                                                                  \n add (Add)                      (None, 64, 64, 64)   0           ['max_pooling2d[0][0]',          \n                                                                  'conv2d_1[0][0]']               \n                                                                                                  \n activation_2 (Activation)      (None, 64, 64, 64)   0           ['add[0][0]']                    \n                                                                                                  \n separable_conv2d_2 (SeparableC  (None, 64, 64, 128)  8896       ['activation_2[0][0]']           \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 64, 64, 128)  512        ['separable_conv2d_2[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n activation_3 (Activation)      (None, 64, 64, 128)  0           ['batch_normalization_3[0][0]']  \n                                                                                                  \n separable_conv2d_3 (SeparableC  (None, 64, 64, 128)  17664      ['activation_3[0][0]']           \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 64, 64, 128)  512        ['separable_conv2d_3[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0          ['batch_normalization_4[0][0]']  \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 32, 32, 128)  8320        ['add[0][0]']                    \n                                                                                                  \n add_1 (Add)                    (None, 32, 32, 128)  0           ['max_pooling2d_1[0][0]',        \n                                                                  'conv2d_2[0][0]']               \n                                                                                                  \n activation_4 (Activation)      (None, 32, 32, 128)  0           ['add_1[0][0]']                  \n                                                                                                  \n separable_conv2d_4 (SeparableC  (None, 32, 32, 256)  34176      ['activation_4[0][0]']           \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 32, 32, 256)  1024       ['separable_conv2d_4[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n activation_5 (Activation)      (None, 32, 32, 256)  0           ['batch_normalization_5[0][0]']  \n                                                                                                  \n separable_conv2d_5 (SeparableC  (None, 32, 32, 256)  68096      ['activation_5[0][0]']           \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 32, 32, 256)  1024       ['separable_conv2d_5[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0          ['batch_normalization_6[0][0]']  \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 16, 16, 256)  33024       ['add_1[0][0]']                  \n                                                                                                  \n add_2 (Add)                    (None, 16, 16, 256)  0           ['max_pooling2d_2[0][0]',        \n                                                                  'conv2d_3[0][0]']               \n                                                                                                  \n activation_6 (Activation)      (None, 16, 16, 256)  0           ['add_2[0][0]']                  \n                                                                                                  \n conv2d_transpose (Conv2DTransp  (None, 16, 16, 256)  590080     ['activation_6[0][0]']           \n ose)                                                                                             \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_transpose[0][0]']       \n rmalization)                                                                                     \n                                                                                                  \n activation_7 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_7[0][0]']  \n                                                                                                  \n conv2d_transpose_1 (Conv2DTran  (None, 16, 16, 256)  590080     ['activation_7[0][0]']           \n spose)                                                                                           \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_transpose_1[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 256)  0          ['add_2[0][0]']                  \n                                                                                                  \n up_sampling2d (UpSampling2D)   (None, 32, 32, 256)  0           ['batch_normalization_8[0][0]']  \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 32, 32, 256)  65792       ['up_sampling2d_1[0][0]']        \n                                                                                                  \n add_3 (Add)                    (None, 32, 32, 256)  0           ['up_sampling2d[0][0]',          \n                                                                  'conv2d_4[0][0]']               \n                                                                                                  \n activation_8 (Activation)      (None, 32, 32, 256)  0           ['add_3[0][0]']                  \n                                                                                                  \n conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 128)  295040     ['activation_8[0][0]']           \n spose)                                                                                           \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_transpose_2[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n activation_9 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_9[0][0]']  \n                                                                                                  \n conv2d_transpose_3 (Conv2DTran  (None, 32, 32, 128)  147584     ['activation_9[0][0]']           \n spose)                                                                                           \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 32, 32, 128)  512        ['conv2d_transpose_3[0][0]']     \n ormalization)                                                                                    \n                                                                                                  \n up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 256)  0          ['add_3[0][0]']                  \n                                                                                                  \n up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 128)  0          ['batch_normalization_10[0][0]'] \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 64, 64, 128)  32896       ['up_sampling2d_3[0][0]']        \n                                                                                                  \n add_4 (Add)                    (None, 64, 64, 128)  0           ['up_sampling2d_2[0][0]',        \n                                                                  'conv2d_5[0][0]']               \n                                                                                                  \n activation_10 (Activation)     (None, 64, 64, 128)  0           ['add_4[0][0]']                  \n                                                                                                  \n conv2d_transpose_4 (Conv2DTran  (None, 64, 64, 64)  73792       ['activation_10[0][0]']          \n spose)                                                                                           \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 64, 64, 64)  256         ['conv2d_transpose_4[0][0]']     \n ormalization)                                                                                    \n                                                                                                  \n activation_11 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_11[0][0]'] \n                                                                                                  \n conv2d_transpose_5 (Conv2DTran  (None, 64, 64, 64)  36928       ['activation_11[0][0]']          \n spose)                                                                                           \n                                                                                                  \n batch_normalization_12 (BatchN  (None, 64, 64, 64)  256         ['conv2d_transpose_5[0][0]']     \n ormalization)                                                                                    \n                                                                                                  \n up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 12  0          ['add_4[0][0]']                  \n                                8)                                                                \n                                                                                                  \n up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 64  0          ['batch_normalization_12[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 128, 128, 64  8256        ['up_sampling2d_5[0][0]']        \n                                )                                                                 \n                                                                                                  \n add_5 (Add)                    (None, 128, 128, 64  0           ['up_sampling2d_4[0][0]',        \n                                )                                 'conv2d_6[0][0]']               \n                                                                                                  \n activation_12 (Activation)     (None, 128, 128, 64  0           ['add_5[0][0]']                  \n                                )                                                                 \n                                                                                                  \n conv2d_transpose_6 (Conv2DTran  (None, 128, 128, 32  18464      ['activation_12[0][0]']          \n spose)                         )                                                                 \n                                                                                                  \n batch_normalization_13 (BatchN  (None, 128, 128, 32  128        ['conv2d_transpose_6[0][0]']     \n ormalization)                  )                                                                 \n                                                                                                  \n activation_13 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_13[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_transpose_7 (Conv2DTran  (None, 128, 128, 32  9248       ['activation_13[0][0]']          \n spose)                         )                                                                 \n                                                                                                  \n batch_normalization_14 (BatchN  (None, 128, 128, 32  128        ['conv2d_transpose_7[0][0]']     \n ormalization)                  )                                                                 \n                                                                                                  \n up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 64  0          ['add_5[0][0]']                  \n                                )                                                                 \n                                                                                                  \n up_sampling2d_6 (UpSampling2D)  (None, 256, 256, 32  0          ['batch_normalization_14[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 256, 256, 32  2080        ['up_sampling2d_7[0][0]']        \n                                )                                                                 \n                                                                                                  \n add_6 (Add)                    (None, 256, 256, 32  0           ['up_sampling2d_6[0][0]',        \n                                )                                 'conv2d_7[0][0]']               \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 256, 256, 1)  289         ['add_6[0][0]']                  \n                                                                                                  \n==================================================================================================\nTotal params: 2,058,401\nTrainable params: 2,054,625\nNon-trainable params: 3,776\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Prepare datasets","metadata":{"execution":{"iopub.status.busy":"2023-07-10T19:30:33.222338Z","iopub.execute_input":"2023-07-10T19:30:33.222846Z","iopub.status.idle":"2023-07-10T19:30:33.228013Z","shell.execute_reply.started":"2023-07-10T19:30:33.222811Z","shell.execute_reply":"2023-07-10T19:30:33.227016Z"}}},{"cell_type":"code","source":"class AshColorSingleFrames(keras.utils.Sequence):\n    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n\n    def __init__(self, batch_size, img_size, sample_ids, split_dir, n_samples=None):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.split_dir = split_dir\n        self.sample_ids = sample_ids[:n_samples]\n\n    def __len__(self):\n        return math.ceil(len(self.sample_ids) / self.batch_size)\n\n    def __getitem__(self, idx):\n        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n        i = idx * self.batch_size\n        batch_sample_ids = self.sample_ids[i : i + self.batch_size]\n        \n        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n        for j, sample_id in enumerate(batch_sample_ids):\n            img = get_ash_colors(sample_id, self.split_dir)\n            x[j] = img[..., N_TIMES_BEFORE]\n\n        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n        if self.split_dir != 'test':\n            for j, sample_id in enumerate(batch_sample_ids):\n                img = get_pixel_mask(sample_id, self.split_dir)\n                y[j] = img\n        \n        return x, y","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:54.934605Z","iopub.execute_input":"2023-07-10T22:05:54.935349Z","iopub.status.idle":"2023-07-10T22:05:54.958786Z","shell.execute_reply.started":"2023-07-10T22:05:54.935314Z","shell.execute_reply":"2023-07-10T22:05:54.957703Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_set = AshColorSingleFrames(Config.batch_size, Config.img_size, train_ids, 'train', n_samples=500)\nprint('number of batches:', len(train_set))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:54.965958Z","iopub.execute_input":"2023-07-10T22:05:54.966335Z","iopub.status.idle":"2023-07-10T22:05:54.997502Z","shell.execute_reply.started":"2023-07-10T22:05:54.966301Z","shell.execute_reply":"2023-07-10T22:05:54.996704Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"number of batches: 16\n","output_type":"stream"}]},{"cell_type":"code","source":"valid_set = AshColorSingleFrames(Config.batch_size, Config.img_size, valid_ids, 'validation', n_samples=100)\nprint('number of batches:', len(valid_set))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:54.998592Z","iopub.execute_input":"2023-07-10T22:05:54.999033Z","iopub.status.idle":"2023-07-10T22:05:55.011581Z","shell.execute_reply.started":"2023-07-10T22:05:54.999000Z","shell.execute_reply":"2023-07-10T22:05:55.010841Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"number of batches: 4\n","output_type":"stream"}]},{"cell_type":"code","source":"test_set = AshColorSingleFrames(Config.batch_size, Config.img_size, test_ids, 'test')\nprint('number of batches:', len(test_set))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:55.012652Z","iopub.execute_input":"2023-07-10T22:05:55.013005Z","iopub.status.idle":"2023-07-10T22:05:55.041276Z","shell.execute_reply.started":"2023-07-10T22:05:55.012974Z","shell.execute_reply":"2023-07-10T22:05:55.040444Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"number of batches: 1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Check batch dimensions (x, y):","metadata":{}},{"cell_type":"code","source":"train_set[0][0].shape, train_set[0][1].shape","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:55.042417Z","iopub.execute_input":"2023-07-10T22:05:55.042834Z","iopub.status.idle":"2023-07-10T22:05:58.372358Z","shell.execute_reply.started":"2023-07-10T22:05:55.042801Z","shell.execute_reply":"2023-07-10T22:05:58.371336Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"((32, 256, 256, 3), (32, 256, 256, 1))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"markdown","source":"`dice_coef` adapted from:\n- https://stackoverflow.com/questions/72195156/correct-implementation-of-dice-loss-in-tensorflow-keras\n- https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580","metadata":{}},{"cell_type":"code","source":"def dice_coef(y_true, y_pred, threshold=0.5, smooth=0.001):\n    y_true_f = backend.flatten(tf.cast(y_true, tf.float32))\n    y_pred_f = backend.flatten(tf.cast(y_pred, tf.float32))\n    # ValueError: No gradients provided for any variable\n    #y_pred_f = backend.flatten(tf.cast(tf.math.greater(tf.cast(y_pred, tf.float32), threshold), tf.float32))\n    intersection = backend.sum(y_true_f * y_pred_f)\n    dice = (2. * intersection + smooth) / (backend.sum(y_true_f) + backend.sum(y_pred_f) + smooth)\n    return dice\n\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:58.373668Z","iopub.execute_input":"2023-07-10T22:05:58.374487Z","iopub.status.idle":"2023-07-10T22:05:58.382113Z","shell.execute_reply.started":"2023-07-10T22:05:58.374453Z","shell.execute_reply":"2023-07-10T22:05:58.380979Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Check `dice_coef()` on one of the samples.","metadata":{}},{"cell_type":"code","source":"sample_id = train_ids[3]\n\nmerged_mask = get_pixel_mask(sample_id, 'train')\nindiv_masks = get_individual_mask(sample_id, 'train')\n\nprint(dice_coef(tf.convert_to_tensor(merged_mask),\n                tf.convert_to_tensor(merged_mask)))\nfor idv in range(6):\n    print(dice_coef(tf.convert_to_tensor(merged_mask),\n                    tf.convert_to_tensor(indiv_masks[..., idv])))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:58.383409Z","iopub.execute_input":"2023-07-10T22:05:58.383791Z","iopub.status.idle":"2023-07-10T22:05:58.466688Z","shell.execute_reply.started":"2023-07-10T22:05:58.383760Z","shell.execute_reply":"2023-07-10T22:05:58.465696Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"tf.Tensor(1.0, shape=(), dtype=float32)\ntf.Tensor(0.8743467, shape=(), dtype=float32)\ntf.Tensor(0.83587146, shape=(), dtype=float32)\ntf.Tensor(0.7393573, shape=(), dtype=float32)\ntf.Tensor(0.8522139, shape=(), dtype=float32)\ntf.Tensor(0.87988245, shape=(), dtype=float32)\ntf.Tensor(0.84089667, shape=(), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Learning rate scheduler:\n- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules\n- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecay - warmup only from v2.13.1 on","metadata":{}},{"cell_type":"code","source":"decay_steps = 1000\ninitial_learning_rate = 0\nwarmup_steps = 1000\ntarget_learning_rate = 0.1\nscheduler = keras.optimizers.schedules.CosineDecay(\n    initial_learning_rate, decay_steps\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:58.468195Z","iopub.execute_input":"2023-07-10T22:05:58.468844Z","iopub.status.idle":"2023-07-10T22:05:58.474403Z","shell.execute_reply.started":"2023-07-10T22:05:58.468811Z","shell.execute_reply":"2023-07-10T22:05:58.473427Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Configure the model for training.\n# We use the \"sparse\" version of categorical_crossentropy\n# because our target data is integers.\nmodel.compile(optimizer=\"rmsprop\", loss=dice_loss, metrics=[dice_coef])\n\ncallbacks = [\n    #keras.callbacks.LearningRateScheduler(scheduler),\n    keras.callbacks.ModelCheckpoint(\"contrails-unet.h5\", save_best_only=True)\n]\n\n# Train the model, doing validation at the end of each epoch.\nmodel.fit(train_set, epochs=Config.num_epochs, validation_data=valid_set, callbacks=callbacks)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:05:58.475985Z","iopub.execute_input":"2023-07-10T22:05:58.476678Z","iopub.status.idle":"2023-07-10T22:07:08.168351Z","shell.execute_reply.started":"2023-07-10T22:05:58.476647Z","shell.execute_reply":"2023-07-10T22:07:08.167360Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"16/16 [==============================] - 69s 3s/step - loss: 0.9882 - dice_coef: 0.0118 - val_loss: 0.9976 - val_dice_coef: 0.0024\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f290c20e740>"},"metadata":{}}]},{"cell_type":"code","source":"#keras.backend.clear_session()","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:07:08.169857Z","iopub.execute_input":"2023-07-10T22:07:08.170223Z","iopub.status.idle":"2023-07-10T22:07:08.175523Z","shell.execute_reply.started":"2023-07-10T22:07:08.170193Z","shell.execute_reply":"2023-07-10T22:07:08.174367Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## Make predictions on test dataset","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(test_set)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:07:08.177191Z","iopub.execute_input":"2023-07-10T22:07:08.178298Z","iopub.status.idle":"2023-07-10T22:07:09.150148Z","shell.execute_reply.started":"2023-07-10T22:07:08.178184Z","shell.execute_reply":"2023-07-10T22:07:09.149092Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 1s 686ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"len(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:07:09.151525Z","iopub.execute_input":"2023-07-10T22:07:09.152180Z","iopub.status.idle":"2023-07-10T22:07:09.159077Z","shell.execute_reply.started":"2023-07-10T22:07:09.152144Z","shell.execute_reply":"2023-07-10T22:07:09.158059Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"32"},"metadata":{}}]},{"cell_type":"markdown","source":"## Create a submission","metadata":{}},{"cell_type":"code","source":"def rle_encode(x, fg_val=1):\n    \"\"\"\n    Args:\n        x:  numpy array of shape (height, width), 1 - mask, 0 - background\n    Returns: run length encoding as list\n    \"\"\"\n\n    dots = np.where(\n        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if b > prev + 1:\n            run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\n\ndef list_to_string(x):\n    \"\"\"\n    Converts list to a string representation\n    Empty list returns '-'\n    \"\"\"\n    if x: # non-empty list\n        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n    else:\n        s = '-'\n    return s\n","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:07:09.160770Z","iopub.execute_input":"2023-07-10T22:07:09.161474Z","iopub.status.idle":"2023-07-10T22:07:09.170587Z","shell.execute_reply.started":"2023-07-10T22:07:09.161442Z","shell.execute_reply":"2023-07-10T22:07:09.169491Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"test_recs = os.listdir(os.path.join(DATA_DIR, 'test'))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:07:09.172102Z","iopub.execute_input":"2023-07-10T22:07:09.172555Z","iopub.status.idle":"2023-07-10T22:07:09.185198Z","shell.execute_reply.started":"2023-07-10T22:07:09.172523Z","shell.execute_reply":"2023-07-10T22:07:09.184209Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'), index_col='record_id')[0:0]\n\nfor test_id, mask in zip(test_ids, predictions):\n    \n    # notice the we're converting rec to an `int` here:\n    submission.loc[int(test_id), 'encoded_pixels'] = list_to_string(rle_encode(mask))\n    \nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-10T22:07:09.186693Z","iopub.execute_input":"2023-07-10T22:07:09.187102Z","iopub.status.idle":"2023-07-10T22:07:09.278552Z","shell.execute_reply.started":"2023-07-10T22:07:09.187047Z","shell.execute_reply":"2023-07-10T22:07:09.277593Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"UPDATED 00:06","metadata":{}}]}