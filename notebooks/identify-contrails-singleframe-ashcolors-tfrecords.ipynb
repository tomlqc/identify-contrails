{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Identify Contrails SingleFrame AshColors TFRecords DataSet","metadata":{}},{"cell_type":"code","source":"# reinstall tensorflow-io\n# to avoid the UserWarning: unable to load libtensorflow_io_plugins.so\n\n#!pip install tensorflow-io","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:16.529273Z","iopub.execute_input":"2023-07-23T10:29:16.529779Z","iopub.status.idle":"2023-07-23T10:29:16.537908Z","shell.execute_reply.started":"2023-07-23T10:29:16.529742Z","shell.execute_reply":"2023-07-23T10:29:16.536668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:16.539867Z","iopub.execute_input":"2023-07-23T10:29:16.540952Z","iopub.status.idle":"2023-07-23T10:29:16.556835Z","shell.execute_reply.started":"2023-07-23T10:29:16.540896Z","shell.execute_reply":"2023-07-23T10:29:16.555230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ==============================\n\nLOAD_CHECKPOINT = False  # <DEVEL>\nTRAIN = True  # <DEVEL>\n\nif os.path.exists('/kaggle'):\n    PLATFORM = 'kaggle'\nelse:\n    PLATFORM = 'gcp'\n\n# ==============================\n\nprint(f'PLATFORM = {PLATFORM}')\nprint()\nprint(f'LOAD_CHECKPOINT = {LOAD_CHECKPOINT}')\nprint(f'TRAIN = {TRAIN}')","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:16.559085Z","iopub.execute_input":"2023-07-23T10:29:16.560347Z","iopub.status.idle":"2023-07-23T10:29:16.573321Z","shell.execute_reply.started":"2023-07-23T10:29:16.560232Z","shell.execute_reply":"2023-07-23T10:29:16.571608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if PLATFORM == 'kaggle':\n\n    WORK_DIR = '/kaggle/working'  # preserved if notebook is saved\n    TEMP_DIR = '/kaggle/temp'  # just during current session\n\n    DATA_DIR = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n    RECORDS_DIR = WORK_DIR\n    \n    WEIGHTS_DIR = WORK_DIR\n    \n    # You can write up to 20GB to the current directory (/kaggle/working/)\n    # that gets preserved as output when you create a version using \"Save & Run All\" \n    # You can also write temporary files to /kaggle/temp/,\n    # but they won't be saved outside of the current session\n\nelif PLATFORM == 'gcp':\n\n    WORK_DIR = '/home/jupyter/kaggle/working'  # preserved if notebook is saved\n    TEMP_DIR = '/home/jupyter/kaggle/temp'  # just during current session\n\n    DATA_DIR = '/home/jupyter/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n    RECORDS_DIR = WORK_DIR\n    \n    WEIGHTS_DIR = '/home/jupyter/identify-contrails-models'\n    \n    %cd $WORK_DIR\n    \nelse:\n    raise NotImplementedError(f'unknown platform \"{PLATFORM}\"')\n\nprint('PWD =', os.getcwd())","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:16.575310Z","iopub.execute_input":"2023-07-23T10:29:16.576913Z","iopub.status.idle":"2023-07-23T10:29:16.587996Z","shell.execute_reply.started":"2023-07-23T10:29:16.576839Z","shell.execute_reply":"2023-07-23T10:29:16.586861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport datetime\nimport itertools\nimport math\nimport multiprocessing\nimport pathlib\nimport random\nimport shutil\n\nfrom pprint import pprint\nfrom pytz import timezone\nfrom tqdm.notebook import tqdm\n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport scipy","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-07-23T10:29:16.590503Z","iopub.execute_input":"2023-07-23T10:29:16.591085Z","iopub.status.idle":"2023-07-23T10:29:16.691220Z","shell.execute_reply.started":"2023-07-23T10:29:16.591045Z","shell.execute_reply":"2023-07-23T10:29:16.690251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PRINT_TIME_FORMAT = \"%Y-%m-%d %H:%M:%S %Z%z\"\nFILE_TIME_FORMAT = \"%Y-%m-%d_%H-%M-%S\"\n\nstart_time = datetime.datetime.now(timezone('CET'))\n\nfile_time_str = start_time.strftime(FILE_TIME_FORMAT)\n\nprint('Started', start_time.strftime(PRINT_TIME_FORMAT))","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:16.692567Z","iopub.execute_input":"2023-07-23T10:29:16.693123Z","iopub.status.idle":"2023-07-23T10:29:16.727455Z","shell.execute_reply.started":"2023-07-23T10:29:16.693092Z","shell.execute_reply":"2023-07-23T10:29:16.726211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import backend as backend\n\nAUTOTUNE = tf.data.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:16.728897Z","iopub.execute_input":"2023-07-23T10:29:16.729459Z","iopub.status.idle":"2023-07-23T10:29:21.149104Z","shell.execute_reply.started":"2023-07-23T10:29:16.729427Z","shell.execute_reply":"2023-07-23T10:29:21.147771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('TensorFlow version:', tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.150976Z","iopub.execute_input":"2023-07-23T10:29:21.151851Z","iopub.status.idle":"2023-07-23T10:29:21.158372Z","shell.execute_reply.started":"2023-07-23T10:29:21.151814Z","shell.execute_reply":"2023-07-23T10:29:21.157080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nprint('cpu_count: ', multiprocessing.cpu_count())","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.162231Z","iopub.execute_input":"2023-07-23T10:29:21.162730Z","iopub.status.idle":"2023-07-23T10:29:21.174681Z","shell.execute_reply.started":"2023-07-23T10:29:21.162693Z","shell.execute_reply":"2023-07-23T10:29:21.173160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#---------------------------------------------------------------------------79","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.176372Z","iopub.execute_input":"2023-07-23T10:29:21.176789Z","iopub.status.idle":"2023-07-23T10:29:21.187138Z","shell.execute_reply.started":"2023-07-23T10:29:21.176755Z","shell.execute_reply":"2023-07-23T10:29:21.185521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup dataset","metadata":{}},{"cell_type":"code","source":"class Paths:\n    train = os.path.join(DATA_DIR, 'train')\n    valid = os.path.join(DATA_DIR, 'validation')\n    test = os.path.join(DATA_DIR, 'test')","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.189155Z","iopub.execute_input":"2023-07-23T10:29:21.189719Z","iopub.status.idle":"2023-07-23T10:29:21.201302Z","shell.execute_reply.started":"2023-07-23T10:29:21.189672Z","shell.execute_reply":"2023-07-23T10:29:21.199973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ids = sorted(os.listdir(Paths.train))\nvalid_ids = sorted(os.listdir(Paths.valid))\ntest_ids = sorted(os.listdir(Paths.test))\nprint('n_samples (train, validation, test) =', len(train_ids), len(valid_ids), len(test_ids))","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.203118Z","iopub.execute_input":"2023-07-23T10:29:21.204008Z","iopub.status.idle":"2023-07-23T10:29:21.243162Z","shell.execute_reply.started":"2023-07-23T10:29:21.203963Z","shell.execute_reply":"2023-07-23T10:29:21.241662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ABI:\n    bands = {name: idx for idx, name in enumerate([\n        '08', '09', '10', '11', '12', '13', '14', '15', '16'])}\n    colors = {name: idx for idx, name in enumerate([\n        'red', 'blue', 'green', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'black'])}","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.245536Z","iopub.execute_input":"2023-07-23T10:29:21.246497Z","iopub.status.idle":"2023-07-23T10:29:21.254520Z","shell.execute_reply.started":"2023-07-23T10:29:21.246446Z","shell.execute_reply":"2023-07-23T10:29:21.253047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_TIMES_BEFORE = 4\nN_TIMES_AFTER = 3","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.256566Z","iopub.execute_input":"2023-07-23T10:29:21.256974Z","iopub.status.idle":"2023-07-23T10:29:21.270311Z","shell.execute_reply.started":"2023-07-23T10:29:21.256942Z","shell.execute_reply":"2023-07-23T10:29:21.268982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_range(data, bounds):\n    \"\"\"Maps data to the range [0, 1].\"\"\"\n    return (data - bounds[0]) / (bounds[1] - bounds[0])\n\n_T11_BOUNDS = (243, 303)\n_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n_TDIFF_BOUNDS = (-4, 2)\n\ndef get_ash_colors(sample_id, split_dir):\n    \"\"\"\n    Based on bands: 11, 14, 15\n    \n    Args:\n        sample_id(str): The id of the example i.e. '1000216489776414077'\n        split_dir(str): The split directoryu i.e. 'test', 'train', 'val'\n    \"\"\"\n    band15 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_15.npy\")\n    band14 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_14.npy\")\n    band11 = np.load(DATA_DIR + f\"/{split_dir}/{sample_id}/band_11.npy\")\n\n    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)\n    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n    b = normalize_range(band14, _T11_BOUNDS)\n    ash_colors = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n    \n    return ash_colors","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.271929Z","iopub.execute_input":"2023-07-23T10:29:21.272334Z","iopub.status.idle":"2023-07-23T10:29:21.287162Z","shell.execute_reply.started":"2023-07-23T10:29:21.272302Z","shell.execute_reply":"2023-07-23T10:29:21.285823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_individual_mask(sample_id, split_dir):\n    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_individual_masks.npy\"\n    pixel_mask = np.load(masks_path)\n    return pixel_mask\n\ndef get_pixel_mask(sample_id, split_dir):\n    masks_path = DATA_DIR + f\"/{split_dir}/{sample_id}/human_pixel_masks.npy\"\n    pixel_mask = np.load(masks_path)\n    return pixel_mask","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.289300Z","iopub.execute_input":"2023-07-23T10:29:21.289884Z","iopub.status.idle":"2023-07-23T10:29:21.307148Z","shell.execute_reply.started":"2023-07-23T10:29:21.289830Z","shell.execute_reply":"2023-07-23T10:29:21.305760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check some values","metadata":{}},{"cell_type":"code","source":"sample_id = 7829917977180135058  # train_ids[3]\n\nprint(f'Check `ash_colors` on one of the samples: {sample_id}')\n\nash_colors = get_ash_colors(sample_id, 'train')[..., N_TIMES_BEFORE]\n\nprint(ash_colors.shape)\nfor color in range(3):\n    array = ash_colors[..., color]\n    print(array.min(), array.max())","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.308956Z","iopub.execute_input":"2023-07-23T10:29:21.309368Z","iopub.status.idle":"2023-07-23T10:29:21.361821Z","shell.execute_reply.started":"2023-07-23T10:29:21.309335Z","shell.execute_reply":"2023-07-23T10:29:21.360538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pixel_mask = get_pixel_mask(sample_id, 'train')\n\nprint(pixel_mask.shape)\nprint(pixel_mask.min(), pixel_mask.max())","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.367850Z","iopub.execute_input":"2023-07-23T10:29:21.368871Z","iopub.status.idle":"2023-07-23T10:29:21.378477Z","shell.execute_reply.started":"2023-07-23T10:29:21.368827Z","shell.execute_reply":"2023-07-23T10:29:21.377174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"execution":{"iopub.execute_input":"2023-07-10T19:30:33.222846Z","iopub.status.busy":"2023-07-10T19:30:33.222338Z","iopub.status.idle":"2023-07-10T19:30:33.228013Z","shell.execute_reply":"2023-07-10T19:30:33.227016Z","shell.execute_reply.started":"2023-07-10T19:30:33.222811Z"}}},{"cell_type":"code","source":"SEED = 42","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.379977Z","iopub.execute_input":"2023-07-23T10:29:21.381257Z","iopub.status.idle":"2023-07-23T10:29:21.390111Z","shell.execute_reply.started":"2023-07-23T10:29:21.381193Z","shell.execute_reply":"2023-07-23T10:29:21.388793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:  # <CONFIG>\n    \n    seed = SEED\n\n    img_size = (256, 256)\n    \n    model = 'unet'\n    preprocess = None\n    backbone_trainable = True\n    \n#    num_epochs = 10  # <DEVEL> else 10\n    num_classes = 1\n    batch_size = 16  # <DEVEL> else 16 or 32\n    \n#    threshold = 'auto'","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.391668Z","iopub.execute_input":"2023-07-23T10:29:21.392454Z","iopub.status.idle":"2023-07-23T10:29:21.404111Z","shell.execute_reply.started":"2023-07-23T10:29:21.392419Z","shell.execute_reply":"2023-07-23T10:29:21.402805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://keras.io/examples/keras_recipes/reproducibility_recipes/\n\n# Set the seed using keras.utils.set_random_seed. This will set:\n# 1) `numpy` seed\n# 2) `tensorflow` random seed\n# 3) `python` random seed\nkeras.utils.set_random_seed(Config.seed)\n\n# See also:\n# tf.config.experimental.enable_op_determinism()","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.405511Z","iopub.execute_input":"2023-07-23T10:29:21.406542Z","iopub.status.idle":"2023-07-23T10:29:21.425705Z","shell.execute_reply.started":"2023-07-23T10:29:21.406500Z","shell.execute_reply":"2023-07-23T10:29:21.424351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mixed Precision\n# https://www.tensorflow.org/guide/mixed_precision#supported_hardware\n\nif PLATFORM == 'kaggle':\n    MIXED_PRECISION = True\nelif PLATFORM == 'gcp':\n    # No mixed precision on QCP:\n    # \"Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0.\n    # Your GPU: Tesla P100-PCIE-16GB, compute capability 6.0\"\n    MIXED_PRECISION = False\nelse:\n    raise NotImplementedError(f'unknown platform \"{PLATFORM}\"')\n\nif MIXED_PRECISION:\n    print('setting mixed_precision')\n\n    NP_FLOAT = 'float16'\n    TF_FLOAT = tf.float16\n    \n    keras.mixed_precision.set_global_policy('mixed_float16')\n    final_dtype = 'float32'\n    \nelse:\n    print('no mixed_precision')\n\n    NP_FLOAT = 'float32'\n    TF_FLOAT = tf.float32\n\n    final_dtype = None","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.427818Z","iopub.execute_input":"2023-07-23T10:29:21.428206Z","iopub.status.idle":"2023-07-23T10:29:21.442391Z","shell.execute_reply.started":"2023-07-23T10:29:21.428175Z","shell.execute_reply":"2023-07-23T10:29:21.440720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet:\n    '''U-Net model.\n    \n    Inspired by and adapted from:\n    - https://keras.io/examples/vision/oxford_pets_image_segmentation\n    - https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580\n    - https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow/home/week/3\n    '''\n    \n    def __init__(self, preprocess=None, weights=None):\n        self.preprocess = preprocess\n        self.weights = weights\n        \n    def conv2d_block(self, input_tensor, n_filters, kernel_size=3):\n        x = input_tensor\n        for i in range(2):\n            x = tf.keras.layers.SeparableConv2D(\n                filters = n_filters, kernel_size=(kernel_size, kernel_size), padding='same')(x)\n            #? kernel_initializer = 'he_normal'\n            x = tf.keras.layers.BatchNormalization()(x)\n            x = tf.keras.layers.Activation('relu')(x)\n        return x\n\n    def encoder_block(self, inputs, n_filters, pool_size, dropout):\n        f = self.conv2d_block(inputs, n_filters=n_filters)\n        p = tf.keras.layers.MaxPooling2D(pool_size)(f)\n        p = tf.keras.layers.Dropout(dropout)(p)\n        return f, p\n\n    def encoder(self, inputs, dropout=0.1):\n        f1, p1 = self.encoder_block(inputs, n_filters=64, pool_size=(2,2), dropout=dropout)\n        f2, p2 = self.encoder_block(p1, n_filters=128, pool_size=(2,2), dropout=dropout)\n        f3, p3 = self.encoder_block(p2, n_filters=256, pool_size=(2,2), dropout=dropout)\n        f4, p4 = self.encoder_block(p3, n_filters=512, pool_size=(2,2), dropout=dropout)\n        return p4, (f1, f2, f3, f4)\n\n    def bottleneck(self, inputs):\n        bottle_neck = self.conv2d_block(inputs, n_filters=1024)\n        return bottle_neck\n\n    def decoder_block(self, inputs, conv_output, n_filters, kernel_size, strides, dropout):\n        u = tf.keras.layers.Conv2DTranspose(\n            n_filters, kernel_size, strides=strides, padding = 'same')(inputs)\n        u = tf.keras.layers.BatchNormalization()(u)\n        c = tf.keras.layers.concatenate([u, conv_output])\n        c = tf.keras.layers.Dropout(dropout)(c)\n        c = self.conv2d_block(c, n_filters, kernel_size=3)\n        return c\n\n    def decoder(self, inputs, convs, num_classes, dropout=0.1):\n        f1, f2, f3, f4 = convs\n        c6 = self.decoder_block(inputs, f4, n_filters=512, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        c7 = self.decoder_block(c6, f3, n_filters=256, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        c8 = self.decoder_block(c7, f2, n_filters=128, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        c9 = self.decoder_block(c8, f1, n_filters=64, kernel_size=(3,3), strides=(2,2), dropout=dropout)\n        if num_classes == 1:\n            activation = \"sigmoid\"\n        else:\n            activation = \"softmax\"\n        outputs = layers.Conv2D(num_classes, kernel_size=3, activation=activation, padding=\"same\")(c9)\n        return outputs\n\n    def model(self, image_size, num_classes):\n        inputs = tf.keras.layers.Input(shape=(image_size,image_size,3))\n        encoder_output, convs = self.encoder(inputs)\n        #model = tf.keras.Model(inputs=inputs, outputs=encoder_output)  # debug\n        bottle_neck = self.bottleneck(encoder_output)\n        outputs = self.decoder(bottle_neck, convs, num_classes)\n        model = tf.keras.Model(name=self.__class__.__name__, inputs=inputs, outputs=outputs)\n        return model","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.444238Z","iopub.execute_input":"2023-07-23T10:29:21.445068Z","iopub.status.idle":"2023-07-23T10:29:21.473173Z","shell.execute_reply.started":"2023-07-23T10:29:21.445030Z","shell.execute_reply":"2023-07-23T10:29:21.472006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Free up RAM in case the model definition cells were run multiple times\nkeras.backend.clear_session()\n\n# Build model\nif Config.model == 'unet':\n    builder = UNet()\n\nelse:\n    raise NotImplementedError(f'model \"{Config.model}\"')\n    \nmodel = builder.model(image_size=Config.img_size[0], num_classes=Config.num_classes)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:21.475361Z","iopub.execute_input":"2023-07-23T10:29:21.475938Z","iopub.status.idle":"2023-07-23T10:29:23.455231Z","shell.execute_reply.started":"2023-07-23T10:29:21.475783Z","shell.execute_reply":"2023-07-23T10:29:23.453670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Free up RAM in case the model definition cells were run multiple times\n#keras.backend.clear_session()\n\n#class ModelBuilder:\n#    \n#    def __init__(self):\n#        self.preprocess = None\n#\n#builder = ModelBuilder()","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:23.457520Z","iopub.execute_input":"2023-07-23T10:29:23.458671Z","iopub.status.idle":"2023-07-23T10:29:23.464951Z","shell.execute_reply.started":"2023-07-23T10:29:23.458628Z","shell.execute_reply":"2023-07-23T10:29:23.463053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare datasets","metadata":{"execution":{"iopub.execute_input":"2023-07-10T19:30:33.222846Z","iopub.status.busy":"2023-07-10T19:30:33.222338Z","iopub.status.idle":"2023-07-10T19:30:33.228013Z","shell.execute_reply":"2023-07-10T19:30:33.227016Z","shell.execute_reply.started":"2023-07-10T19:30:33.222811Z"}}},{"cell_type":"code","source":"N_TRAIN = None  # 512 <DEVEL> else None\nN_VALID = None  # 128 <DEVEL> else None\nN_PARTIAL = 128  # 128","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:23.467236Z","iopub.execute_input":"2023-07-23T10:29:23.467840Z","iopub.status.idle":"2023-07-23T10:29:23.478808Z","shell.execute_reply.started":"2023-07-23T10:29:23.467791Z","shell.execute_reply":"2023-07-23T10:29:23.477462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('preprocess =', builder.preprocess)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:23.480576Z","iopub.execute_input":"2023-07-23T10:29:23.481068Z","iopub.status.idle":"2023-07-23T10:29:23.499639Z","shell.execute_reply.started":"2023-07-23T10:29:23.481024Z","shell.execute_reply":"2023-07-23T10:29:23.498120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AshColorSingleFrames(keras.utils.Sequence):\n    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n\n    def __init__(self, batch_size, img_size, sample_ids, split_dir, preprocess=None, n_samples=None):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.split_dir = split_dir\n        self.sample_ids = sample_ids[:n_samples]\n        self.preprocess = preprocess\n\n    def __len__(self):\n        return math.ceil(len(self.sample_ids) / self.batch_size)\n    \n    def get_sample_ids(self, idx):\n        '''Get sample ids of batch idx.'''\n        i = idx * self.batch_size\n        return self.sample_ids[i : i + self.batch_size]\n    \n    def __getitem__(self, idx):\n        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n        \n        batch_sample_ids = self.get_sample_ids(idx)\n        \n        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=NP_FLOAT)\n        for j, sample_id in enumerate(batch_sample_ids):\n            \n            img = get_ash_colors(sample_id, self.split_dir)[..., N_TIMES_BEFORE]\n            \n            if self.preprocess == 'resnet50':\n                img = keras.applications.resnet50.preprocess_input(img)\n            elif self.preprocess is not None:\n                raise NotImplementedError(f'preprocess \"{self.preprocess}\"')\n            \n            x[j] = img\n\n        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n        if self.split_dir != 'test':\n            for j, sample_id in enumerate(batch_sample_ids):\n                img = get_pixel_mask(sample_id, self.split_dir)\n                y[j] = img\n        \n        return x, y","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:23.501501Z","iopub.execute_input":"2023-07-23T10:29:23.502010Z","iopub.status.idle":"2023-07-23T10:29:23.522259Z","shell.execute_reply.started":"2023-07-23T10:29:23.501964Z","shell.execute_reply":"2023-07-23T10:29:23.520738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = AshColorSingleFrames(\n    Config.batch_size, Config.img_size, train_ids, 'train',\n    preprocess=builder.preprocess, n_samples=N_TRAIN)\nprint('number of batches:', len(train_set), 'train')\n\nvalid_set = AshColorSingleFrames(\n    Config.batch_size, Config.img_size, valid_ids, 'validation',\n    preprocess=builder.preprocess, n_samples=N_VALID)\nprint('number of batches:', len(valid_set), 'valid')\n\npartial_set = AshColorSingleFrames(\n    Config.batch_size, Config.img_size, valid_ids, 'validation',\n    preprocess=builder.preprocess, n_samples=N_PARTIAL)\nprint('number of batches:', len(partial_set), 'partial')\n\ntest_set = AshColorSingleFrames(\n    Config.batch_size, Config.img_size, test_ids, 'test',\n    preprocess=builder.preprocess)\nprint('number of batches:', len(test_set), 'test')","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:23.524078Z","iopub.execute_input":"2023-07-23T10:29:23.524512Z","iopub.status.idle":"2023-07-23T10:29:23.538936Z","shell.execute_reply.started":"2023-07-23T10:29:23.524478Z","shell.execute_reply":"2023-07-23T10:29:23.537529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Check dimensions (x, y) of first batch:')\n\ntrain_set[0][0].shape, train_set[0][1].shape","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:23.540217Z","iopub.execute_input":"2023-07-23T10:29:23.540684Z","iopub.status.idle":"2023-07-23T10:29:24.314726Z","shell.execute_reply.started":"2023-07-23T10:29:23.540641Z","shell.execute_reply":"2023-07-23T10:29:24.313241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generate TFRecords","metadata":{}},{"cell_type":"code","source":"class TFDataSetCreator:\n    '''Write TFRecords files and generate a TFRecordDataset from a keras.Sequence.\n    \n    Inspired by:\n    - https://www.tensorflow.org/tutorials/load_data/tfrecord\n    - https://keras.io/examples/keras_recipes/creating_tfrecords\n    - https://keras.io/examples/keras_recipes/tfrecord\n    - https://stackoverflow.com/questions/47861084/how-to-store-numpy-arrays-as-tfrecord\n    \n    References:\n    - https://www.tensorflow.org/guide/data - Build TensorFlow input pipelines\n    - https://www.tensorflow.org/guide/data_performance - Better performance with the tf.data API\n    '''\n    \n    def __init__(self, keras_sequence):\n        self.keras_sequence = keras_sequence\n        self.split_dir = keras_sequence.split_dir\n        self.batch_size = keras_sequence.batch_size\n        \n        self.keep_existing = True\n        self.records_dir = os.path.join(RECORDS_DIR, f'records-{NP_FLOAT}-{self.split_dir}')\n        self.record_paths = []\n        \n        self.progress_bar = True  # <DEVEL>\n    \n    def write_tfrec(self, batch_idx):\n        #pid = multiprocessing.current_process().pid\n        if self.progress_bar:\n            if batch_idx != 0 and batch_idx % 100 == 0:\n                print('\\n%d' % int(batch_idx / 100), end='')\n            else:\n                print('.', end='')\n        \n        sample_ids = self.keras_sequence.get_sample_ids(batch_idx)\n        x_b, y_b = self.keras_sequence[batch_idx]\n        \n        record_paths = []\n        \n        for x, y, sample_id in zip(x_b, y_b, sample_ids):\n            \n            #x = x[np.newaxis, :]\n            #y = y[np.newaxis, :]\n            \n            record_path = os.path.join(self.records_dir, f'{sample_id}.tfrec')\n            record_paths.append(record_path)\n            \n            if self.keep_existing and os.path.exists(record_path):\n                continue\n        \n            with tf.io.TFRecordWriter(record_path) as writer:\n                    feature = {\n                        \"x\": tf.train.Feature(\n                            bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(x).numpy()])),\n                        \"y\": tf.train.Feature(\n                            bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(y).numpy()])),\n                    }\n                    example = tf.train.Example(features=tf.train.Features(feature=feature))\n                    writer.write(example.SerializeToString())\n        \n        return record_paths\n    \n    def generate_tfrec(self, keep_existing=True):\n        \n        self.keep_existing = keep_existing\n        \n        records_dir = self.records_dir\n        os.makedirs(records_dir, exist_ok=True)\n        \n        n_records = len(self.keras_sequence)\n        n_procs = multiprocessing.cpu_count() * 2\n        print(f'generating {n_records} records with {n_procs} processes in: {records_dir}')\n        %ll -hd $records_dir\n\n        pool = multiprocessing.Pool(processes=n_procs)\n        batch_indexes = range(n_records)\n        all_record_paths = sorted(pool.map(self.write_tfrec, batch_indexes))\n        if self.progress_bar:\n            print()\n        \n        !du -sh $records_dir\n        self.record_paths = list(itertools.chain.from_iterable(all_record_paths))\n        return self\n    \n    @staticmethod\n    def parse_tfrecord_sample(element):\n        parse_dic = {\n            'x': tf.io.FixedLenFeature([], tf.string),  # Note that it is tf.string, not tf.float32\n            'y': tf.io.FixedLenFeature([], tf.string),  # Note that it is tf.string, not tf.float32\n        }\n        feature = tf.io.parse_single_example(element, parse_dic)\n        feature['x'] = tf.io.parse_tensor(feature['x'], out_type=TF_FLOAT)\n        feature['y'] = tf.io.parse_tensor(feature['y'], out_type=tf.uint8)\n        return feature\n\n    @staticmethod\n    def prepare_sample(features):\n        return features['x'], features['y']\n\n    def dataset(self):\n        dataset = (\n            tf.data.TFRecordDataset(self.record_paths, num_parallel_reads=AUTOTUNE)\n            .map(self.parse_tfrecord_sample, num_parallel_calls=AUTOTUNE)\n            .map(self.prepare_sample, num_parallel_calls=AUTOTUNE)\n            .shuffle(len(self.keras_sequence.sample_ids))\n            .batch(self.batch_size)\n            .prefetch(AUTOTUNE)\n        )\n        return dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:24.317160Z","iopub.execute_input":"2023-07-23T10:29:24.318216Z","iopub.status.idle":"2023-07-23T10:29:24.368953Z","shell.execute_reply.started":"2023-07-23T10:29:24.318175Z","shell.execute_reply":"2023-07-23T10:29:24.367496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KEEP_EXISTING = True  # <DEVEL>\n\ntimeit_start = datetime.datetime.now()\n\ntf.debugging.set_log_device_placement(True)\n\n# Place tensors on the CPU\nwith tf.device('/CPU:0'):\n\n    tf_train_set = (\n        TFDataSetCreator(train_set)\n        .generate_tfrec(KEEP_EXISTING)\n        .dataset()\n    )\n\n    tf_valid_set = (\n        TFDataSetCreator(valid_set)\n        .generate_tfrec(KEEP_EXISTING)\n        .dataset()\n    )\n\n    tf_test_set = (\n        TFDataSetCreator(test_set)\n        .generate_tfrec(KEEP_EXISTING)\n        .dataset()\n    )\n\ntf.debugging.set_log_device_placement(False)\n\ntimeit_end = datetime.datetime.now()\nprint('datasets generated in:', timeit_end - timeit_start)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:29:24.370676Z","iopub.execute_input":"2023-07-23T10:29:24.371096Z","iopub.status.idle":"2023-07-23T10:36:23.189674Z","shell.execute_reply.started":"2023-07-23T10:29:24.371060Z","shell.execute_reply":"2023-07-23T10:36:23.187561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def strf_timedelta(timedelta):\n    total_seconds = timedelta.total_seconds()\n    hours, remainder = divmod(total_seconds, 3600)\n    minutes, seconds = divmod(remainder, 60)\n    return '{:02}:{:02}:{:02}'.format(int(hours), int(minutes), int(seconds))\n\nend_time = datetime.datetime.now(timezone('CET'))\n\nprint('Terminated', end_time.strftime(PRINT_TIME_FORMAT),\n      'in', strf_timedelta(end_time - start_time))","metadata":{"execution":{"iopub.status.busy":"2023-07-23T10:36:23.197816Z","iopub.execute_input":"2023-07-23T10:36:23.198371Z","iopub.status.idle":"2023-07-23T10:36:23.211736Z","shell.execute_reply.started":"2023-07-23T10:36:23.198286Z","shell.execute_reply":"2023-07-23T10:36:23.210105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"THIS IS THE END!","metadata":{}}]}