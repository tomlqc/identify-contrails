
Identify Contrails with Keras

# reinstall tensorflow-io
# to avoid the UserWarning: unable to load libtensorflow_io_plugins.so

#!pip install tensorflow-io

import os

# ==============================

TRAIN = True

if os.path.exists('/kaggle'):
    PLATFORM = 'kaggle'
else:
    PLATFORM = 'gcp'

# ==============================

print(f'PLATFORM = {PLATFORM}')

PLATFORM = kaggle

if PLATFORM == 'kaggle':

    WORK_DIR = '/kaggle/working'  # preserved if notebook is saved
    TEMP_DIR = '/kaggle/temp'  # just during current session

    DATA_DIR = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'

    # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
    # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

elif PLATFORM == 'gcp':

    WORK_DIR = '/home/jupyter/kaggle/working'  # preserved if notebook is saved
    TEMP_DIR = '/home/jupyter/kaggle/temp'  # just during current session

    DATA_DIR = '/home/jupyter/kaggle/input/google-research-identify-contrails-reduce-global-warming'
    
    %cd $WORK_DIR

print('PWD =', os.getcwd())

PWD = /kaggle/working

UPDATE_DATA = False

if UPDATE_DATA:
    %cp -v /kaggle/input/identify-contrails/contrails_2023*.h5 .

if not TRAIN:
    checkpoint_path = 'contrails_2023-07-15_15-10-49.h5'
    print(f'checkpoint_path = {checkpoint_path}')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import datetime
import math
import pathlib
import random
import shutil

from pytz import timezone

from tqdm.notebook import tqdm

import matplotlib.pyplot as plt
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import scipy

PRINT_TIME_FORMAT = "%Y-%m-%d %H:%M:%S %Z%z"
FILE_TIME_FORMAT = "%Y-%m-%d_%H-%M-%S"

now_time = datetime.datetime.now(timezone('CET'))

file_time_str = now_time.strftime(FILE_TIME_FORMAT)

print('Started', now_time.strftime(PRINT_TIME_FORMAT))

Started 2023-07-20 17:45:46 CEST+0200

import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import backend as backend

/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']
caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']
  warnings.warn(f"unable to load libtensorflow_io_plugins.so: {e}")
/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']
caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']
  warnings.warn(f"file system plugins are not loaded: {e}")

print('TensorFlow version:', tf.__version__)

TensorFlow version: 2.12.0

print("Num CPUs Available: ", len(tf.config.list_physical_devices('CPU')))
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

Num CPUs Available:  1
Num GPUs Available:  1

#---------------------------------------------------------------------------79

Setup

class Paths:
    train = os.path.join(DATA_DIR, 'train')
    valid = os.path.join(DATA_DIR, 'validation')
    test = os.path.join(DATA_DIR, 'test')

sort_list = list  # list | sorted  # <DEVEL>

train_ids = sort_list(os.listdir(Paths.train))
valid_ids = sort_list(os.listdir(Paths.valid))
test_ids = sort_list(os.listdir(Paths.test))
print('n_samples (train, validation, test) =', len(train_ids), len(valid_ids), len(test_ids))

n_samples (train, validation, test) = 20529 1856 2

class ABI:
    bands = {name: idx for idx, name in enumerate([
        '08', '09', '10', '11', '12', '13', '14', '15', '16'])}
    colors = {name: idx for idx, name in enumerate([
        'red', 'blue', 'green', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'black'])}

N_TIMES_BEFORE = 4
N_TIMES_AFTER = 3

def normalize_range(data, bounds):
    """Maps data to the range [0, 1]."""
    return (data - bounds[0]) / (bounds[1] - bounds[0])

_T11_BOUNDS = (243, 303)
_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)
_TDIFF_BOUNDS = (-4, 2)

def get_ash_colors(sample_id, split_dir):
    """
    Based on bands: 11, 14, 15
    
    Args:
        sample_id(str): The id of the example i.e. '1000216489776414077'
        split_dir(str): The split directoryu i.e. 'test', 'train', 'val'
    """
    band15 = np.load(DATA_DIR + f"/{split_dir}/{sample_id}/band_15.npy")
    band14 = np.load(DATA_DIR + f"/{split_dir}/{sample_id}/band_14.npy")
    band11 = np.load(DATA_DIR + f"/{split_dir}/{sample_id}/band_11.npy")

    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)
    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)
    b = normalize_range(band14, _T11_BOUNDS)
    ash_colors = np.clip(np.stack([r, g, b], axis=2), 0, 1)
    
    return ash_colors

def get_individual_mask(sample_id, split_dir):
    masks_path = DATA_DIR + f"/{split_dir}/{sample_id}/human_individual_masks.npy"
    pixel_mask = np.load(masks_path)
    return pixel_mask

def get_pixel_mask(sample_id, split_dir):
    masks_path = DATA_DIR + f"/{split_dir}/{sample_id}/human_pixel_masks.npy"
    pixel_mask = np.load(masks_path)
    return pixel_mask

Check some values (DEVEL)

sample_id = train_ids[3]

ash_colors = get_ash_colors(sample_id, 'train')[..., N_TIMES_BEFORE]

print(ash_colors.shape)
for color in range(3):
    array = ash_colors[..., color]
    print(array.min(), array.max())

(256, 256, 3)
0.0 0.50921124
0.097476535 0.86938816
0.031865694 0.81146187

pixel_mask = get_pixel_mask(sample_id, 'train')

print(pixel_mask.shape)
print(pixel_mask.min(), pixel_mask.max())

(256, 256, 1)
0 1

Model

SEED = 42

class Config:
    
    img_size = (256, 256)
    
    model = 'unet'
    
    num_epochs = 3  # <DEVEL> else 10
    num_classes = 1
    batch_size = 16  # <DEVEL> else 16 or 32
    
    threshold = 0.40
    
    seed = SEED

# https://keras.io/examples/keras_recipes/reproducibility_recipes/

# Set the seed using keras.utils.set_random_seed. This will set:
# 1) `numpy` seed
# 2) `tensorflow` random seed
# 3) `python` random seed
keras.utils.set_random_seed(Config.seed)

# See also:
# tf.config.experimental.enable_op_determinism()

class UNet:
    '''U-Net model.
    
    Inspired by and adapted from:
    - https://keras.io/examples/vision/oxford_pets_image_segmentation
    - https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580
    - https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow/home/week/3
    '''
    
    @classmethod
    def conv2d_block(cls, input_tensor, n_filters, kernel_size=3):
        x = input_tensor
        for i in range(2):
            x = tf.keras.layers.SeparableConv2D(
                filters = n_filters, kernel_size=(kernel_size, kernel_size), padding='same')(x)
            #? kernel_initializer = 'he_normal'
            x = tf.keras.layers.BatchNormalization()(x)
            x = tf.keras.layers.Activation('relu')(x)
        return x

    @classmethod
    def encoder_block(cls, inputs, n_filters, pool_size, dropout):
        f = cls.conv2d_block(inputs, n_filters=n_filters)
        p = tf.keras.layers.MaxPooling2D(pool_size)(f)
        p = tf.keras.layers.Dropout(dropout)(p)
        return f, p

    @classmethod
    def encoder(cls, inputs, dropout=0.1):
        f1, p1 = cls.encoder_block(inputs, n_filters=64, pool_size=(2,2), dropout=dropout)
        f2, p2 = cls.encoder_block(p1, n_filters=128, pool_size=(2,2), dropout=dropout)
        f3, p3 = cls.encoder_block(p2, n_filters=256, pool_size=(2,2), dropout=dropout)
        f4, p4 = cls.encoder_block(p3, n_filters=512, pool_size=(2,2), dropout=dropout)
        return p4, (f1, f2, f3, f4)

    @classmethod
    def bottleneck(cls, inputs):
        bottle_neck = cls.conv2d_block(inputs, n_filters=1024)
        return bottle_neck

    @classmethod
    def decoder_block(cls, inputs, conv_output, n_filters, kernel_size, strides, dropout):
        u = tf.keras.layers.Conv2DTranspose(
            n_filters, kernel_size, strides=strides, padding = 'same')(inputs)
        u = tf.keras.layers.BatchNormalization()(u)
        c = tf.keras.layers.concatenate([u, conv_output])
        c = tf.keras.layers.Dropout(dropout)(c)
        c = cls.conv2d_block(c, n_filters, kernel_size=3)
        return c

    @classmethod
    def decoder(cls, inputs, convs, num_classes, dropout=0.1):
        f1, f2, f3, f4 = convs
        c6 = cls.decoder_block(inputs, f4, n_filters=512, kernel_size=(3,3), strides=(2,2), dropout=dropout)
        c7 = cls.decoder_block(c6, f3, n_filters=256, kernel_size=(3,3), strides=(2,2), dropout=dropout)
        c8 = cls.decoder_block(c7, f2, n_filters=128, kernel_size=(3,3), strides=(2,2), dropout=dropout)
        c9 = cls.decoder_block(c8, f1, n_filters=64, kernel_size=(3,3), strides=(2,2), dropout=dropout)
        if num_classes == 1:
            activation = "sigmoid"
        else:
            activation = "softmax"
        outputs = layers.Conv2D(num_classes, kernel_size=3, activation=activation, padding="same")(c9)
        return outputs

    @classmethod
    def model(cls, image_size, num_classes):
        inputs = tf.keras.layers.Input(shape=(image_size,image_size,3))
        encoder_output, convs = cls.encoder(inputs)
        #model = tf.keras.Model(inputs=inputs, outputs=encoder_output)  # debug
        bottle_neck = cls.bottleneck(encoder_output)
        outputs = cls.decoder(bottle_neck, convs, num_classes)
        model = tf.keras.Model(name=cls.__name__, inputs=inputs, outputs=outputs)
        return model

class DeepLabV3Plus:
    '''DeepLabV3+ model.
    
    Adapted from:
    - https://keras.io/examples/vision/deeplabv3_plus/#inference-using-colormap-overlay
    '''
    
    @classmethod
    def convolution_block(
        cls,
        block_input,
        num_filters=256,
        kernel_size=3,
        dilation_rate=1,
        padding="same",
        use_bias=False,
    ):
        x = layers.Conv2D(
            num_filters,
            kernel_size=kernel_size,
            dilation_rate=dilation_rate,
            padding="same",
            use_bias=use_bias,
            kernel_initializer=keras.initializers.HeNormal(),
        )(block_input)
        x = layers.BatchNormalization()(x)
        return tf.nn.relu(x)

    @classmethod
    def DilatedSpatialPyramidPooling(cls, dspp_input):
        dims = dspp_input.shape
        x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)
        x = cls.convolution_block(x, kernel_size=1, use_bias=True)
        out_pool = layers.UpSampling2D(
            size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation="bilinear",
        )(x)

        out_1 = cls.convolution_block(dspp_input, kernel_size=1, dilation_rate=1)
        out_6 = cls.convolution_block(dspp_input, kernel_size=3, dilation_rate=6)
        out_12 = cls.convolution_block(dspp_input, kernel_size=3, dilation_rate=12)
        out_18 = cls.convolution_block(dspp_input, kernel_size=3, dilation_rate=18)

        x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])
        output = cls.convolution_block(x, kernel_size=1)
        return output
    
    @classmethod
    def model(cls, image_size, num_classes, weights):
        
        model_input = keras.Input(shape=(image_size, image_size, 3))
        
        resnet50 = keras.applications.ResNet50(
            weights=weights, include_top=False, input_tensor=model_input,
        )
        resnet50.trainable = False
        print('resnet50.trainable =', resnet50.trainable)
        
        x = resnet50.get_layer("conv4_block6_2_relu").output
        x = cls.DilatedSpatialPyramidPooling(x)

        input_a = layers.UpSampling2D(
            size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),
            interpolation="bilinear",
        )(x)
        input_b = resnet50.get_layer("conv2_block3_2_relu").output
        input_b = cls.convolution_block(input_b, num_filters=48, kernel_size=1)

        x = layers.Concatenate(axis=-1)([input_a, input_b])
        x = cls.convolution_block(x)
        x = cls.convolution_block(x)
        x = layers.UpSampling2D(
            size=(image_size // x.shape[1], image_size // x.shape[2]),
            interpolation="bilinear",
        )(x)
        
        if num_classes == 1:
            activation = "sigmoid"
        else:
            activation = "softmax"
        model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), activation=activation, padding="same")(x)
        
        return keras.Model(name=cls.__name__, inputs=model_input, outputs=model_output)    

#import tensorflow_hub as hub
#
#model = tf.keras.Sequential([
#    keras.Input(shape=(224, 224, 3)),
#    hub.KerasLayer("/kaggle/input/resnet-50/tensorflow2/feature-vector/1",
#       trainable=False)
#])
#    
#model.summary()

# Free up RAM in case the model definition cells were run multiple times
keras.backend.clear_session()


# Build model
if Config.model == 'unet':
    model = UNet.model(image_size=256, num_classes=1)
    PREPROCESS = None

elif Config.model == 'deeplabv3plus':
    resnet50_weights_path = '/kaggle/input/d/alexisbcook/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'
    model = DeepLabV3Plus.model(image_size=256, num_classes=1, weights=resnet50_weights_path)
    PREPROCESS = 'resnet50'

else:
    raise NotImplementedError(f'model "{Config.model}"')
    
model.summary()

Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               
                                )]                                                                
                                                                                                  
 separable_conv2d (SeparableCon  (None, 256, 256, 64  283        ['input_1[0][0]']                
 v2D)                           )                                                                 
                                                                                                  
 batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['separable_conv2d[0][0]']       
 alization)                     )                                                                 
                                                                                                  
 activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    
                                )                                                                 
                                                                                                  
 separable_conv2d_1 (SeparableC  (None, 256, 256, 64  4736       ['activation[0][0]']             
 onv2D)                         )                                                                 
                                                                                                  
 batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['separable_conv2d_1[0][0]']     
 rmalization)                   )                                                                 
                                                                                                  
 activation_1 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[0][0]']  
                                )                                                                 
                                                                                                  
 max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['activation_1[0][0]']           
                                )                                                                 
                                                                                                  
 dropout (Dropout)              (None, 128, 128, 64  0           ['max_pooling2d[0][0]']          
                                )                                                                 
                                                                                                  
 separable_conv2d_2 (SeparableC  (None, 128, 128, 12  8896       ['dropout[0][0]']                
 onv2D)                         8)                                                                
                                                                                                  
 batch_normalization_2 (BatchNo  (None, 128, 128, 12  512        ['separable_conv2d_2[0][0]']     
 rmalization)                   8)                                                                
                                                                                                  
 activation_2 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_2[0][0]']  
                                8)                                                                
                                                                                                  
 separable_conv2d_3 (SeparableC  (None, 128, 128, 12  17664      ['activation_2[0][0]']           
 onv2D)                         8)                                                                
                                                                                                  
 batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['separable_conv2d_3[0][0]']     
 rmalization)                   8)                                                                
                                                                                                  
 activation_3 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[0][0]']  
                                8)                                                                
                                                                                                  
 max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['activation_3[0][0]']           
                                                                                                  
 dropout_1 (Dropout)            (None, 64, 64, 128)  0           ['max_pooling2d_1[0][0]']        
                                                                                                  
 separable_conv2d_4 (SeparableC  (None, 64, 64, 256)  34176      ['dropout_1[0][0]']              
 onv2D)                                                                                           
                                                                                                  
 batch_normalization_4 (BatchNo  (None, 64, 64, 256)  1024       ['separable_conv2d_4[0][0]']     
 rmalization)                                                                                     
                                                                                                  
 activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_4[0][0]']  
                                                                                                  
 separable_conv2d_5 (SeparableC  (None, 64, 64, 256)  68096      ['activation_4[0][0]']           
 onv2D)                                                                                           
                                                                                                  
 batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['separable_conv2d_5[0][0]']     
 rmalization)                                                                                     
                                                                                                  
 activation_5 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[0][0]']  
                                                                                                  
 max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['activation_5[0][0]']           
                                                                                                  
 dropout_2 (Dropout)            (None, 32, 32, 256)  0           ['max_pooling2d_2[0][0]']        
                                                                                                  
 separable_conv2d_6 (SeparableC  (None, 32, 32, 512)  133888     ['dropout_2[0][0]']              
 onv2D)                                                                                           
                                                                                                  
 batch_normalization_6 (BatchNo  (None, 32, 32, 512)  2048       ['separable_conv2d_6[0][0]']     
 rmalization)                                                                                     
                                                                                                  
 activation_6 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_6[0][0]']  
                                                                                                  
 separable_conv2d_7 (SeparableC  (None, 32, 32, 512)  267264     ['activation_6[0][0]']           
 onv2D)                                                                                           
                                                                                                  
 batch_normalization_7 (BatchNo  (None, 32, 32, 512)  2048       ['separable_conv2d_7[0][0]']     
 rmalization)                                                                                     
                                                                                                  
 activation_7 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_7[0][0]']  
                                                                                                  
 max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['activation_7[0][0]']           
                                                                                                  
 dropout_3 (Dropout)            (None, 16, 16, 512)  0           ['max_pooling2d_3[0][0]']        
                                                                                                  
 separable_conv2d_8 (SeparableC  (None, 16, 16, 1024  529920     ['dropout_3[0][0]']              
 onv2D)                         )                                                                 
                                                                                                  
 batch_normalization_8 (BatchNo  (None, 16, 16, 1024  4096       ['separable_conv2d_8[0][0]']     
 rmalization)                   )                                                                 
                                                                                                  
 activation_8 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_8[0][0]']  
                                )                                                                 
                                                                                                  
 separable_conv2d_9 (SeparableC  (None, 16, 16, 1024  1058816    ['activation_8[0][0]']           
 onv2D)                         )                                                                 
                                                                                                  
 batch_normalization_9 (BatchNo  (None, 16, 16, 1024  4096       ['separable_conv2d_9[0][0]']     
 rmalization)                   )                                                                 
                                                                                                  
 activation_9 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_9[0][0]']  
                                )                                                                 
                                                                                                  
 conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  4719104    ['activation_9[0][0]']           
 ose)                                                                                             
                                                                                                  
 batch_normalization_10 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_transpose[0][0]']       
 ormalization)                                                                                    
                                                                                                  
 concatenate (Concatenate)      (None, 32, 32, 1024  0           ['batch_normalization_10[0][0]', 
                                )                                 'activation_7[0][0]']           
                                                                                                  
 dropout_4 (Dropout)            (None, 32, 32, 1024  0           ['concatenate[0][0]']            
                                )                                                                 
                                                                                                  
 separable_conv2d_10 (Separable  (None, 32, 32, 512)  534016     ['dropout_4[0][0]']              
 Conv2D)                                                                                          
                                                                                                  
 batch_normalization_11 (BatchN  (None, 32, 32, 512)  2048       ['separable_conv2d_10[0][0]']    
 ormalization)                                                                                    
                                                                                                  
 activation_10 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_11[0][0]'] 
                                                                                                  
 separable_conv2d_11 (Separable  (None, 32, 32, 512)  267264     ['activation_10[0][0]']          
 Conv2D)                                                                                          
                                                                                                  
 batch_normalization_12 (BatchN  (None, 32, 32, 512)  2048       ['separable_conv2d_11[0][0]']    
 ormalization)                                                                                    
                                                                                                  
 activation_11 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_12[0][0]'] 
                                                                                                  
 conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  1179904    ['activation_11[0][0]']          
 spose)                                                                                           
                                                                                                  
 batch_normalization_13 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_transpose_1[0][0]']     
 ormalization)                                                                                    
                                                                                                  
 concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['batch_normalization_13[0][0]', 
                                                                  'activation_5[0][0]']           
                                                                                                  
 dropout_5 (Dropout)            (None, 64, 64, 512)  0           ['concatenate_1[0][0]']          
                                                                                                  
 separable_conv2d_12 (Separable  (None, 64, 64, 256)  135936     ['dropout_5[0][0]']              
 Conv2D)                                                                                          
                                                                                                  
 batch_normalization_14 (BatchN  (None, 64, 64, 256)  1024       ['separable_conv2d_12[0][0]']    
 ormalization)                                                                                    
                                                                                                  
 activation_12 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_14[0][0]'] 
                                                                                                  
 separable_conv2d_13 (Separable  (None, 64, 64, 256)  68096      ['activation_12[0][0]']          
 Conv2D)                                                                                          
                                                                                                  
 batch_normalization_15 (BatchN  (None, 64, 64, 256)  1024       ['separable_conv2d_13[0][0]']    
 ormalization)                                                                                    
                                                                                                  
 activation_13 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_15[0][0]'] 
                                                                                                  
 conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  295040     ['activation_13[0][0]']          
 spose)                         8)                                                                
                                                                                                  
 batch_normalization_16 (BatchN  (None, 128, 128, 12  512        ['conv2d_transpose_2[0][0]']     
 ormalization)                  8)                                                                
                                                                                                  
 concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['batch_normalization_16[0][0]', 
                                6)                                'activation_3[0][0]']           
                                                                                                  
 dropout_6 (Dropout)            (None, 128, 128, 25  0           ['concatenate_2[0][0]']          
                                6)                                                                
                                                                                                  
 separable_conv2d_14 (Separable  (None, 128, 128, 12  35200      ['dropout_6[0][0]']              
 Conv2D)                        8)                                                                
                                                                                                  
 batch_normalization_17 (BatchN  (None, 128, 128, 12  512        ['separable_conv2d_14[0][0]']    
 ormalization)                  8)                                                                
                                                                                                  
 activation_14 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_17[0][0]'] 
                                8)                                                                
                                                                                                  
 separable_conv2d_15 (Separable  (None, 128, 128, 12  17664      ['activation_14[0][0]']          
 Conv2D)                        8)                                                                
                                                                                                  
 batch_normalization_18 (BatchN  (None, 128, 128, 12  512        ['separable_conv2d_15[0][0]']    
 ormalization)                  8)                                                                
                                                                                                  
 activation_15 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_18[0][0]'] 
                                8)                                                                
                                                                                                  
 conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  73792      ['activation_15[0][0]']          
 spose)                         )                                                                 
                                                                                                  
 batch_normalization_19 (BatchN  (None, 256, 256, 64  256        ['conv2d_transpose_3[0][0]']     
 ormalization)                  )                                                                 
                                                                                                  
 concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['batch_normalization_19[0][0]', 
                                8)                                'activation_1[0][0]']           
                                                                                                  
 dropout_7 (Dropout)            (None, 256, 256, 12  0           ['concatenate_3[0][0]']          
                                8)                                                                
                                                                                                  
 separable_conv2d_16 (Separable  (None, 256, 256, 64  9408       ['dropout_7[0][0]']              
 Conv2D)                        )                                                                 
                                                                                                  
 batch_normalization_20 (BatchN  (None, 256, 256, 64  256        ['separable_conv2d_16[0][0]']    
 ormalization)                  )                                                                 
                                                                                                  
 activation_16 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_20[0][0]'] 
                                )                                                                 
                                                                                                  
 separable_conv2d_17 (Separable  (None, 256, 256, 64  4736       ['activation_16[0][0]']          
 Conv2D)                        )                                                                 
                                                                                                  
 batch_normalization_21 (BatchN  (None, 256, 256, 64  256        ['separable_conv2d_17[0][0]']    
 ormalization)                  )                                                                 
                                                                                                  
 activation_17 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_21[0][0]'] 
                                )                                                                 
                                                                                                  
 conv2d (Conv2D)                (None, 256, 256, 1)  577         ['activation_17[0][0]']          
                                                                                                  
==================================================================================================
Total params: 9,491,868
Trainable params: 9,478,172
Non-trainable params: 13,696
__________________________________________________________________________________________________

Prepare datasets

N_SAMPLES = None  # <DEVEL> None to take all
N_PARTIAL = 128  # 128

class AshColorSingleFrames(keras.utils.Sequence):
    """Helper to iterate over the data (as Numpy arrays)."""

    def __init__(self, batch_size, img_size, sample_ids, split_dir, preprocess=None, n_samples=None):
        self.batch_size = batch_size
        self.img_size = img_size
        self.split_dir = split_dir
        self.sample_ids = sample_ids[:n_samples]
        self.preprocess = preprocess

    def __len__(self):
        return math.ceil(len(self.sample_ids) / self.batch_size)

    def __getitem__(self, idx):
        """Returns tuple (input, target) correspond to batch #idx."""
        i = idx * self.batch_size
        batch_sample_ids = self.sample_ids[i : i + self.batch_size]
        
        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype="float32")
        for j, sample_id in enumerate(batch_sample_ids):
            
            img = get_ash_colors(sample_id, self.split_dir)[..., N_TIMES_BEFORE]
            
            if self.preprocess == 'resnet50':
                img = keras.applications.resnet50.preprocess_input(img)
            elif self.preprocess is not None:
                raise NotImplementedError(f'preprocess "{preprocess}"')
            
            x[j] = img

        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype="uint8")
        if self.split_dir != 'test':
            for j, sample_id in enumerate(batch_sample_ids):
                img = get_pixel_mask(sample_id, self.split_dir)
                y[j] = img
        
        return x, y

train_set = AshColorSingleFrames(
    Config.batch_size, Config.img_size, train_ids, 'train',
    preprocess=PREPROCESS, n_samples=N_SAMPLES)  # <DEVEL>
print('number of batches:', len(train_set))

number of batches: 1284

valid_set = AshColorSingleFrames(
    Config.batch_size, Config.img_size, valid_ids, 'validation',
    preprocess=PREPROCESS, n_samples=N_SAMPLES)  # <DEVEL>
print('number of batches:', len(valid_set))

number of batches: 116

partial_set = AshColorSingleFrames(
    Config.batch_size, Config.img_size, valid_ids, 'validation',
    preprocess=PREPROCESS, n_samples=N_PARTIAL)  # <DEVEL>
print('number of batches:', len(partial_set))

number of batches: 8

test_set = AshColorSingleFrames(
    Config.batch_size, Config.img_size, test_ids, 'test',
    preprocess=PREPROCESS)
print('number of batches:', len(test_set))

number of batches: 1

# Check batch dimensions (x, y):

train_set[0][0].shape, train_set[0][1].shape

((16, 256, 256, 3), (16, 256, 256, 1))

Training

def dice_coef(y_true, y_pred, smooth=0.001, threshold=None):
    '''Dice coefficient.
    
    Adapted from:
    - https://stackoverflow.com/questions/72195156/correct-implementation-of-dice-loss-in-tensorflow-keras
    - https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580
    '''
    
    y_true_f = backend.flatten(tf.cast(y_true, tf.float32))
    y_pred_f = backend.flatten(tf.cast(y_pred, tf.float32))
    # ValueError: No gradients provided for any variable
    if threshold is not None:
        y_pred_f = backend.flatten(
            tf.cast(tf.math.greater(tf.cast(y_pred, tf.float32), threshold), tf.float32))
    intersection = backend.sum(y_true_f * y_pred_f)
    dice = (2. * intersection + smooth) / (backend.sum(y_true_f) + backend.sum(y_pred_f) + smooth)
    return dice

def threshold_dice_coef(y_true, y_pred, smooth=0.001):
    return dice_coef(y_true, y_pred, smooth=smooth, threshold=Config.threshold)

def dice_loss(y_true, y_pred):
    return 1 - dice_coef(y_true, y_pred)

sample_id = train_ids[3]

print(f'Check `dice_coef()` on one of the samples: {sample_id}')

merged_mask = get_pixel_mask(sample_id, 'train')
indiv_masks = get_individual_mask(sample_id, 'train')

print(dice_coef(tf.convert_to_tensor(merged_mask),
                tf.convert_to_tensor(merged_mask)))
for idv in range(6):
    print(dice_coef(tf.convert_to_tensor(merged_mask),
                    tf.convert_to_tensor(indiv_masks[..., idv])))

Check `dice_coef()` on one of the samples: 7829917977180135058
tf.Tensor(1.0, shape=(), dtype=float32)
tf.Tensor(0.8743467, shape=(), dtype=float32)
tf.Tensor(0.83587146, shape=(), dtype=float32)
tf.Tensor(0.7393573, shape=(), dtype=float32)
tf.Tensor(0.8522139, shape=(), dtype=float32)
tf.Tensor(0.87988245, shape=(), dtype=float32)
tf.Tensor(0.84089667, shape=(), dtype=float32)

if TRAIN:
    checkpoint_path = f"contrails_{file_time_str}.h5"

print(f'checkpoint file: {checkpoint_path}')

checkpoint file: contrails_2023-07-20_17-45-46.h5

# Learning rate scheduler:
# - https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules
# - https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecay
# Note: CosineDecay got warmup in v2.13.1

initial_learning_rate = 0.01
decay_steps = len(train_set)
decay_rate = 0.7

cos_scheduler = keras.optimizers.schedules.CosineDecay(
    initial_learning_rate, decay_steps)

exp_scheduler = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate, decay_steps, decay_rate)

# Configure the model for training.

# We use the "sparse" version of categorical_crossentropy
# because our target data is integers.
# See also:
# loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)

model.compile(optimizer="adam", loss='binary_crossentropy', metrics=[dice_coef])
#model.compile(optimizer="adam", loss=dice_loss, metrics=[dice_coef])

callbacks = [
    #keras.callbacks.LearningRateScheduler(exp_scheduler),
    keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True)
]

if TRAIN:
    # Train the model, doing validation at the end of each epoch.
    history = model.fit(
        train_set, epochs=Config.num_epochs, validation_data=valid_set, callbacks=callbacks,
        workers=4, use_multiprocessing=True)
else:
    # Loads the weights
    model.load_weights(checkpoint_path)

Epoch 1/3

2023-07-20 15:46:10.633997: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inUNet/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer

1284/1284 [==============================] - 1426s 1s/step - loss: 0.0261 - dice_coef: 0.1586 - val_loss: 0.0096 - val_dice_coef: 0.1426
Epoch 2/3
1284/1284 [==============================] - 1408s 1s/step - loss: 0.0133 - dice_coef: 0.3419 - val_loss: 0.0057 - val_dice_coef: 0.3077
Epoch 3/3
1284/1284 [==============================] - 1383s 1s/step - loss: 0.0119 - dice_coef: 0.3925 - val_loss: 0.0058 - val_dice_coef: 0.2839

if TRAIN:
    print('History', history.history.keys())

    for var in ['loss', 'val_loss', 'dice_coef', 'val_dice_coef']:
        plt.figure(figsize=(10, 3))
        plt.plot(history.history[var])
        plt.title(f'model {var}')
        plt.ylabel(var)
        plt.xlabel('epoch')
        plt.legend(['train', 'val'], loc='upper left')
        plt.show()

History dict_keys(['loss', 'dice_coef', 'val_loss', 'val_dice_coef'])

Evaluate

def apply_threshold(pred, threshold):
    return (pred > threshold).astype(np.int32)

if not TRAIN:    
    # Evaluate the model

    ALL_BATCHES = True
    BATCH_IDX = 0
    SAMPLE_IDX = 1

    if ALL_BATCHES:
        loss, acc = model.evaluate(partial_set, verbose=2)
    else:
        eval_images, eval_masks = partial_set[BATCH_IDX]
        loss, acc = model.evaluate(eval_images, eval_masks, verbose=2)

    print("Saved model, accuracy: {:5.2f}%".format(100 * acc))

    predictions = model.predict(partial_set)

def eval_dice_coef(sample_set, pred_set, batch_size, threshold):
    dice_coef_per_batch = np.full(len(sample_set), np.nan)
    for idx in range(len(sample_set)):
        x, y = sample_set[idx]
        pred = pred_set[idx*batch_size:(idx + 1)*batch_size]
        _coef = dice_coef(y, pred, threshold=threshold)
        dice_coef_per_batch[idx] = _coef
    return dice_coef_per_batch

if not TRAIN:
    _coefs = eval_dice_coef(
        partial_set, predictions, batch_size=partial_set.batch_size, threshold=None)
    print(f'w/o threshod: {_coefs.mean():.2%}')

    _coefs = eval_dice_coef(
        partial_set, predictions, batch_size=partial_set.batch_size, threshold=Config.threshold)
    print(f'{Config.threshold}: {_coefs.mean():.2%}')

def plot_prediction(img, truth, pred):

    fig, axs = plt.subplots(1, 4, figsize=(16, 8))

    axs[0].imshow(img)
    axs[0].set_title("Ash Color Image")

    axs[1].imshow(truth)
    axs[1].set_title("Ground Truth")

    axs[2].imshow(pred)
    axs[2].set_title("Prediction")

    axs[3].imshow(img)
    axs[3].imshow(truth, cmap='Reds', alpha=.3, interpolation='none')
    axs[3].set_title('Contrail mask on ash color image')

    plt.tight_layout() 
    plt.show()

    return

if not TRAIN:
    eval_images, eval_masks = partial_set[BATCH_IDX]
    idx = SAMPLE_IDX
    threshold = Config.threshold
    plot_prediction(
        eval_images[idx], eval_masks[idx], apply_threshold(predictions[idx], threshold))

Make predictions on test dataset

predictions = model.predict(test_set)

1/1 [==============================] - 1s 781ms/step

len(predictions)

16

Create a submission

def rle_encode(x, fg_val=1):
    """
    Args:
        x:  numpy array of shape (height, width), 1 - mask, 0 - background
    Returns: run length encoding as list
    """

    dots = np.where(
        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right
    run_lengths = []
    prev = -2
    for b in dots:
        if b > prev + 1:
            run_lengths.extend((b + 1, 0))
        run_lengths[-1] += 1
        prev = b
    return run_lengths


def list_to_string(x):
    """
    Converts list to a string representation
    Empty list returns '-'
    """
    if x: # non-empty list
        s = str(x).replace("[", "").replace("]", "").replace(",", "")
    else:
        s = '-'
    return s

test_recs = os.listdir(os.path.join(DATA_DIR, 'test'))

submission = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'), index_col='record_id')[0:0]

for test_id, pred in zip(test_ids, predictions):
    
    mask = apply_threshold(pred, Config.threshold)
    
    # notice the we're converting rec to an `int` here:
    submission.loc[int(test_id), 'encoded_pixels'] = list_to_string(rle_encode(mask))
    
submission.to_csv('submission.csv')

print('Terminated', datetime.datetime.now(timezone('CET')).strftime(PRINT_TIME_FORMAT))

Terminated 2023-07-20 18:56:52 CEST+0200
