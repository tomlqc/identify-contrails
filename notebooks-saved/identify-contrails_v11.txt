
Identify Contrails with Keras

# reinstall tensorflow-io
# to avoid the UserWarning: unable to load libtensorflow_io_plugins.so

#!pip install tensorflow-io

#%cp ../input/identify-contrails-weights-v8/weights_v8_contrails-unet_cst-lr.h5 .
#%mv weights_v8_contrails-unet_cst-lr.h5 contrails-unet_cst-lr.h5

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import datetime
import math
import pathlib
import random
import shutil

from pytz import timezone

from tqdm.notebook import tqdm

import matplotlib.pyplot as plt
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import scipy

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
#for dirname, _, filenames in os.walk('/kaggle/input'):
#    for filename in filenames:
#        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

PRINT_TIME_FORMAT = "%Y-%m-%d %H:%M:%S %Z%z"
FILE_TIME_FORMAT = "%Y-%m-%d_%H-%M-%S"

file_time = datetime.datetime.now().strftime(FILE_TIME_FORMAT)

print('Started', datetime.datetime.now(timezone('CET')).strftime(PRINT_TIME_FORMAT))

Started 2023-07-15 17:10:50 CEST+0200

import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import backend as backend

/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']
caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']
  warnings.warn(f"unable to load libtensorflow_io_plugins.so: {e}")
/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']
caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']
  warnings.warn(f"file system plugins are not loaded: {e}")

tf.__version__

'2.12.0'

print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

Num GPUs Available:  1

%pwd

'/kaggle/working'

#---------------------------------------------------------------------------79

Following U-Net model is adapted from:

    https://keras.io/examples/vision/oxford_pets_image_segmentation
    https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580

Setup

WORK_DIR = '/kaggle/working'  # preserved if notebook is saved
TEMP_DIR = '/kaggle/temp'  # just during current session

DATA_DIR = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'

class Paths:
    train = os.path.join(DATA_DIR, 'train')
    valid = os.path.join(DATA_DIR, 'validation')
    test = os.path.join(DATA_DIR, 'test')

train_ids = os.listdir(Paths.train)
valid_ids = os.listdir(Paths.valid)
test_ids = os.listdir(Paths.test)
print(len(train_ids), len(valid_ids), len(test_ids))

20529 1856 2

class ABI:
    bands = {name: idx for idx, name in enumerate([
        '08', '09', '10', '11', '12', '13', '14', '15', '16'])}
    colors = {name: idx for idx, name in enumerate([
        'red', 'blue', 'green', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'black'])}

N_TIMES_BEFORE = 4
N_TIMES_AFTER = 3

def normalize_range(data, bounds):
    """Maps data to the range [0, 1]."""
    return (data - bounds[0]) / (bounds[1] - bounds[0])

_T11_BOUNDS = (243, 303)
_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)
_TDIFF_BOUNDS = (-4, 2)

def get_ash_colors(sample_id, split_dir):
    """
    Based on bands: 11, 14, 15
    
    Args:
        sample_id(str): The id of the example i.e. '1000216489776414077'
        split_dir(str): The split directoryu i.e. 'test', 'train', 'val'
    """
    band15 = np.load(DATA_DIR + f"/{split_dir}/{sample_id}/band_15.npy")
    band14 = np.load(DATA_DIR + f"/{split_dir}/{sample_id}/band_14.npy")
    band11 = np.load(DATA_DIR + f"/{split_dir}/{sample_id}/band_11.npy")

    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)
    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)
    b = normalize_range(band14, _T11_BOUNDS)
    ash_colors = np.clip(np.stack([r, g, b], axis=2), 0, 1)
    
    return ash_colors

def get_individual_mask(sample_id, split_dir):
    masks_path = DATA_DIR + f"/{split_dir}/{sample_id}/human_individual_masks.npy"
    pixel_mask = np.load(masks_path)
    return pixel_mask

def get_pixel_mask(sample_id, split_dir):
    masks_path = DATA_DIR + f"/{split_dir}/{sample_id}/human_pixel_masks.npy"
    pixel_mask = np.load(masks_path)
    return pixel_mask

Check some values (DEVEL)

sample_id = train_ids[3]

ash_colors = get_ash_colors(sample_id, 'train')[..., N_TIMES_BEFORE]

print(ash_colors.shape)
for color in range(3):
    array = ash_colors[..., color]
    print(array.min(), array.max())

(256, 256, 3)
0.0 0.50921124
0.097476535 0.86938816
0.031865694 0.81146187

pixel_mask = get_pixel_mask(sample_id, 'train')

print(pixel_mask.shape)
print(pixel_mask.min(), pixel_mask.max())

(256, 256, 1)
0 1

Model

SEED = 42

class Config:
    
    img_size = (256, 256)
    
    num_epochs = 10  # <DEVEL> else 10
    num_classes = 1
    batch_size = 16  # <DEVEL> else 32
    
    threshold = 0.40
    
    seed = SEED

# https://keras.io/examples/keras_recipes/reproducibility_recipes/

# Set the seed using keras.utils.set_random_seed. This will set:
# 1) `numpy` seed
# 2) `tensorflow` random seed
# 3) `python` random seed
keras.utils.set_random_seed(Config.seed)

# See also:
# tf.config.experimental.enable_op_determinism()

Model inspired by:

    https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow/
    file:///D:/Courses/2023-07_Advanced-Computer-Vision-with-TensorFlow/lecture-notes/C3_W3_Image-Segmentation.pdf

def conv2d_block(input_tensor, n_filters, kernel_size=3):
    x = input_tensor
    for i in range(2):
        x = tf.keras.layers.SeparableConv2D(
            filters = n_filters, kernel_size=(kernel_size, kernel_size), padding='same')(x)
        #? kernel_initializer = 'he_normal'
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation('relu')(x)
    return x

def encoder_block(inputs, n_filters, pool_size, dropout):
    f = conv2d_block(inputs, n_filters=n_filters)
    p = tf.keras.layers.MaxPooling2D(pool_size)(f)
    p = tf.keras.layers.Dropout(dropout)(p)
    return f, p

def encoder(inputs, dropout=0.1):
    f1, p1 = encoder_block(inputs, n_filters=64, pool_size=(2,2), dropout=dropout)
    f2, p2 = encoder_block(p1, n_filters=128, pool_size=(2,2), dropout=dropout)
    f3, p3 = encoder_block(p2, n_filters=256, pool_size=(2,2), dropout=dropout)
    f4, p4 = encoder_block(p3, n_filters=512, pool_size=(2,2), dropout=dropout)
    return p4, (f1, f2, f3, f4)

def bottleneck(inputs):
    bottle_neck = conv2d_block(inputs, n_filters=1024)
    return bottle_neck

def decoder_block(inputs, conv_output, n_filters, kernel_size, strides, dropout):
    u = tf.keras.layers.Conv2DTranspose(
        n_filters, kernel_size, strides=strides, padding = 'same')(inputs)
    u = tf.keras.layers.BatchNormalization()(u)
    c = tf.keras.layers.concatenate([u, conv_output])
    c = tf.keras.layers.Dropout(dropout)(c)
    c = conv2d_block(c, n_filters, kernel_size=3)
    return c

def decoder(inputs, convs, num_classes, dropout=0.1):
    f1, f2, f3, f4 = convs
    c6 = decoder_block(inputs, f4, n_filters=512, kernel_size=(3,3), strides=(2,2), dropout=dropout)
    c7 = decoder_block(c6, f3, n_filters=256, kernel_size=(3,3), strides=(2,2), dropout=dropout)
    c8 = decoder_block(c7, f2, n_filters=128, kernel_size=(3,3), strides=(2,2), dropout=dropout)
    c9 = decoder_block(c8, f1, n_filters=64, kernel_size=(3,3), strides=(2,2), dropout=dropout)
    if num_classes == 1:
        activation = "sigmoid"
    else:
        activation = "softmax"
    outputs = layers.Conv2D(num_classes, kernel_size=3, activation=activation, padding="same")(c9)
    return outputs

def unet(image_size, num_classes):
    inputs = tf.keras.layers.Input(shape=(image_size,image_size,3))
    encoder_output, convs = encoder(inputs)
    #model = tf.keras.Model(inputs=inputs, outputs=encoder_output)  # debug
    bottle_neck = bottleneck(encoder_output)
    outputs = decoder(bottle_neck, convs, num_classes)
    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model

# Free up RAM in case the model definition cells were run multiple times
keras.backend.clear_session()

# Build model
#model = get_model(Config.img_size, Config.num_classes)
model = unet(image_size=256, num_classes=1)
model.summary()

Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               
                                )]                                                                
                                                                                                  
 separable_conv2d (SeparableCon  (None, 256, 256, 64  283        ['input_1[0][0]']                
 v2D)                           )                                                                 
                                                                                                  
 batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['separable_conv2d[0][0]']       
 alization)                     )                                                                 
                                                                                                  
 activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    
                                )                                                                 
                                                                                                  
 separable_conv2d_1 (SeparableC  (None, 256, 256, 64  4736       ['activation[0][0]']             
 onv2D)                         )                                                                 
                                                                                                  
 batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['separable_conv2d_1[0][0]']     
 rmalization)                   )                                                                 
                                                                                                  
 activation_1 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[0][0]']  
                                )                                                                 
                                                                                                  
 max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['activation_1[0][0]']           
                                )                                                                 
                                                                                                  
 dropout (Dropout)              (None, 128, 128, 64  0           ['max_pooling2d[0][0]']          
                                )                                                                 
                                                                                                  
 separable_conv2d_2 (SeparableC  (None, 128, 128, 12  8896       ['dropout[0][0]']                
 onv2D)                         8)                                                                
                                                                                                  
 batch_normalization_2 (BatchNo  (None, 128, 128, 12  512        ['separable_conv2d_2[0][0]']     
 rmalization)                   8)                                                                
                                                                                                  
 activation_2 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_2[0][0]']  
                                8)                                                                
                                                                                                  
 separable_conv2d_3 (SeparableC  (None, 128, 128, 12  17664      ['activation_2[0][0]']           
 onv2D)                         8)                                                                
                                                                                                  
 batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['separable_conv2d_3[0][0]']     
 rmalization)                   8)                                                                
                                                                                                  
 activation_3 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[0][0]']  
                                8)                                                                
                                                                                                  
 max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['activation_3[0][0]']           
                                                                                                  
 dropout_1 (Dropout)            (None, 64, 64, 128)  0           ['max_pooling2d_1[0][0]']        
                                                                                                  
 separable_conv2d_4 (SeparableC  (None, 64, 64, 256)  34176      ['dropout_1[0][0]']              
 onv2D)                                                                                           
                                                                                                  
 batch_normalization_4 (BatchNo  (None, 64, 64, 256)  1024       ['separable_conv2d_4[0][0]']     
 rmalization)                                                                                     
                                                                                                  
 activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_4[0][0]']  
                                                                                                  
 separable_conv2d_5 (SeparableC  (None, 64, 64, 256)  68096      ['activation_4[0][0]']           
 onv2D)                                                                                           
                                                                                                  
 batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['separable_conv2d_5[0][0]']     
 rmalization)                                                                                     
                                                                                                  
 activation_5 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[0][0]']  
                                                                                                  
 max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['activation_5[0][0]']           
                                                                                                  
 dropout_2 (Dropout)            (None, 32, 32, 256)  0           ['max_pooling2d_2[0][0]']        
                                                                                                  
 separable_conv2d_6 (SeparableC  (None, 32, 32, 512)  133888     ['dropout_2[0][0]']              
 onv2D)                                                                                           
                                                                                                  
 batch_normalization_6 (BatchNo  (None, 32, 32, 512)  2048       ['separable_conv2d_6[0][0]']     
 rmalization)                                                                                     
                                                                                                  
 activation_6 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_6[0][0]']  
                                                                                                  
 separable_conv2d_7 (SeparableC  (None, 32, 32, 512)  267264     ['activation_6[0][0]']           
 onv2D)                                                                                           
                                                                                                  
 batch_normalization_7 (BatchNo  (None, 32, 32, 512)  2048       ['separable_conv2d_7[0][0]']     
 rmalization)                                                                                     
                                                                                                  
 activation_7 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_7[0][0]']  
                                                                                                  
 max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['activation_7[0][0]']           
                                                                                                  
 dropout_3 (Dropout)            (None, 16, 16, 512)  0           ['max_pooling2d_3[0][0]']        
                                                                                                  
 separable_conv2d_8 (SeparableC  (None, 16, 16, 1024  529920     ['dropout_3[0][0]']              
 onv2D)                         )                                                                 
                                                                                                  
 batch_normalization_8 (BatchNo  (None, 16, 16, 1024  4096       ['separable_conv2d_8[0][0]']     
 rmalization)                   )                                                                 
                                                                                                  
 activation_8 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_8[0][0]']  
                                )                                                                 
                                                                                                  
 separable_conv2d_9 (SeparableC  (None, 16, 16, 1024  1058816    ['activation_8[0][0]']           
 onv2D)                         )                                                                 
                                                                                                  
 batch_normalization_9 (BatchNo  (None, 16, 16, 1024  4096       ['separable_conv2d_9[0][0]']     
 rmalization)                   )                                                                 
                                                                                                  
 activation_9 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_9[0][0]']  
                                )                                                                 
                                                                                                  
 conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  4719104    ['activation_9[0][0]']           
 ose)                                                                                             
                                                                                                  
 batch_normalization_10 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_transpose[0][0]']       
 ormalization)                                                                                    
                                                                                                  
 concatenate (Concatenate)      (None, 32, 32, 1024  0           ['batch_normalization_10[0][0]', 
                                )                                 'activation_7[0][0]']           
                                                                                                  
 dropout_4 (Dropout)            (None, 32, 32, 1024  0           ['concatenate[0][0]']            
                                )                                                                 
                                                                                                  
 separable_conv2d_10 (Separable  (None, 32, 32, 512)  534016     ['dropout_4[0][0]']              
 Conv2D)                                                                                          
                                                                                                  
 batch_normalization_11 (BatchN  (None, 32, 32, 512)  2048       ['separable_conv2d_10[0][0]']    
 ormalization)                                                                                    
                                                                                                  
 activation_10 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_11[0][0]'] 
                                                                                                  
 separable_conv2d_11 (Separable  (None, 32, 32, 512)  267264     ['activation_10[0][0]']          
 Conv2D)                                                                                          
                                                                                                  
 batch_normalization_12 (BatchN  (None, 32, 32, 512)  2048       ['separable_conv2d_11[0][0]']    
 ormalization)                                                                                    
                                                                                                  
 activation_11 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_12[0][0]'] 
                                                                                                  
 conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  1179904    ['activation_11[0][0]']          
 spose)                                                                                           
                                                                                                  
 batch_normalization_13 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_transpose_1[0][0]']     
 ormalization)                                                                                    
                                                                                                  
 concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['batch_normalization_13[0][0]', 
                                                                  'activation_5[0][0]']           
                                                                                                  
 dropout_5 (Dropout)            (None, 64, 64, 512)  0           ['concatenate_1[0][0]']          
                                                                                                  
 separable_conv2d_12 (Separable  (None, 64, 64, 256)  135936     ['dropout_5[0][0]']              
 Conv2D)                                                                                          
                                                                                                  
 batch_normalization_14 (BatchN  (None, 64, 64, 256)  1024       ['separable_conv2d_12[0][0]']    
 ormalization)                                                                                    
                                                                                                  
 activation_12 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_14[0][0]'] 
                                                                                                  
 separable_conv2d_13 (Separable  (None, 64, 64, 256)  68096      ['activation_12[0][0]']          
 Conv2D)                                                                                          
                                                                                                  
 batch_normalization_15 (BatchN  (None, 64, 64, 256)  1024       ['separable_conv2d_13[0][0]']    
 ormalization)                                                                                    
                                                                                                  
 activation_13 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_15[0][0]'] 
                                                                                                  
 conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  295040     ['activation_13[0][0]']          
 spose)                         8)                                                                
                                                                                                  
 batch_normalization_16 (BatchN  (None, 128, 128, 12  512        ['conv2d_transpose_2[0][0]']     
 ormalization)                  8)                                                                
                                                                                                  
 concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['batch_normalization_16[0][0]', 
                                6)                                'activation_3[0][0]']           
                                                                                                  
 dropout_6 (Dropout)            (None, 128, 128, 25  0           ['concatenate_2[0][0]']          
                                6)                                                                
                                                                                                  
 separable_conv2d_14 (Separable  (None, 128, 128, 12  35200      ['dropout_6[0][0]']              
 Conv2D)                        8)                                                                
                                                                                                  
 batch_normalization_17 (BatchN  (None, 128, 128, 12  512        ['separable_conv2d_14[0][0]']    
 ormalization)                  8)                                                                
                                                                                                  
 activation_14 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_17[0][0]'] 
                                8)                                                                
                                                                                                  
 separable_conv2d_15 (Separable  (None, 128, 128, 12  17664      ['activation_14[0][0]']          
 Conv2D)                        8)                                                                
                                                                                                  
 batch_normalization_18 (BatchN  (None, 128, 128, 12  512        ['separable_conv2d_15[0][0]']    
 ormalization)                  8)                                                                
                                                                                                  
 activation_15 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_18[0][0]'] 
                                8)                                                                
                                                                                                  
 conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  73792      ['activation_15[0][0]']          
 spose)                         )                                                                 
                                                                                                  
 batch_normalization_19 (BatchN  (None, 256, 256, 64  256        ['conv2d_transpose_3[0][0]']     
 ormalization)                  )                                                                 
                                                                                                  
 concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['batch_normalization_19[0][0]', 
                                8)                                'activation_1[0][0]']           
                                                                                                  
 dropout_7 (Dropout)            (None, 256, 256, 12  0           ['concatenate_3[0][0]']          
                                8)                                                                
                                                                                                  
 separable_conv2d_16 (Separable  (None, 256, 256, 64  9408       ['dropout_7[0][0]']              
 Conv2D)                        )                                                                 
                                                                                                  
 batch_normalization_20 (BatchN  (None, 256, 256, 64  256        ['separable_conv2d_16[0][0]']    
 ormalization)                  )                                                                 
                                                                                                  
 activation_16 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_20[0][0]'] 
                                )                                                                 
                                                                                                  
 separable_conv2d_17 (Separable  (None, 256, 256, 64  4736       ['activation_16[0][0]']          
 Conv2D)                        )                                                                 
                                                                                                  
 batch_normalization_21 (BatchN  (None, 256, 256, 64  256        ['separable_conv2d_17[0][0]']    
 ormalization)                  )                                                                 
                                                                                                  
 activation_17 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_21[0][0]'] 
                                )                                                                 
                                                                                                  
 conv2d (Conv2D)                (None, 256, 256, 1)  577         ['activation_17[0][0]']          
                                                                                                  
==================================================================================================
Total params: 9,491,868
Trainable params: 9,478,172
Non-trainable params: 13,696
__________________________________________________________________________________________________

Prepare datasets

N_SAMPLES = None  # None to take all
N_PARTIAL = 128  # 128

class AshColorSingleFrames(keras.utils.Sequence):
    """Helper to iterate over the data (as Numpy arrays)."""

    def __init__(self, batch_size, img_size, sample_ids, split_dir, n_samples=None):
        self.batch_size = batch_size
        self.img_size = img_size
        self.split_dir = split_dir
        self.sample_ids = sample_ids[:n_samples]

    def __len__(self):
        return math.ceil(len(self.sample_ids) / self.batch_size)

    def __getitem__(self, idx):
        """Returns tuple (input, target) correspond to batch #idx."""
        i = idx * self.batch_size
        batch_sample_ids = self.sample_ids[i : i + self.batch_size]
        
        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype="float32")
        for j, sample_id in enumerate(batch_sample_ids):
            img = get_ash_colors(sample_id, self.split_dir)
            x[j] = img[..., N_TIMES_BEFORE]

        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype="uint8")
        if self.split_dir != 'test':
            for j, sample_id in enumerate(batch_sample_ids):
                img = get_pixel_mask(sample_id, self.split_dir)
                y[j] = img
        
        return x, y

train_set = AshColorSingleFrames(Config.batch_size, Config.img_size, train_ids, 'train',
                                 n_samples=N_SAMPLES)  # <DEVEL>
print('number of batches:', len(train_set))

number of batches: 1284

valid_set = AshColorSingleFrames(Config.batch_size, Config.img_size, valid_ids, 'validation',
                                 n_samples=N_SAMPLES)  # <DEVEL>
print('number of batches:', len(valid_set))

number of batches: 116

partial_set = AshColorSingleFrames(Config.batch_size, Config.img_size, valid_ids, 'validation',
                                 n_samples=N_PARTIAL)  # <DEVEL>
print('number of batches:', len(partial_set))

number of batches: 8

test_set = AshColorSingleFrames(Config.batch_size, Config.img_size, test_ids, 'test')
print('number of batches:', len(test_set))

number of batches: 1

Check batch dimensions (x, y):

train_set[0][0].shape, train_set[0][1].shape

((16, 256, 256, 3), (16, 256, 256, 1))

Training

dice_coef adapted from:

    https://stackoverflow.com/questions/72195156/correct-implementation-of-dice-loss-in-tensorflow-keras
    https://www.kaggle.com/code/shashwatraman/simple-unet-baseline-train-lb-0-580

def dice_coef(y_true, y_pred, smooth=0.001, threshold=None):
    y_true_f = backend.flatten(tf.cast(y_true, tf.float32))
    y_pred_f = backend.flatten(tf.cast(y_pred, tf.float32))
    # ValueError: No gradients provided for any variable
    if threshold is not None:
        y_pred_f = backend.flatten(
            tf.cast(tf.math.greater(tf.cast(y_pred, tf.float32), threshold), tf.float32))
    intersection = backend.sum(y_true_f * y_pred_f)
    dice = (2. * intersection + smooth) / (backend.sum(y_true_f) + backend.sum(y_pred_f) + smooth)
    return dice

def threshold_dice_coef(y_true, y_pred, smooth=0.001):
    return dice_coef(y_true, y_pred, smooth=smooth, threshold=Config.threshold)

def dice_loss(y_true, y_pred):
    return 1 - dice_coef(y_true, y_pred)

Check dice_coef() on one of the samples.

sample_id = train_ids[3]

merged_mask = get_pixel_mask(sample_id, 'train')
indiv_masks = get_individual_mask(sample_id, 'train')

print(dice_coef(tf.convert_to_tensor(merged_mask),
                tf.convert_to_tensor(merged_mask)))
for idv in range(6):
    print(dice_coef(tf.convert_to_tensor(merged_mask),
                    tf.convert_to_tensor(indiv_masks[..., idv])))

tf.Tensor(1.0, shape=(), dtype=float32)
tf.Tensor(0.8743467, shape=(), dtype=float32)
tf.Tensor(0.83587146, shape=(), dtype=float32)
tf.Tensor(0.7393573, shape=(), dtype=float32)
tf.Tensor(0.8522139, shape=(), dtype=float32)
tf.Tensor(0.87988245, shape=(), dtype=float32)
tf.Tensor(0.84089667, shape=(), dtype=float32)

Learning rate scheduler:

    https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules
    https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecay - warmup only from v2.13.1 on

initial_learning_rate = 0.01
decay_steps = len(train_set)
decay_rate = 0.7

cos_scheduler = keras.optimizers.schedules.CosineDecay(
    initial_learning_rate, decay_steps)

exp_scheduler = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate, decay_steps, decay_rate)

checkpoint_path = f"contrails_{file_time}.h5"
print(f'checkpoint file: {checkpoint_path}')

checkpoint file: contrails_2023-07-15_15-10-49.h5

# Configure the model for training.
# We use the "sparse" version of categorical_crossentropy
# because our target data is integers.

model.compile(optimizer="adam", loss='binary_crossentropy', metrics=[dice_coef])
#model.compile(optimizer="adam", loss=dice_loss, metrics=[dice_coef])

callbacks = [
    #keras.callbacks.LearningRateScheduler(exp_scheduler),
    keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True)
]

TRAIN = True

if TRAIN:
    # Train the model, doing validation at the end of each epoch.
    model.fit(train_set, epochs=Config.num_epochs, validation_data=valid_set, callbacks=callbacks)
else:
    # Loads the weights
    model.load_weights(checkpoint_path)

Epoch 1/10

2023-07-15 15:11:13.997896: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer

1284/1284 [==============================] - 1904s 1s/step - loss: 0.0261 - dice_coef: 0.1591 - val_loss: 0.0102 - val_dice_coef: 0.1354
Epoch 2/10
1284/1284 [==============================] - 1786s 1s/step - loss: 0.0135 - dice_coef: 0.3378 - val_loss: 0.0068 - val_dice_coef: 0.2578
Epoch 3/10
1284/1284 [==============================] - 1825s 1s/step - loss: 0.0119 - dice_coef: 0.3930 - val_loss: 0.0050 - val_dice_coef: 0.3580
Epoch 4/10
1284/1284 [==============================] - 1862s 1s/step - loss: 0.0111 - dice_coef: 0.4216 - val_loss: 0.0052 - val_dice_coef: 0.3173
Epoch 5/10
1284/1284 [==============================] - 1865s 1s/step - loss: 0.0106 - dice_coef: 0.4414 - val_loss: 0.0054 - val_dice_coef: 0.3075
Epoch 6/10
1284/1284 [==============================] - 1861s 1s/step - loss: 0.0102 - dice_coef: 0.4593 - val_loss: 0.0046 - val_dice_coef: 0.3755
Epoch 7/10
1284/1284 [==============================] - 1923s 1s/step - loss: 0.0099 - dice_coef: 0.4701 - val_loss: 0.0043 - val_dice_coef: 0.4063
Epoch 8/10
1284/1284 [==============================] - 1897s 1s/step - loss: 0.0096 - dice_coef: 0.4820 - val_loss: 0.0043 - val_dice_coef: 0.4145
Epoch 9/10
1284/1284 [==============================] - 1872s 1s/step - loss: 0.0093 - dice_coef: 0.4932 - val_loss: 0.0054 - val_dice_coef: 0.3256
Epoch 10/10
1284/1284 [==============================] - 1976s 2s/step - loss: 0.0091 - dice_coef: 0.5028 - val_loss: 0.0043 - val_dice_coef: 0.4263

Before submitting, we will have to apply the threshold!

def apply_threshold(pred, threshold):
    return (pred > threshold).astype(np.int32)

#keras.backend.clear_session()

Make predictions on test dataset

predictions = model.predict(test_set)

1/1 [==============================] - 1s 778ms/step

len(predictions)

16

Create a submission

def rle_encode(x, fg_val=1):
    """
    Args:
        x:  numpy array of shape (height, width), 1 - mask, 0 - background
    Returns: run length encoding as list
    """

    dots = np.where(
        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right
    run_lengths = []
    prev = -2
    for b in dots:
        if b > prev + 1:
            run_lengths.extend((b + 1, 0))
        run_lengths[-1] += 1
        prev = b
    return run_lengths


def list_to_string(x):
    """
    Converts list to a string representation
    Empty list returns '-'
    """
    if x: # non-empty list
        s = str(x).replace("[", "").replace("]", "").replace(",", "")
    else:
        s = '-'
    return s

test_recs = os.listdir(os.path.join(DATA_DIR, 'test'))

submission = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'), index_col='record_id')[0:0]

for test_id, pred in zip(test_ids, predictions):
    
    mask = apply_threshold(pred, Config.threshold)
    
    # notice the we're converting rec to an `int` here:
    submission.loc[int(test_id), 'encoded_pixels'] = list_to_string(rle_encode(mask))
    
submission.to_csv('submission.csv')

print('Terminated', datetime.datetime.now(timezone('CET')).strftime(PRINT_TIME_FORMAT))

Terminated 2023-07-15 22:26:23 CEST+0200

